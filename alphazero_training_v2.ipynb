{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "jfTPpJsvdjZx",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 615,
     "status": "ok",
     "timestamp": 1733701384829,
     "user": {
      "displayName": "Siyi Wu",
      "userId": "06196688456534608936"
     },
     "user_tz": 360
    },
    "id": "jfTPpJsvdjZx",
    "outputId": "5b384f92-0fc8-4c1d-eae9-0eaa4b2d5896"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "96P8EsRKeGJT",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 101,
     "status": "ok",
     "timestamp": 1733701385266,
     "user": {
      "displayName": "Siyi Wu",
      "userId": "06196688456534608936"
     },
     "user_tz": 360
    },
    "id": "96P8EsRKeGJT",
    "outputId": "2aa9f03e-cec8-4dab-e260-ecea06b460a3"
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/content/drive/MyDrive/code/WZ'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [1]\u001b[0m, in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mos\u001b[39;00m\n\u001b[1;32m      2\u001b[0m path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/content/drive/MyDrive/code/WZ\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m----> 3\u001b[0m \u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mchdir\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(os\u001b[38;5;241m.\u001b[39mgetcwd())\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/drive/MyDrive/code/WZ'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "path = \"/content/drive/MyDrive/code/WZ\"\n",
    "os.chdir(path)\n",
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5397fffc",
   "metadata": {
    "executionInfo": {
     "elapsed": 9677,
     "status": "ok",
     "timestamp": 1733701395668,
     "user": {
      "displayName": "Siyi Wu",
      "userId": "06196688456534608936"
     },
     "user_tz": 360
    },
    "id": "5397fffc"
   },
   "outputs": [],
   "source": [
    "import importlib\n",
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import random\n",
    "\n",
    "from collections import deque\n",
    "\n",
    "\n",
    "sizef = 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9a318702",
   "metadata": {
    "id": "9a318702"
   },
   "outputs": [],
   "source": [
    "class Gomoku:\n",
    "    def __init__(self, size=sizef, black_strategy=None, white_strategy=None):\n",
    "        self.size = size  # 棋盘大小\n",
    "        self.board = [['.' for _ in range(size)] for _ in range(size)]  # 初始化棋盘\n",
    "        self.current_player = 'X'  # 当前玩家 ('X' or 'O')\n",
    "        self.black_strategy = black_strategy  # 黑棋策略函数\n",
    "        self.white_strategy = white_strategy  # 白棋策略函数\n",
    "\n",
    "    def display_board(self):\n",
    "        \"\"\"打印棋盘\"\"\"\n",
    "        print(\"   \" + \" \".join(f\"{i:2}\" for i in range(self.size)))\n",
    "        for i, row in enumerate(self.board):\n",
    "            print(f\"{i:2} \" + \" \".join(row))\n",
    "\n",
    "    def is_valid_move(self, x, y):\n",
    "        \"\"\"检查落子是否合法\"\"\"\n",
    "        return 0 <= x < self.size and 0 <= y < self.size and self.board[x][y] == '.'\n",
    "\n",
    "    def make_move(self, x, y):\n",
    "        \"\"\"下棋\"\"\"\n",
    "        if self.is_valid_move(x, y):\n",
    "            self.board[x][y] = self.current_player\n",
    "            return True\n",
    "        else:\n",
    "            print(f\"Invalid move by player {self.current_player} at ({x}, {y}).\")\n",
    "            return False\n",
    "\n",
    "    def check_winner(self, x, y):\n",
    "        \"\"\"检查当前玩家是否获胜\"\"\"\n",
    "        directions = [(1, 0), (0, 1), (1, 1), (1, -1)]  # 四个方向：水平、垂直、正斜线、反斜线\n",
    "        for dx, dy in directions:\n",
    "            count = 1\n",
    "            # 检查正方向\n",
    "            for step in range(1, 5):\n",
    "                nx, ny = x + step * dx, y + step * dy\n",
    "                if 0 <= nx < self.size and 0 <= ny < self.size and self.board[nx][ny] == self.current_player:\n",
    "                    count += 1\n",
    "                else:\n",
    "                    break\n",
    "            # 检查反方向\n",
    "            for step in range(1, 5):\n",
    "                nx, ny = x - step * dx, y - step * dy\n",
    "                if 0 <= nx < self.size and 0 <= ny < self.size and self.board[nx][ny] == self.current_player:\n",
    "                    count += 1\n",
    "                else:\n",
    "                    break\n",
    "            if count >= 5:  # 连续五子\n",
    "                return True\n",
    "        return False\n",
    "\n",
    "    def switch_player(self):\n",
    "        \"\"\"切换玩家\"\"\"\n",
    "        self.current_player = 'O' if self.current_player == 'X' else 'X'\n",
    "\n",
    "    def play(self):\n",
    "        \"\"\"游戏主循环\"\"\"\n",
    "        print(\"Starting Gomoku!\")\n",
    "        self.display_board()\n",
    "\n",
    "        # 检查是否有 GPU 可用\n",
    "        device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "        print(f\"Running on device: {device}\")\n",
    "\n",
    "        while True:\n",
    "            if self.current_player == 'X':\n",
    "                if self.black_strategy:\n",
    "                    # 将策略函数运行在指定设备上\n",
    "                    move = self.black_strategy(self.board, 'X', device=device)\n",
    "                else:\n",
    "                    move = self.get_human_move()\n",
    "            else:\n",
    "                if self.white_strategy:\n",
    "                    # 将策略函数运行在指定设备上\n",
    "                    move = self.white_strategy(self.board, 'O', device=device)\n",
    "                else:\n",
    "                    move = self.get_human_move()\n",
    "\n",
    "            if not move or len(move) != 2:\n",
    "                print(f\"Invalid move returned by player {self.current_player}.\")\n",
    "                break\n",
    "\n",
    "            x, y = move\n",
    "            if self.make_move(x, y):\n",
    "                print(f\"Player {self.current_player} places at ({x}, {y})\")\n",
    "                self.display_board()\n",
    "                if self.check_winner(x, y):\n",
    "                    print(f\"Player {self.current_player} wins!\")\n",
    "                    break\n",
    "                self.switch_player()\n",
    "            else:\n",
    "                print(\"Game Over due to invalid move.\")\n",
    "                break\n",
    "\n",
    "        print(\"Game Over!\")\n",
    "\n",
    "    def get_human_move(self):\n",
    "        \"\"\"获取玩家的落子\"\"\"\n",
    "        while True:\n",
    "            try:\n",
    "                move = input(f\"Player {self.current_player}, enter your move (row col): \").strip()\n",
    "                x, y = map(int, move.split())\n",
    "                if self.is_valid_move(x, y):\n",
    "                    return x, y\n",
    "                else:\n",
    "                    print(\"Invalid move. Try again.\")\n",
    "            except ValueError:\n",
    "                print(\"Invalid input. Please enter row and column numbers separated by a space.\")\n",
    "\n",
    "\n",
    "def load_strategy(file_name):\n",
    "    \"\"\"从本地文件加载策略\"\"\"\n",
    "    if not os.path.exists(file_name):\n",
    "        raise FileNotFoundError(f\"Strategy file {file_name} not found.\")\n",
    "\n",
    "    module_name = os.path.splitext(os.path.basename(file_name))[0]\n",
    "    spec = importlib.util.spec_from_file_location(module_name, file_name)\n",
    "    module = importlib.util.module_from_spec(spec)\n",
    "    spec.loader.exec_module(module)\n",
    "    return module.play  # 假设策略文件中定义了一个 play 函数\n",
    "\n",
    "\n",
    "\n",
    "def print_strategy_files(directory):\n",
    "    try:\n",
    "        for root, dirs, files in os.walk(directory):\n",
    "            for file in files:\n",
    "                if file.endswith(\"strategy.py\"):\n",
    "                    print(file)\n",
    "    except Exception as e:\n",
    "        print(f\"Invaid: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "90c801a2",
   "metadata": {
    "id": "90c801a2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Welcome to Gomoku!\n",
      "Choose game mode:\n",
      "1. Human vs AI\n",
      "2. AI vs AI\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "Interrupted by user",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [3]\u001b[0m, in \u001b[0;36m<cell line: 5>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m1. Human vs AI\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m2. AI vs AI\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m----> 5\u001b[0m mode \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43minput\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mEnter 1 or 2: \u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mstrip()\n\u001b[1;32m      7\u001b[0m black_strategy \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m      8\u001b[0m white_strategy \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/opt/miniconda3/lib/python3.9/site-packages/ipykernel/kernelbase.py:1075\u001b[0m, in \u001b[0;36mKernel.raw_input\u001b[0;34m(self, prompt)\u001b[0m\n\u001b[1;32m   1071\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_allow_stdin:\n\u001b[1;32m   1072\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m StdinNotImplementedError(\n\u001b[1;32m   1073\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mraw_input was called, but this frontend does not support input requests.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1074\u001b[0m     )\n\u001b[0;32m-> 1075\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_input_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1076\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1077\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_parent_ident\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mshell\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1078\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_parent\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mshell\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1079\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpassword\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   1080\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/miniconda3/lib/python3.9/site-packages/ipykernel/kernelbase.py:1120\u001b[0m, in \u001b[0;36mKernel._input_request\u001b[0;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[1;32m   1117\u001b[0m             \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m   1118\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyboardInterrupt\u001b[39;00m:\n\u001b[1;32m   1119\u001b[0m     \u001b[38;5;66;03m# re-raise KeyboardInterrupt, to truncate traceback\u001b[39;00m\n\u001b[0;32m-> 1120\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyboardInterrupt\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInterrupted by user\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1121\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[1;32m   1122\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlog\u001b[38;5;241m.\u001b[39mwarning(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInvalid Message:\u001b[39m\u001b[38;5;124m\"\u001b[39m, exc_info\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: Interrupted by user"
     ]
    }
   ],
   "source": [
    "print(\"Welcome to Gomoku!\")\n",
    "print(\"Choose game mode:\")\n",
    "print(\"1. Human vs AI\")\n",
    "print(\"2. AI vs AI\")\n",
    "mode = input(\"Enter 1 or 2: \").strip()\n",
    "\n",
    "black_strategy = None\n",
    "white_strategy = None\n",
    "\n",
    "if mode == \"1\":\n",
    "    print(\"You will play as 'X'.\")\n",
    "    print_strategy_files(os.getcwd())\n",
    "    white_strategy_file = input(\"Enter the AI strategy file for 'O' (e.g., white_strategy.py): \").strip()\n",
    "    white_strategy = load_strategy(white_strategy_file)\n",
    "elif mode == \"2\":\n",
    "    print_strategy_files(os.getcwd())\n",
    "    black_strategy_file = input(\"Enter the AI strategy file for 'X' (e.g., black_strategy.py): \").strip()\n",
    "    white_strategy_file = input(\"Enter the AI strategy file for 'O' (e.g., white_strategy.py): \").strip()\n",
    "    black_strategy = load_strategy(black_strategy_file)\n",
    "    white_strategy = load_strategy(white_strategy_file)\n",
    "else:\n",
    "    print(\"Invalid choice. Exiting.\")\n",
    "\n",
    "game = Gomoku(black_strategy=black_strategy, white_strategy=white_strategy)\n",
    "game.play()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c5873910",
   "metadata": {
    "executionInfo": {
     "elapsed": 327,
     "status": "ok",
     "timestamp": 1733701425464,
     "user": {
      "displayName": "Siyi Wu",
      "userId": "06196688456534608936"
     },
     "user_tz": 360
    },
    "id": "c5873910"
   },
   "outputs": [],
   "source": [
    "from alpha0v2_strategy_v2 import AlphaZeroNet\n",
    "from alpha0v2_strategy_v2 import MCTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "r3lQPHih7ez9",
   "metadata": {
    "executionInfo": {
     "elapsed": 118,
     "status": "ok",
     "timestamp": 1733701428317,
     "user": {
      "displayName": "Siyi Wu",
      "userId": "06196688456534608936"
     },
     "user_tz": 360
    },
    "id": "r3lQPHih7ez9"
   },
   "outputs": [],
   "source": [
    "# ------------------------------\n",
    "# Data Generation via Self-Play\n",
    "# ------------------------------\n",
    "def self_play_game(model, board_size, mcts_simulations=5):\n",
    "    \"\"\"Generate training data via self-play\"\"\"\n",
    "    # 检查是否有 GPU 并将模型移动到 GPU\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model = model.to(device)\n",
    "\n",
    "    # 初始化棋盘和 MCTS\n",
    "    board = [['.' for _ in range(board_size)] for _ in range(board_size)]\n",
    "    mcts = MCTS(model, board_size)\n",
    "    current_player = 'X'\n",
    "    last_move = None\n",
    "    game_data = []  # Store (state, policy, value) for training\n",
    "    winner = None\n",
    "\n",
    "    while True:\n",
    "\n",
    "        # Run MCTS to get the move and actions\n",
    "        move, actions = mcts.run(board, current_player, mcts_simulations, last_move=last_move)\n",
    "\n",
    "        # Step 1: 提取所有 (action, Q + u) 对\n",
    "        action_values = [(action, node.get_value(c_puct=5.0)) for action, node in actions.items()]\n",
    "\n",
    "        # Step 2: 计算所有 (Q + u) 的 softmax 概率\n",
    "        values = np.array([value for _, value in action_values])\n",
    "        exp_values = np.exp(values - np.max(values))  # 稳定的 softmax 计算\n",
    "        probabilities = exp_values / np.sum(exp_values)\n",
    "\n",
    "        # Step 3: 生成结果数组\n",
    "        action_probs = [(action, prob) for (action, _), prob in zip(action_values, probabilities)]\n",
    "        \n",
    "        state = mcts.board_to_tensor(board, current_player, last_move).squeeze(0).detach().cpu().numpy()\n",
    "\n",
    "        # Make the move\n",
    "        board = mcts.make_move(board, move, current_player)\n",
    "\n",
    "        # Store state and policy\n",
    "#         state = np.zeros((4, board_size, board_size))\n",
    "\n",
    "#         # 当前玩家的棋子位置\n",
    "#         for x in range(board_size):\n",
    "#             for y in range(board_size):\n",
    "#                 if board[x][y] == current_player:\n",
    "#                     state[0][x][y] = 1.0\n",
    "#                 elif board[x][y] != '.':  # 对手的棋子位置\n",
    "#                     state[1][x][y] = 1.0\n",
    "\n",
    "#         # 最近一次落子的位置\n",
    "#         if last_move is not None:\n",
    "#             state[2][last_move[0]][last_move[1]] = 1.0\n",
    "\n",
    "#         # 当前轮到谁下棋\n",
    "#         if current_player == 'O':  # 如果是偶数回合，轮到白棋\n",
    "#             state[3][:, :] = 1.0\n",
    "\n",
    "        # 更新 last_move\n",
    "        last_move = move\n",
    "\n",
    "        # 转换动作概率\n",
    "        action_probs_np = np.zeros((board_size, board_size))\n",
    "        for (x, y), prob in action_probs:\n",
    "            action_probs_np[x, y] = prob\n",
    "\n",
    "        # 检查胜利条件\n",
    "        if mcts.check_winner(board, current_player):\n",
    "            winner = current_player\n",
    "            game_data.append([state, action_probs_np, 1 if winner == 'X' else -1])\n",
    "            break\n",
    "\n",
    "        # 检查平局\n",
    "        if not mcts.get_legal_moves(board):\n",
    "            winner = None  # Draw\n",
    "            game_data.append([state, action_probs_np, 0])\n",
    "            break\n",
    "\n",
    "        # 切换玩家\n",
    "        current_player = 'O' if current_player == 'X' else 'X'\n",
    "\n",
    "    return game_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "qi-k2QvkfIsv",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 106,
     "status": "ok",
     "timestamp": 1733614684667,
     "user": {
      "displayName": "Siyi Wu",
      "userId": "06196688456534608936"
     },
     "user_tz": 360
    },
    "id": "qi-k2QvkfIsv",
    "outputId": "a9010201-2a2d-4fc0-dcbd-47b1f849db96"
   },
   "outputs": [],
   "source": [
    "def compute_softmax_probabilities(children):\n",
    "    # Step 1: 提取所有 (action, value_sum) 对\n",
    "    action_values = [(action, node.value_sum) for action, node in children.items()]\n",
    "\n",
    "    # Step 2: 计算所有 value_sum 的 softmax 概率\n",
    "    values = np.array([value_sum for _, value_sum in action_values])\n",
    "    exp_values = np.exp(values - np.max(values))\n",
    "    probabilities = exp_values / np.sum(exp_values)\n",
    "\n",
    "    # Step 3: 生成结果数组\n",
    "    result = [(action, prob) for (action, _), prob in zip(action_values, probabilities)]\n",
    "    return result\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d531a64b",
   "metadata": {
    "executionInfo": {
     "elapsed": 148,
     "status": "ok",
     "timestamp": 1733701435807,
     "user": {
      "displayName": "Siyi Wu",
      "userId": "06196688456534608936"
     },
     "user_tz": 360
    },
    "id": "d531a64b"
   },
   "outputs": [],
   "source": [
    "def train_alphazero(model, board_size, iterations=100, games_per_iteration=10, \n",
    "                    batch_size=32, mcts_simulations=100, alpha=0.5, l2_lambda=1e-4, entropy_alpha=1e-3):\n",
    "    \"\"\"Train AlphaZero model\"\"\"\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    print(f\"Using device: {device}\")\n",
    "\n",
    "    # Move model to GPU if available\n",
    "    model = model.to(device)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.002)\n",
    "    replay_buffer = deque(maxlen=10000)  # Replay buffer to store training data\n",
    "    loss_fn_policy = nn.CrossEntropyLoss()\n",
    "    loss_fn_value = nn.MSELoss()\n",
    "\n",
    "    policy_loss_list = []\n",
    "    value_loss_list = []\n",
    "\n",
    "    for iteration in range(iterations):\n",
    "\n",
    "        # Generate self-play data\n",
    "        for _ in range(games_per_iteration):\n",
    "\n",
    "            game_data = self_play_game(model, board_size, mcts_simulations)\n",
    "            #print(game_data)\n",
    "            replay_buffer.extend(game_data)\n",
    "        \n",
    "        #print(len(replay_buffer))\n",
    "        # Sample a batch from replay buffer\n",
    "        if len(replay_buffer) < batch_size:\n",
    "            continue\n",
    "\n",
    "        batch = random.sample(replay_buffer, batch_size)\n",
    "        states, policies, values = zip(*batch)\n",
    "\n",
    "        # Move data to GPU\n",
    "        states = torch.tensor(np.stack(states), dtype=torch.float32).to(device)\n",
    "        policies = torch.tensor(np.stack(policies), dtype=torch.float32).view(batch_size, \n",
    "                                                        board_size * board_size).to(device)\n",
    "        values = torch.tensor(values, dtype=torch.float32).view(-1, 1).to(device)\n",
    "\n",
    "        # Forward pass\n",
    "        pred_policies, pred_values = model(states)\n",
    "\n",
    "        # Compute losses\n",
    "        policy_loss = loss_fn_policy(pred_policies, policies)\n",
    "        value_loss = loss_fn_value(pred_values, values)\n",
    "\n",
    "        l2_reg = sum(param.pow(2).sum() for param in model.parameters())\n",
    "        #entropy = -torch.sum(pred_policies * torch.log(pred_policies + 1e-8), dim=1).mean()\n",
    "\n",
    "        loss = (policy_loss * alpha + value_loss * (1 - alpha)\n",
    "                + l2_lambda)\n",
    "\n",
    "        # Backward pass and optimization\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        policy_loss_list.append(policy_loss.item())\n",
    "        value_loss_list.append(value_loss.item())\n",
    "\n",
    "        print(f\"Iteration {iteration + 1}/{iterations}\")\n",
    "        print(f\"Policy Loss: {policy_loss.item():.4f}, Value Loss: {value_loss.item():.4f}\")\n",
    "\n",
    "    # Save model weights\n",
    "    torch.save(model.state_dict(), \"alphazero_weights.pth\")\n",
    "    print(\"Training complete. Weights saved to 'alphazero_weights.pth'.\")\n",
    "\n",
    "    return policy_loss_list, value_loss_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "Y0ZrFDw7iblB",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 628229,
     "status": "ok",
     "timestamp": 1733702079186,
     "user": {
      "displayName": "Siyi Wu",
      "userId": "06196688456534608936"
     },
     "user_tz": 360
    },
    "id": "Y0ZrFDw7iblB",
    "outputId": "9da28a17-622b-4058-8bff-9520f6c32ad1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n",
      "Iteration 4/2000\n",
      "Policy Loss: 3.9260, Value Loss: 0.9793\n",
      "Iteration 5/2000\n",
      "Policy Loss: 3.8827, Value Loss: 0.9624\n",
      "Iteration 6/2000\n",
      "Policy Loss: 3.8612, Value Loss: 0.9456\n",
      "Iteration 7/2000\n",
      "Policy Loss: 3.7873, Value Loss: 0.9293\n",
      "Iteration 8/2000\n",
      "Policy Loss: 3.6960, Value Loss: 0.9409\n",
      "Iteration 9/2000\n",
      "Policy Loss: 3.5369, Value Loss: 0.9321\n",
      "Iteration 10/2000\n",
      "Policy Loss: 3.1771, Value Loss: 0.8652\n",
      "Iteration 11/2000\n",
      "Policy Loss: 2.9392, Value Loss: 0.6914\n",
      "Iteration 12/2000\n",
      "Policy Loss: 3.5882, Value Loss: 0.4920\n",
      "Iteration 13/2000\n",
      "Policy Loss: 3.2989, Value Loss: 0.5201\n",
      "Iteration 14/2000\n",
      "Policy Loss: 3.2554, Value Loss: 0.8188\n",
      "Iteration 15/2000\n",
      "Policy Loss: 2.8203, Value Loss: 0.6447\n",
      "Iteration 16/2000\n",
      "Policy Loss: 3.1837, Value Loss: 0.9550\n",
      "Iteration 17/2000\n",
      "Policy Loss: 3.2630, Value Loss: 0.6131\n",
      "Iteration 18/2000\n",
      "Policy Loss: 3.2076, Value Loss: 0.4540\n",
      "Iteration 19/2000\n",
      "Policy Loss: 2.9703, Value Loss: 0.4296\n",
      "Iteration 20/2000\n",
      "Policy Loss: 2.6618, Value Loss: 0.3909\n",
      "Iteration 21/2000\n",
      "Policy Loss: 3.2641, Value Loss: 0.3347\n",
      "Iteration 22/2000\n",
      "Policy Loss: 4.4075, Value Loss: 0.4408\n",
      "Iteration 23/2000\n",
      "Policy Loss: 3.3670, Value Loss: 0.6134\n",
      "Iteration 24/2000\n",
      "Policy Loss: 3.8220, Value Loss: 0.4677\n",
      "Iteration 25/2000\n",
      "Policy Loss: 3.3681, Value Loss: 0.4178\n",
      "Iteration 26/2000\n",
      "Policy Loss: 3.4497, Value Loss: 0.5420\n",
      "Iteration 27/2000\n",
      "Policy Loss: 3.5521, Value Loss: 0.7226\n",
      "Iteration 28/2000\n",
      "Policy Loss: 3.6841, Value Loss: 0.7461\n",
      "Iteration 29/2000\n",
      "Policy Loss: 3.0794, Value Loss: 0.3422\n",
      "Iteration 30/2000\n",
      "Policy Loss: 3.6793, Value Loss: 0.8024\n",
      "Iteration 31/2000\n",
      "Policy Loss: 3.5436, Value Loss: 0.6871\n",
      "Iteration 32/2000\n",
      "Policy Loss: 3.4497, Value Loss: 0.6353\n",
      "Iteration 33/2000\n",
      "Policy Loss: 3.7822, Value Loss: 0.6298\n",
      "Iteration 34/2000\n",
      "Policy Loss: 3.5551, Value Loss: 0.5627\n",
      "Iteration 35/2000\n",
      "Policy Loss: 3.3500, Value Loss: 0.6545\n",
      "Iteration 36/2000\n",
      "Policy Loss: 3.4129, Value Loss: 0.5747\n",
      "Iteration 37/2000\n",
      "Policy Loss: 3.2371, Value Loss: 0.6302\n",
      "Iteration 38/2000\n",
      "Policy Loss: 3.2043, Value Loss: 0.3189\n",
      "Iteration 39/2000\n",
      "Policy Loss: 3.3618, Value Loss: 0.5170\n",
      "Iteration 40/2000\n",
      "Policy Loss: 3.1588, Value Loss: 0.5571\n",
      "Iteration 41/2000\n",
      "Policy Loss: 2.7890, Value Loss: 0.3397\n",
      "Iteration 42/2000\n",
      "Policy Loss: 3.7159, Value Loss: 0.6794\n",
      "Iteration 43/2000\n",
      "Policy Loss: 2.5577, Value Loss: 0.6067\n",
      "Iteration 44/2000\n",
      "Policy Loss: 2.7664, Value Loss: 0.5498\n",
      "Iteration 45/2000\n",
      "Policy Loss: 3.3283, Value Loss: 0.5406\n",
      "Iteration 46/2000\n",
      "Policy Loss: 3.0434, Value Loss: 0.5313\n",
      "Iteration 47/2000\n",
      "Policy Loss: 2.6545, Value Loss: 0.4629\n",
      "Iteration 48/2000\n",
      "Policy Loss: 2.5652, Value Loss: 0.3944\n",
      "Iteration 49/2000\n",
      "Policy Loss: 3.0166, Value Loss: 0.3098\n",
      "Iteration 50/2000\n",
      "Policy Loss: 3.0286, Value Loss: 0.5447\n",
      "Iteration 51/2000\n",
      "Policy Loss: 2.8381, Value Loss: 0.5702\n",
      "Iteration 52/2000\n",
      "Policy Loss: 2.6208, Value Loss: 0.3674\n",
      "Iteration 53/2000\n",
      "Policy Loss: 2.9230, Value Loss: 0.5171\n",
      "Iteration 54/2000\n",
      "Policy Loss: 2.7391, Value Loss: 0.6065\n",
      "Iteration 55/2000\n",
      "Policy Loss: 3.2304, Value Loss: 0.5262\n",
      "Iteration 56/2000\n",
      "Policy Loss: 2.4509, Value Loss: 0.5072\n",
      "Iteration 57/2000\n",
      "Policy Loss: 3.3652, Value Loss: 0.6400\n",
      "Iteration 58/2000\n",
      "Policy Loss: 2.6470, Value Loss: 0.3689\n",
      "Iteration 59/2000\n",
      "Policy Loss: 3.7905, Value Loss: 0.6750\n",
      "Iteration 60/2000\n",
      "Policy Loss: 2.8598, Value Loss: 0.4130\n",
      "Iteration 61/2000\n",
      "Policy Loss: 2.6468, Value Loss: 0.5641\n",
      "Iteration 62/2000\n",
      "Policy Loss: 2.9692, Value Loss: 0.4694\n",
      "Iteration 63/2000\n",
      "Policy Loss: 2.2559, Value Loss: 0.3120\n",
      "Iteration 64/2000\n",
      "Policy Loss: 2.2099, Value Loss: 0.4308\n",
      "Iteration 65/2000\n",
      "Policy Loss: 2.8738, Value Loss: 0.5406\n",
      "Iteration 66/2000\n",
      "Policy Loss: 2.8893, Value Loss: 0.3778\n",
      "Iteration 67/2000\n",
      "Policy Loss: 1.9151, Value Loss: 0.3253\n",
      "Iteration 68/2000\n",
      "Policy Loss: 2.6782, Value Loss: 0.4964\n",
      "Iteration 69/2000\n",
      "Policy Loss: 3.2711, Value Loss: 0.4566\n",
      "Iteration 70/2000\n",
      "Policy Loss: 3.5590, Value Loss: 0.4096\n",
      "Iteration 71/2000\n",
      "Policy Loss: 3.1638, Value Loss: 0.5616\n",
      "Iteration 72/2000\n",
      "Policy Loss: 2.7695, Value Loss: 0.3516\n",
      "Iteration 73/2000\n",
      "Policy Loss: 1.7210, Value Loss: 0.2313\n",
      "Iteration 74/2000\n",
      "Policy Loss: 1.9818, Value Loss: 0.2422\n",
      "Iteration 75/2000\n",
      "Policy Loss: 1.9481, Value Loss: 0.1972\n",
      "Iteration 76/2000\n",
      "Policy Loss: 1.6348, Value Loss: 0.0617\n",
      "Iteration 77/2000\n",
      "Policy Loss: 2.2368, Value Loss: 0.3096\n",
      "Iteration 78/2000\n",
      "Policy Loss: 2.5792, Value Loss: 0.4928\n",
      "Iteration 79/2000\n",
      "Policy Loss: 1.7193, Value Loss: 0.2671\n",
      "Iteration 80/2000\n",
      "Policy Loss: 1.9925, Value Loss: 0.3570\n",
      "Iteration 81/2000\n",
      "Policy Loss: 1.9751, Value Loss: 0.2627\n",
      "Iteration 82/2000\n",
      "Policy Loss: 2.1516, Value Loss: 0.3297\n",
      "Iteration 83/2000\n",
      "Policy Loss: 2.2114, Value Loss: 0.3773\n",
      "Iteration 84/2000\n",
      "Policy Loss: 2.7466, Value Loss: 0.3666\n",
      "Iteration 85/2000\n",
      "Policy Loss: 1.9168, Value Loss: 0.2472\n",
      "Iteration 86/2000\n",
      "Policy Loss: 1.8948, Value Loss: 0.2993\n",
      "Iteration 87/2000\n",
      "Policy Loss: 1.0822, Value Loss: 0.2509\n",
      "Iteration 88/2000\n",
      "Policy Loss: 2.3363, Value Loss: 0.3723\n",
      "Iteration 89/2000\n",
      "Policy Loss: 1.6820, Value Loss: 0.3826\n",
      "Iteration 90/2000\n",
      "Policy Loss: 1.1503, Value Loss: 0.2858\n",
      "Iteration 91/2000\n",
      "Policy Loss: 1.8860, Value Loss: 0.2902\n",
      "Iteration 92/2000\n",
      "Policy Loss: 1.6625, Value Loss: 0.2950\n",
      "Iteration 93/2000\n",
      "Policy Loss: 1.7027, Value Loss: 0.2684\n",
      "Iteration 94/2000\n",
      "Policy Loss: 0.8852, Value Loss: 0.2015\n",
      "Iteration 95/2000\n",
      "Policy Loss: 1.2711, Value Loss: 0.2253\n",
      "Iteration 96/2000\n",
      "Policy Loss: 1.7724, Value Loss: 0.2119\n",
      "Iteration 97/2000\n",
      "Policy Loss: 2.3182, Value Loss: 0.2236\n",
      "Iteration 98/2000\n",
      "Policy Loss: 1.3719, Value Loss: 0.1539\n",
      "Iteration 99/2000\n",
      "Policy Loss: 1.8033, Value Loss: 0.2187\n",
      "Iteration 100/2000\n",
      "Policy Loss: 1.4459, Value Loss: 0.1460\n",
      "Iteration 101/2000\n",
      "Policy Loss: 1.2609, Value Loss: 0.0921\n",
      "Iteration 102/2000\n",
      "Policy Loss: 1.2571, Value Loss: 0.1169\n",
      "Iteration 103/2000\n",
      "Policy Loss: 1.0720, Value Loss: 0.1136\n",
      "Iteration 104/2000\n",
      "Policy Loss: 0.7646, Value Loss: 0.0659\n",
      "Iteration 105/2000\n",
      "Policy Loss: 0.6292, Value Loss: 0.0816\n",
      "Iteration 106/2000\n",
      "Policy Loss: 0.9527, Value Loss: 0.1246\n",
      "Iteration 107/2000\n",
      "Policy Loss: 0.3816, Value Loss: 0.0507\n",
      "Iteration 108/2000\n",
      "Policy Loss: 1.2998, Value Loss: 0.0520\n",
      "Iteration 109/2000\n",
      "Policy Loss: 0.6649, Value Loss: 0.0269\n",
      "Iteration 110/2000\n",
      "Policy Loss: 0.6593, Value Loss: 0.0851\n",
      "Iteration 111/2000\n",
      "Policy Loss: 0.8980, Value Loss: 0.0768\n",
      "Iteration 112/2000\n",
      "Policy Loss: 1.0703, Value Loss: 0.0709\n",
      "Iteration 113/2000\n",
      "Policy Loss: 0.7260, Value Loss: 0.0204\n",
      "Iteration 114/2000\n",
      "Policy Loss: 0.9906, Value Loss: 0.0594\n",
      "Iteration 115/2000\n",
      "Policy Loss: 1.0235, Value Loss: 0.1590\n",
      "Iteration 116/2000\n",
      "Policy Loss: 0.7388, Value Loss: 0.0640\n",
      "Iteration 117/2000\n",
      "Policy Loss: 0.4816, Value Loss: 0.0150\n",
      "Iteration 118/2000\n",
      "Policy Loss: 0.9795, Value Loss: 0.0108\n",
      "Iteration 119/2000\n",
      "Policy Loss: 0.5499, Value Loss: 0.0079\n",
      "Iteration 120/2000\n",
      "Policy Loss: 0.5106, Value Loss: 0.2321\n",
      "Iteration 121/2000\n",
      "Policy Loss: 0.4094, Value Loss: 0.1080\n",
      "Iteration 122/2000\n",
      "Policy Loss: 0.7761, Value Loss: 0.0430\n",
      "Iteration 123/2000\n",
      "Policy Loss: 0.4869, Value Loss: 0.0020\n",
      "Iteration 124/2000\n",
      "Policy Loss: 0.4471, Value Loss: 0.0864\n",
      "Iteration 125/2000\n",
      "Policy Loss: 0.3178, Value Loss: 0.1047\n",
      "Iteration 126/2000\n",
      "Policy Loss: 0.6298, Value Loss: 0.0805\n",
      "Iteration 127/2000\n",
      "Policy Loss: 0.6381, Value Loss: 0.0453\n",
      "Iteration 128/2000\n",
      "Policy Loss: 0.8982, Value Loss: 0.0432\n",
      "Iteration 129/2000\n",
      "Policy Loss: 1.4614, Value Loss: 0.0339\n",
      "Iteration 130/2000\n",
      "Policy Loss: 0.8642, Value Loss: 0.0218\n",
      "Iteration 131/2000\n",
      "Policy Loss: 0.5818, Value Loss: 0.0201\n",
      "Iteration 132/2000\n",
      "Policy Loss: 0.3524, Value Loss: 0.0835\n",
      "Iteration 133/2000\n",
      "Policy Loss: 0.7667, Value Loss: 0.0578\n",
      "Iteration 134/2000\n",
      "Policy Loss: 0.6574, Value Loss: 0.0593\n",
      "Iteration 135/2000\n",
      "Policy Loss: 0.3583, Value Loss: 0.0416\n",
      "Iteration 136/2000\n",
      "Policy Loss: 0.5177, Value Loss: 0.0738\n",
      "Iteration 137/2000\n",
      "Policy Loss: 0.3819, Value Loss: 0.0221\n",
      "Iteration 138/2000\n",
      "Policy Loss: 0.9483, Value Loss: 0.0853\n",
      "Iteration 139/2000\n",
      "Policy Loss: 1.3558, Value Loss: 0.0250\n",
      "Iteration 140/2000\n",
      "Policy Loss: 0.7844, Value Loss: 0.0727\n",
      "Iteration 141/2000\n",
      "Policy Loss: 0.4971, Value Loss: 0.0030\n",
      "Iteration 142/2000\n",
      "Policy Loss: 0.4817, Value Loss: 0.0567\n",
      "Iteration 143/2000\n",
      "Policy Loss: 0.9463, Value Loss: 0.0013\n",
      "Iteration 144/2000\n",
      "Policy Loss: 0.5053, Value Loss: 0.0905\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 145/2000\n",
      "Policy Loss: 0.4750, Value Loss: 0.0001\n",
      "Iteration 146/2000\n",
      "Policy Loss: 1.3037, Value Loss: 0.1234\n",
      "Iteration 147/2000\n",
      "Policy Loss: 0.8938, Value Loss: 0.1692\n",
      "Iteration 148/2000\n",
      "Policy Loss: 0.3487, Value Loss: 0.2092\n",
      "Iteration 149/2000\n",
      "Policy Loss: 0.3179, Value Loss: 0.0673\n",
      "Iteration 150/2000\n",
      "Policy Loss: 0.2519, Value Loss: 0.1217\n",
      "Iteration 151/2000\n",
      "Policy Loss: 0.7480, Value Loss: 0.0336\n",
      "Iteration 152/2000\n",
      "Policy Loss: 0.6775, Value Loss: 0.0076\n",
      "Iteration 153/2000\n",
      "Policy Loss: 0.5126, Value Loss: 0.0689\n",
      "Iteration 154/2000\n",
      "Policy Loss: 0.2815, Value Loss: 0.0005\n",
      "Iteration 155/2000\n",
      "Policy Loss: 0.6462, Value Loss: 0.0420\n",
      "Iteration 156/2000\n",
      "Policy Loss: 0.6537, Value Loss: 0.0410\n",
      "Iteration 157/2000\n",
      "Policy Loss: 0.4758, Value Loss: 0.0173\n",
      "Iteration 158/2000\n",
      "Policy Loss: 0.4744, Value Loss: 0.0088\n",
      "Iteration 159/2000\n",
      "Policy Loss: 0.3921, Value Loss: 0.0103\n",
      "Iteration 160/2000\n",
      "Policy Loss: 0.9765, Value Loss: 0.0008\n",
      "Iteration 161/2000\n",
      "Policy Loss: 0.5344, Value Loss: 0.0245\n",
      "Iteration 162/2000\n",
      "Policy Loss: 0.2793, Value Loss: 0.0052\n",
      "Iteration 163/2000\n",
      "Policy Loss: 0.3139, Value Loss: 0.0001\n",
      "Iteration 164/2000\n",
      "Policy Loss: 0.1479, Value Loss: 0.0002\n",
      "Iteration 165/2000\n",
      "Policy Loss: 0.5065, Value Loss: 0.0293\n",
      "Iteration 166/2000\n",
      "Policy Loss: 0.2105, Value Loss: 0.0026\n",
      "Iteration 167/2000\n",
      "Policy Loss: 0.6638, Value Loss: 0.0020\n",
      "Iteration 168/2000\n",
      "Policy Loss: 0.1249, Value Loss: 0.0007\n",
      "Iteration 169/2000\n",
      "Policy Loss: 1.0826, Value Loss: 0.0011\n",
      "Iteration 170/2000\n",
      "Policy Loss: 0.3637, Value Loss: 0.0056\n",
      "Iteration 171/2000\n",
      "Policy Loss: 0.1374, Value Loss: 0.0154\n",
      "Iteration 172/2000\n",
      "Policy Loss: 0.9115, Value Loss: 0.0191\n",
      "Iteration 173/2000\n",
      "Policy Loss: 0.3638, Value Loss: 0.0019\n",
      "Iteration 174/2000\n",
      "Policy Loss: 0.3687, Value Loss: 0.0007\n",
      "Iteration 175/2000\n",
      "Policy Loss: 0.1817, Value Loss: 0.0041\n",
      "Iteration 176/2000\n",
      "Policy Loss: 0.3665, Value Loss: 0.0267\n",
      "Iteration 177/2000\n",
      "Policy Loss: 0.3749, Value Loss: 0.0083\n",
      "Iteration 178/2000\n",
      "Policy Loss: 0.0660, Value Loss: 0.0047\n",
      "Iteration 179/2000\n",
      "Policy Loss: 0.1684, Value Loss: 0.0052\n",
      "Iteration 180/2000\n",
      "Policy Loss: 0.1289, Value Loss: 0.0000\n",
      "Iteration 181/2000\n",
      "Policy Loss: 0.3835, Value Loss: 0.0066\n",
      "Iteration 182/2000\n",
      "Policy Loss: 0.1135, Value Loss: 0.0036\n",
      "Iteration 183/2000\n",
      "Policy Loss: 0.0301, Value Loss: 0.0139\n",
      "Iteration 184/2000\n",
      "Policy Loss: 0.0147, Value Loss: 0.0029\n",
      "Iteration 185/2000\n",
      "Policy Loss: 0.0764, Value Loss: 0.0020\n",
      "Iteration 186/2000\n",
      "Policy Loss: 0.6953, Value Loss: 0.0074\n",
      "Iteration 187/2000\n",
      "Policy Loss: 0.6268, Value Loss: 0.0001\n",
      "Iteration 188/2000\n",
      "Policy Loss: 2.0613, Value Loss: 0.0023\n",
      "Iteration 189/2000\n",
      "Policy Loss: 0.0416, Value Loss: 0.0007\n",
      "Iteration 190/2000\n",
      "Policy Loss: 0.1595, Value Loss: 0.0023\n",
      "Iteration 191/2000\n",
      "Policy Loss: 0.7814, Value Loss: 0.0009\n",
      "Iteration 192/2000\n",
      "Policy Loss: 0.5662, Value Loss: 0.0064\n",
      "Iteration 193/2000\n",
      "Policy Loss: 0.8137, Value Loss: 0.0177\n",
      "Iteration 194/2000\n",
      "Policy Loss: 0.0934, Value Loss: 0.0032\n",
      "Iteration 195/2000\n",
      "Policy Loss: 0.2933, Value Loss: 0.0159\n",
      "Iteration 196/2000\n",
      "Policy Loss: 0.2675, Value Loss: 0.0022\n",
      "Iteration 197/2000\n",
      "Policy Loss: 0.0751, Value Loss: 0.0002\n",
      "Iteration 198/2000\n",
      "Policy Loss: 0.2097, Value Loss: 0.0108\n",
      "Iteration 199/2000\n",
      "Policy Loss: 0.6161, Value Loss: 0.0064\n",
      "Iteration 200/2000\n",
      "Policy Loss: 0.2678, Value Loss: 0.0010\n",
      "Iteration 201/2000\n",
      "Policy Loss: 0.8181, Value Loss: 0.0175\n",
      "Iteration 202/2000\n",
      "Policy Loss: 1.2001, Value Loss: 0.0233\n",
      "Iteration 203/2000\n",
      "Policy Loss: 0.3734, Value Loss: 0.0039\n",
      "Iteration 204/2000\n",
      "Policy Loss: 0.1970, Value Loss: 0.0006\n",
      "Iteration 205/2000\n",
      "Policy Loss: 0.6901, Value Loss: 0.0216\n",
      "Iteration 206/2000\n",
      "Policy Loss: 0.2110, Value Loss: 0.0004\n",
      "Iteration 207/2000\n",
      "Policy Loss: 0.1711, Value Loss: 0.0182\n",
      "Iteration 208/2000\n",
      "Policy Loss: 0.6569, Value Loss: 0.0076\n",
      "Iteration 209/2000\n",
      "Policy Loss: 0.4361, Value Loss: 0.0230\n",
      "Iteration 210/2000\n",
      "Policy Loss: 0.1582, Value Loss: 0.0888\n",
      "Iteration 211/2000\n",
      "Policy Loss: 0.3264, Value Loss: 0.0223\n",
      "Iteration 212/2000\n",
      "Policy Loss: 0.1441, Value Loss: 0.0074\n",
      "Iteration 213/2000\n",
      "Policy Loss: 0.3148, Value Loss: 0.0069\n",
      "Iteration 214/2000\n",
      "Policy Loss: 0.3107, Value Loss: 0.0026\n",
      "Iteration 215/2000\n",
      "Policy Loss: 0.1277, Value Loss: 0.0059\n",
      "Iteration 216/2000\n",
      "Policy Loss: 0.5000, Value Loss: 0.0029\n",
      "Iteration 217/2000\n",
      "Policy Loss: 0.0741, Value Loss: 0.0175\n",
      "Iteration 218/2000\n",
      "Policy Loss: 0.1153, Value Loss: 0.0079\n",
      "Iteration 219/2000\n",
      "Policy Loss: 0.1968, Value Loss: 0.0053\n",
      "Iteration 220/2000\n",
      "Policy Loss: 0.1406, Value Loss: 0.0138\n",
      "Iteration 221/2000\n",
      "Policy Loss: 0.6545, Value Loss: 0.0043\n",
      "Iteration 222/2000\n",
      "Policy Loss: 0.1780, Value Loss: 0.0003\n",
      "Iteration 223/2000\n",
      "Policy Loss: 0.4403, Value Loss: 0.0056\n",
      "Iteration 224/2000\n",
      "Policy Loss: 0.2599, Value Loss: 0.0010\n",
      "Iteration 225/2000\n",
      "Policy Loss: 0.3793, Value Loss: 0.0007\n",
      "Iteration 226/2000\n",
      "Policy Loss: 0.5135, Value Loss: 0.0016\n",
      "Iteration 227/2000\n",
      "Policy Loss: 0.0364, Value Loss: 0.0018\n",
      "Iteration 228/2000\n",
      "Policy Loss: 0.2448, Value Loss: 0.0062\n",
      "Iteration 229/2000\n",
      "Policy Loss: 0.2395, Value Loss: 0.0009\n",
      "Iteration 230/2000\n",
      "Policy Loss: 0.1972, Value Loss: 0.0001\n",
      "Iteration 231/2000\n",
      "Policy Loss: 0.0751, Value Loss: 0.0014\n",
      "Iteration 232/2000\n",
      "Policy Loss: 0.2712, Value Loss: 0.0007\n",
      "Iteration 233/2000\n",
      "Policy Loss: 0.1543, Value Loss: 0.0072\n",
      "Iteration 234/2000\n",
      "Policy Loss: 0.1240, Value Loss: 0.0092\n",
      "Iteration 235/2000\n",
      "Policy Loss: 0.1285, Value Loss: 0.0001\n",
      "Iteration 236/2000\n",
      "Policy Loss: 0.0182, Value Loss: 0.0018\n",
      "Iteration 237/2000\n",
      "Policy Loss: 0.1111, Value Loss: 0.0014\n",
      "Iteration 238/2000\n",
      "Policy Loss: 0.0619, Value Loss: 0.0002\n",
      "Iteration 239/2000\n",
      "Policy Loss: 0.1077, Value Loss: 0.0057\n",
      "Iteration 240/2000\n",
      "Policy Loss: 0.1231, Value Loss: 0.0003\n",
      "Iteration 241/2000\n",
      "Policy Loss: 0.0613, Value Loss: 0.0000\n",
      "Iteration 242/2000\n",
      "Policy Loss: 0.1521, Value Loss: 0.0000\n",
      "Iteration 243/2000\n",
      "Policy Loss: 0.0445, Value Loss: 0.0012\n",
      "Iteration 244/2000\n",
      "Policy Loss: 0.0763, Value Loss: 0.0040\n",
      "Iteration 245/2000\n",
      "Policy Loss: 0.0679, Value Loss: 0.0268\n",
      "Iteration 246/2000\n",
      "Policy Loss: 0.0474, Value Loss: 0.0065\n",
      "Iteration 247/2000\n",
      "Policy Loss: 0.4845, Value Loss: 0.0000\n",
      "Iteration 248/2000\n",
      "Policy Loss: 0.3317, Value Loss: 0.0026\n",
      "Iteration 249/2000\n",
      "Policy Loss: 0.0633, Value Loss: 0.0014\n",
      "Iteration 250/2000\n",
      "Policy Loss: 0.0248, Value Loss: 0.0002\n",
      "Iteration 251/2000\n",
      "Policy Loss: 0.1158, Value Loss: 0.0051\n",
      "Iteration 252/2000\n",
      "Policy Loss: 0.2164, Value Loss: 0.0003\n",
      "Iteration 253/2000\n",
      "Policy Loss: 0.0638, Value Loss: 0.0356\n",
      "Iteration 254/2000\n",
      "Policy Loss: 0.2322, Value Loss: 0.0003\n",
      "Iteration 255/2000\n",
      "Policy Loss: 0.1209, Value Loss: 0.0016\n",
      "Iteration 256/2000\n",
      "Policy Loss: 0.0957, Value Loss: 0.0000\n",
      "Iteration 257/2000\n",
      "Policy Loss: 0.0475, Value Loss: 0.0159\n",
      "Iteration 258/2000\n",
      "Policy Loss: 0.0814, Value Loss: 0.0062\n",
      "Iteration 259/2000\n",
      "Policy Loss: 0.1236, Value Loss: 0.0039\n",
      "Iteration 260/2000\n",
      "Policy Loss: 0.1257, Value Loss: 0.0007\n",
      "Iteration 261/2000\n",
      "Policy Loss: 0.0452, Value Loss: 0.0016\n",
      "Iteration 262/2000\n",
      "Policy Loss: 0.0712, Value Loss: 0.0011\n",
      "Iteration 263/2000\n",
      "Policy Loss: 0.0219, Value Loss: 0.0108\n",
      "Iteration 264/2000\n",
      "Policy Loss: 1.9054, Value Loss: 0.0222\n",
      "Iteration 265/2000\n",
      "Policy Loss: 0.0858, Value Loss: 0.0121\n",
      "Iteration 266/2000\n",
      "Policy Loss: 1.5079, Value Loss: 0.0145\n",
      "Iteration 267/2000\n",
      "Policy Loss: 0.0122, Value Loss: 0.0016\n",
      "Iteration 268/2000\n",
      "Policy Loss: 0.0261, Value Loss: 0.0003\n",
      "Iteration 269/2000\n",
      "Policy Loss: 0.1209, Value Loss: 0.0097\n",
      "Iteration 270/2000\n",
      "Policy Loss: 0.0451, Value Loss: 0.0092\n",
      "Iteration 271/2000\n",
      "Policy Loss: 1.3301, Value Loss: 0.0133\n",
      "Iteration 272/2000\n",
      "Policy Loss: 0.0571, Value Loss: 0.0093\n",
      "Iteration 273/2000\n",
      "Policy Loss: 0.1088, Value Loss: 0.0015\n",
      "Iteration 274/2000\n",
      "Policy Loss: 0.2307, Value Loss: 0.0151\n",
      "Iteration 275/2000\n",
      "Policy Loss: 0.0929, Value Loss: 0.0001\n",
      "Iteration 276/2000\n",
      "Policy Loss: 0.8584, Value Loss: 0.0041\n",
      "Iteration 277/2000\n",
      "Policy Loss: 0.0397, Value Loss: 0.0018\n",
      "Iteration 278/2000\n",
      "Policy Loss: 0.0842, Value Loss: 0.0017\n",
      "Iteration 279/2000\n",
      "Policy Loss: 0.0545, Value Loss: 0.0007\n",
      "Iteration 280/2000\n",
      "Policy Loss: 0.0773, Value Loss: 0.0015\n",
      "Iteration 281/2000\n",
      "Policy Loss: 0.0794, Value Loss: 0.0001\n",
      "Iteration 282/2000\n",
      "Policy Loss: 0.0936, Value Loss: 0.0004\n",
      "Iteration 283/2000\n",
      "Policy Loss: 0.1169, Value Loss: 0.0015\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 284/2000\n",
      "Policy Loss: 0.2489, Value Loss: 0.0005\n",
      "Iteration 285/2000\n",
      "Policy Loss: 0.0696, Value Loss: 0.0016\n",
      "Iteration 286/2000\n",
      "Policy Loss: 0.0706, Value Loss: 0.0025\n",
      "Iteration 287/2000\n",
      "Policy Loss: 0.0824, Value Loss: 0.0008\n",
      "Iteration 288/2000\n",
      "Policy Loss: 0.0938, Value Loss: 0.0006\n",
      "Iteration 289/2000\n",
      "Policy Loss: 0.1386, Value Loss: 0.0001\n",
      "Iteration 290/2000\n",
      "Policy Loss: 0.4102, Value Loss: 0.0000\n",
      "Iteration 291/2000\n",
      "Policy Loss: 0.1207, Value Loss: 0.0002\n",
      "Iteration 292/2000\n",
      "Policy Loss: 0.3827, Value Loss: 0.0001\n",
      "Iteration 293/2000\n",
      "Policy Loss: 0.0199, Value Loss: 0.0194\n",
      "Iteration 294/2000\n",
      "Policy Loss: 0.0559, Value Loss: 0.0109\n",
      "Iteration 295/2000\n",
      "Policy Loss: 0.0296, Value Loss: 0.0029\n",
      "Iteration 296/2000\n",
      "Policy Loss: 0.1701, Value Loss: 0.0184\n",
      "Iteration 297/2000\n",
      "Policy Loss: 0.1626, Value Loss: 0.0003\n",
      "Iteration 298/2000\n",
      "Policy Loss: 0.0782, Value Loss: 0.0002\n",
      "Iteration 299/2000\n",
      "Policy Loss: 0.0587, Value Loss: 0.0016\n",
      "Iteration 300/2000\n",
      "Policy Loss: 0.1971, Value Loss: 0.0159\n",
      "Iteration 301/2000\n",
      "Policy Loss: 0.1088, Value Loss: 0.0327\n",
      "Iteration 302/2000\n",
      "Policy Loss: 0.1472, Value Loss: 0.0153\n",
      "Iteration 303/2000\n",
      "Policy Loss: 0.0164, Value Loss: 0.0000\n",
      "Iteration 304/2000\n",
      "Policy Loss: 0.0165, Value Loss: 0.0003\n",
      "Iteration 305/2000\n",
      "Policy Loss: 0.0205, Value Loss: 0.0080\n",
      "Iteration 306/2000\n",
      "Policy Loss: 0.3476, Value Loss: 0.0040\n",
      "Iteration 307/2000\n",
      "Policy Loss: 0.0207, Value Loss: 0.0056\n",
      "Iteration 308/2000\n",
      "Policy Loss: 0.0256, Value Loss: 0.0068\n",
      "Iteration 309/2000\n",
      "Policy Loss: 0.1422, Value Loss: 0.0055\n",
      "Iteration 310/2000\n",
      "Policy Loss: 0.0199, Value Loss: 0.0001\n",
      "Iteration 311/2000\n",
      "Policy Loss: 0.1558, Value Loss: 0.0283\n",
      "Iteration 312/2000\n",
      "Policy Loss: 0.0042, Value Loss: 0.0020\n",
      "Iteration 313/2000\n",
      "Policy Loss: 0.0116, Value Loss: 0.0141\n",
      "Iteration 314/2000\n",
      "Policy Loss: 0.1500, Value Loss: 0.0007\n",
      "Iteration 315/2000\n",
      "Policy Loss: 0.0227, Value Loss: 0.0030\n",
      "Iteration 316/2000\n",
      "Policy Loss: 0.0068, Value Loss: 0.0018\n",
      "Iteration 317/2000\n",
      "Policy Loss: 0.0234, Value Loss: 0.0207\n",
      "Iteration 318/2000\n",
      "Policy Loss: 0.0650, Value Loss: 0.0023\n",
      "Iteration 319/2000\n",
      "Policy Loss: 0.0071, Value Loss: 0.0023\n",
      "Iteration 320/2000\n",
      "Policy Loss: 0.0047, Value Loss: 0.0005\n",
      "Iteration 321/2000\n",
      "Policy Loss: 0.0093, Value Loss: 0.0002\n",
      "Iteration 322/2000\n",
      "Policy Loss: 0.8591, Value Loss: 0.0024\n",
      "Iteration 323/2000\n",
      "Policy Loss: 0.0133, Value Loss: 0.0018\n",
      "Iteration 324/2000\n",
      "Policy Loss: 0.0228, Value Loss: 0.0003\n",
      "Iteration 325/2000\n",
      "Policy Loss: 0.0588, Value Loss: 0.0001\n",
      "Iteration 326/2000\n",
      "Policy Loss: 0.0065, Value Loss: 0.0001\n",
      "Iteration 327/2000\n",
      "Policy Loss: 0.0171, Value Loss: 0.0007\n",
      "Iteration 328/2000\n",
      "Policy Loss: 0.0059, Value Loss: 0.0000\n",
      "Iteration 329/2000\n",
      "Policy Loss: 0.0580, Value Loss: 0.0004\n",
      "Iteration 330/2000\n",
      "Policy Loss: 0.0468, Value Loss: 0.0052\n",
      "Iteration 331/2000\n",
      "Policy Loss: 0.0354, Value Loss: 0.0000\n",
      "Iteration 332/2000\n",
      "Policy Loss: 0.0094, Value Loss: 0.0007\n",
      "Iteration 333/2000\n",
      "Policy Loss: 0.0078, Value Loss: 0.0011\n",
      "Iteration 334/2000\n",
      "Policy Loss: 0.0093, Value Loss: 0.0034\n",
      "Iteration 335/2000\n",
      "Policy Loss: 0.0017, Value Loss: 0.0002\n",
      "Iteration 336/2000\n",
      "Policy Loss: 0.0019, Value Loss: 0.0021\n",
      "Iteration 337/2000\n",
      "Policy Loss: 0.0140, Value Loss: 0.0000\n",
      "Iteration 338/2000\n",
      "Policy Loss: 1.0249, Value Loss: 0.0008\n",
      "Iteration 339/2000\n",
      "Policy Loss: 0.0342, Value Loss: 0.0037\n",
      "Iteration 340/2000\n",
      "Policy Loss: 0.1174, Value Loss: 0.0020\n",
      "Iteration 341/2000\n",
      "Policy Loss: 0.0253, Value Loss: 0.0104\n",
      "Iteration 342/2000\n",
      "Policy Loss: 0.1388, Value Loss: 0.0056\n",
      "Iteration 343/2000\n",
      "Policy Loss: 0.4624, Value Loss: 0.0055\n",
      "Iteration 344/2000\n",
      "Policy Loss: 0.0871, Value Loss: 0.0001\n",
      "Iteration 345/2000\n",
      "Policy Loss: 0.0863, Value Loss: 0.0012\n",
      "Iteration 346/2000\n",
      "Policy Loss: 0.1439, Value Loss: 0.0025\n",
      "Iteration 347/2000\n",
      "Policy Loss: 0.0141, Value Loss: 0.0010\n",
      "Iteration 348/2000\n",
      "Policy Loss: 0.0251, Value Loss: 0.0017\n",
      "Iteration 349/2000\n",
      "Policy Loss: 0.1378, Value Loss: 0.0031\n",
      "Iteration 350/2000\n",
      "Policy Loss: 0.0242, Value Loss: 0.0001\n",
      "Iteration 351/2000\n",
      "Policy Loss: 0.2364, Value Loss: 0.0012\n",
      "Iteration 352/2000\n",
      "Policy Loss: 0.4180, Value Loss: 0.0001\n",
      "Iteration 353/2000\n",
      "Policy Loss: 0.3228, Value Loss: 0.0007\n",
      "Iteration 354/2000\n",
      "Policy Loss: 0.0561, Value Loss: 0.0001\n",
      "Iteration 355/2000\n",
      "Policy Loss: 0.4435, Value Loss: 0.0001\n",
      "Iteration 356/2000\n",
      "Policy Loss: 0.0507, Value Loss: 0.0001\n",
      "Iteration 357/2000\n",
      "Policy Loss: 0.0222, Value Loss: 0.0002\n",
      "Iteration 358/2000\n",
      "Policy Loss: 0.0188, Value Loss: 0.0035\n",
      "Iteration 359/2000\n",
      "Policy Loss: 0.0631, Value Loss: 0.0009\n",
      "Iteration 360/2000\n",
      "Policy Loss: 0.0552, Value Loss: 0.0018\n",
      "Iteration 361/2000\n",
      "Policy Loss: 0.0652, Value Loss: 0.0014\n",
      "Iteration 362/2000\n",
      "Policy Loss: 0.0591, Value Loss: 0.0002\n",
      "Iteration 363/2000\n",
      "Policy Loss: 0.1000, Value Loss: 0.0043\n",
      "Iteration 364/2000\n",
      "Policy Loss: 0.0531, Value Loss: 0.0020\n",
      "Iteration 365/2000\n",
      "Policy Loss: 0.1761, Value Loss: 0.0006\n",
      "Iteration 366/2000\n",
      "Policy Loss: 0.2792, Value Loss: 0.0025\n",
      "Iteration 367/2000\n",
      "Policy Loss: 0.0307, Value Loss: 0.0002\n",
      "Iteration 368/2000\n",
      "Policy Loss: 0.0305, Value Loss: 0.0006\n",
      "Iteration 369/2000\n",
      "Policy Loss: 0.0654, Value Loss: 0.0008\n",
      "Iteration 370/2000\n",
      "Policy Loss: 0.0614, Value Loss: 0.0001\n",
      "Iteration 371/2000\n",
      "Policy Loss: 0.1596, Value Loss: 0.0001\n",
      "Iteration 372/2000\n",
      "Policy Loss: 0.2551, Value Loss: 0.0003\n",
      "Iteration 373/2000\n",
      "Policy Loss: 0.2161, Value Loss: 0.0002\n",
      "Iteration 374/2000\n",
      "Policy Loss: 0.0253, Value Loss: 0.0004\n",
      "Iteration 375/2000\n",
      "Policy Loss: 0.0609, Value Loss: 0.0048\n",
      "Iteration 376/2000\n",
      "Policy Loss: 0.1042, Value Loss: 0.0001\n",
      "Iteration 377/2000\n",
      "Policy Loss: 0.0186, Value Loss: 0.0020\n",
      "Iteration 378/2000\n",
      "Policy Loss: 0.1229, Value Loss: 0.0019\n",
      "Iteration 379/2000\n",
      "Policy Loss: 0.0173, Value Loss: 0.0000\n",
      "Iteration 380/2000\n",
      "Policy Loss: 0.0169, Value Loss: 0.0001\n",
      "Iteration 381/2000\n",
      "Policy Loss: 0.0084, Value Loss: 0.0018\n",
      "Iteration 382/2000\n",
      "Policy Loss: 0.0042, Value Loss: 0.0034\n",
      "Iteration 383/2000\n",
      "Policy Loss: 0.3734, Value Loss: 0.0004\n",
      "Iteration 384/2000\n",
      "Policy Loss: 0.0671, Value Loss: 0.0002\n",
      "Iteration 385/2000\n",
      "Policy Loss: 0.0256, Value Loss: 0.0000\n",
      "Iteration 386/2000\n",
      "Policy Loss: 0.0523, Value Loss: 0.0001\n",
      "Iteration 387/2000\n",
      "Policy Loss: 0.0063, Value Loss: 0.0027\n",
      "Iteration 388/2000\n",
      "Policy Loss: 0.0230, Value Loss: 0.0002\n",
      "Iteration 389/2000\n",
      "Policy Loss: 0.0405, Value Loss: 0.0003\n",
      "Iteration 390/2000\n",
      "Policy Loss: 0.0126, Value Loss: 0.0005\n",
      "Iteration 391/2000\n",
      "Policy Loss: 0.0259, Value Loss: 0.0001\n",
      "Iteration 392/2000\n",
      "Policy Loss: 0.0222, Value Loss: 0.0042\n",
      "Iteration 393/2000\n",
      "Policy Loss: 0.0248, Value Loss: 0.0001\n",
      "Iteration 394/2000\n",
      "Policy Loss: 0.0354, Value Loss: 0.0010\n",
      "Iteration 395/2000\n",
      "Policy Loss: 0.0215, Value Loss: 0.0009\n",
      "Iteration 396/2000\n",
      "Policy Loss: 0.0154, Value Loss: 0.0002\n",
      "Iteration 397/2000\n",
      "Policy Loss: 0.0202, Value Loss: 0.0001\n",
      "Iteration 398/2000\n",
      "Policy Loss: 0.2215, Value Loss: 0.0052\n",
      "Iteration 399/2000\n",
      "Policy Loss: 0.0052, Value Loss: 0.0000\n",
      "Iteration 400/2000\n",
      "Policy Loss: 0.0157, Value Loss: 0.0033\n",
      "Iteration 401/2000\n",
      "Policy Loss: 0.0023, Value Loss: 0.0009\n",
      "Iteration 402/2000\n",
      "Policy Loss: 0.0134, Value Loss: 0.0011\n",
      "Iteration 403/2000\n",
      "Policy Loss: 0.1084, Value Loss: 0.0000\n",
      "Iteration 404/2000\n",
      "Policy Loss: 0.0061, Value Loss: 0.0016\n",
      "Iteration 405/2000\n",
      "Policy Loss: 0.0131, Value Loss: 0.0011\n",
      "Iteration 406/2000\n",
      "Policy Loss: 0.0086, Value Loss: 0.0005\n",
      "Iteration 407/2000\n",
      "Policy Loss: 0.0126, Value Loss: 0.0000\n",
      "Iteration 408/2000\n",
      "Policy Loss: 0.2277, Value Loss: 0.0016\n",
      "Iteration 409/2000\n",
      "Policy Loss: 0.0263, Value Loss: 0.0002\n",
      "Iteration 410/2000\n",
      "Policy Loss: 0.0043, Value Loss: 0.0000\n",
      "Iteration 411/2000\n",
      "Policy Loss: 0.0043, Value Loss: 0.0008\n",
      "Iteration 412/2000\n",
      "Policy Loss: 0.0174, Value Loss: 0.0002\n",
      "Iteration 413/2000\n",
      "Policy Loss: 0.0065, Value Loss: 0.0000\n",
      "Iteration 414/2000\n",
      "Policy Loss: 0.0764, Value Loss: 0.0058\n",
      "Iteration 415/2000\n",
      "Policy Loss: 0.1431, Value Loss: 0.0006\n",
      "Iteration 416/2000\n",
      "Policy Loss: 0.0234, Value Loss: 0.0000\n",
      "Iteration 417/2000\n",
      "Policy Loss: 0.0062, Value Loss: 0.0033\n",
      "Iteration 418/2000\n",
      "Policy Loss: 0.0078, Value Loss: 0.0001\n",
      "Iteration 419/2000\n",
      "Policy Loss: 0.2231, Value Loss: 0.0000\n",
      "Iteration 420/2000\n",
      "Policy Loss: 0.0043, Value Loss: 0.0006\n",
      "Iteration 421/2000\n",
      "Policy Loss: 0.0108, Value Loss: 0.0009\n",
      "Iteration 422/2000\n",
      "Policy Loss: 0.0170, Value Loss: 0.0018\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 423/2000\n",
      "Policy Loss: 0.2315, Value Loss: 0.0014\n",
      "Iteration 424/2000\n",
      "Policy Loss: 0.0015, Value Loss: 0.0024\n",
      "Iteration 425/2000\n",
      "Policy Loss: 0.0201, Value Loss: 0.0006\n",
      "Iteration 426/2000\n",
      "Policy Loss: 0.0034, Value Loss: 0.0006\n",
      "Iteration 427/2000\n",
      "Policy Loss: 0.0174, Value Loss: 0.0000\n",
      "Iteration 428/2000\n",
      "Policy Loss: 0.0078, Value Loss: 0.0008\n",
      "Iteration 429/2000\n",
      "Policy Loss: 0.0176, Value Loss: 0.0003\n",
      "Iteration 430/2000\n",
      "Policy Loss: 0.1077, Value Loss: 0.0016\n",
      "Iteration 431/2000\n",
      "Policy Loss: 0.1474, Value Loss: 0.0006\n",
      "Iteration 432/2000\n",
      "Policy Loss: 0.0948, Value Loss: 0.0001\n",
      "Iteration 433/2000\n",
      "Policy Loss: 0.0183, Value Loss: 0.0000\n",
      "Iteration 434/2000\n",
      "Policy Loss: 0.0288, Value Loss: 0.0007\n",
      "Iteration 435/2000\n",
      "Policy Loss: 0.0080, Value Loss: 0.0003\n",
      "Iteration 436/2000\n",
      "Policy Loss: 0.0362, Value Loss: 0.0004\n",
      "Iteration 437/2000\n",
      "Policy Loss: 0.0059, Value Loss: 0.0002\n",
      "Iteration 438/2000\n",
      "Policy Loss: 0.6204, Value Loss: 0.0003\n",
      "Iteration 439/2000\n",
      "Policy Loss: 0.0085, Value Loss: 0.0003\n",
      "Iteration 440/2000\n",
      "Policy Loss: 0.1733, Value Loss: 0.0002\n",
      "Iteration 441/2000\n",
      "Policy Loss: 0.0918, Value Loss: 0.0000\n",
      "Iteration 442/2000\n",
      "Policy Loss: 0.0819, Value Loss: 0.0001\n",
      "Iteration 443/2000\n",
      "Policy Loss: 0.0072, Value Loss: 0.0000\n",
      "Iteration 444/2000\n",
      "Policy Loss: 0.0206, Value Loss: 0.0000\n",
      "Iteration 445/2000\n",
      "Policy Loss: 0.5452, Value Loss: 0.0000\n",
      "Iteration 446/2000\n",
      "Policy Loss: 0.1299, Value Loss: 0.0012\n",
      "Iteration 447/2000\n",
      "Policy Loss: 0.1753, Value Loss: 0.0013\n",
      "Iteration 448/2000\n",
      "Policy Loss: 0.0084, Value Loss: 0.0002\n",
      "Iteration 449/2000\n",
      "Policy Loss: 0.3061, Value Loss: 0.0000\n",
      "Iteration 450/2000\n",
      "Policy Loss: 0.0042, Value Loss: 0.0006\n",
      "Iteration 451/2000\n",
      "Policy Loss: 0.0136, Value Loss: 0.0000\n",
      "Iteration 452/2000\n",
      "Policy Loss: 0.1438, Value Loss: 0.0001\n",
      "Iteration 453/2000\n",
      "Policy Loss: 0.2182, Value Loss: 0.0000\n",
      "Iteration 454/2000\n",
      "Policy Loss: 0.0046, Value Loss: 0.0001\n",
      "Iteration 455/2000\n",
      "Policy Loss: 0.1058, Value Loss: 0.0001\n",
      "Iteration 456/2000\n",
      "Policy Loss: 0.1412, Value Loss: 0.0000\n",
      "Iteration 457/2000\n",
      "Policy Loss: 0.0054, Value Loss: 0.0003\n",
      "Iteration 458/2000\n",
      "Policy Loss: 0.0205, Value Loss: 0.0000\n",
      "Iteration 459/2000\n",
      "Policy Loss: 0.1057, Value Loss: 0.0000\n",
      "Iteration 460/2000\n",
      "Policy Loss: 0.1860, Value Loss: 0.0001\n",
      "Iteration 461/2000\n",
      "Policy Loss: 0.0113, Value Loss: 0.0001\n",
      "Iteration 462/2000\n",
      "Policy Loss: 0.0082, Value Loss: 0.0000\n",
      "Iteration 463/2000\n",
      "Policy Loss: 0.6102, Value Loss: 0.0000\n",
      "Iteration 464/2000\n",
      "Policy Loss: 0.1316, Value Loss: 0.0001\n",
      "Iteration 465/2000\n",
      "Policy Loss: 0.0960, Value Loss: 0.0109\n",
      "Iteration 466/2000\n",
      "Policy Loss: 0.0442, Value Loss: 0.0001\n",
      "Iteration 467/2000\n",
      "Policy Loss: 0.0605, Value Loss: 0.0000\n",
      "Iteration 468/2000\n",
      "Policy Loss: 0.0749, Value Loss: 0.0001\n",
      "Iteration 469/2000\n",
      "Policy Loss: 0.0410, Value Loss: 0.0002\n",
      "Iteration 470/2000\n",
      "Policy Loss: 0.0153, Value Loss: 0.0009\n",
      "Iteration 471/2000\n",
      "Policy Loss: 0.1454, Value Loss: 0.0001\n",
      "Iteration 472/2000\n",
      "Policy Loss: 0.1098, Value Loss: 0.0000\n",
      "Iteration 473/2000\n",
      "Policy Loss: 0.2981, Value Loss: 0.0000\n",
      "Iteration 474/2000\n",
      "Policy Loss: 0.1277, Value Loss: 0.0003\n",
      "Iteration 475/2000\n",
      "Policy Loss: 0.1674, Value Loss: 0.0003\n",
      "Iteration 476/2000\n",
      "Policy Loss: 0.0113, Value Loss: 0.0019\n",
      "Iteration 477/2000\n",
      "Policy Loss: 0.2675, Value Loss: 0.0000\n",
      "Iteration 478/2000\n",
      "Policy Loss: 0.1962, Value Loss: 0.0004\n",
      "Iteration 479/2000\n",
      "Policy Loss: 0.2934, Value Loss: 0.0004\n",
      "Iteration 480/2000\n",
      "Policy Loss: 0.0182, Value Loss: 0.0007\n",
      "Iteration 481/2000\n",
      "Policy Loss: 0.0143, Value Loss: 0.0000\n",
      "Iteration 482/2000\n",
      "Policy Loss: 0.0236, Value Loss: 0.0001\n",
      "Iteration 483/2000\n",
      "Policy Loss: 0.0493, Value Loss: 0.0001\n",
      "Iteration 484/2000\n",
      "Policy Loss: 0.1453, Value Loss: 0.0000\n",
      "Iteration 485/2000\n",
      "Policy Loss: 0.1540, Value Loss: 0.0014\n",
      "Iteration 486/2000\n",
      "Policy Loss: 0.1243, Value Loss: 0.0005\n",
      "Iteration 487/2000\n",
      "Policy Loss: 0.0309, Value Loss: 0.0009\n",
      "Iteration 488/2000\n",
      "Policy Loss: 0.0495, Value Loss: 0.0004\n",
      "Iteration 489/2000\n",
      "Policy Loss: 0.0304, Value Loss: 0.0004\n",
      "Iteration 490/2000\n",
      "Policy Loss: 0.0231, Value Loss: 0.0002\n",
      "Iteration 491/2000\n",
      "Policy Loss: 0.1360, Value Loss: 0.0002\n",
      "Iteration 492/2000\n",
      "Policy Loss: 0.0298, Value Loss: 0.0002\n",
      "Iteration 493/2000\n",
      "Policy Loss: 0.1493, Value Loss: 0.0009\n",
      "Iteration 494/2000\n",
      "Policy Loss: 0.0324, Value Loss: 0.0000\n",
      "Iteration 495/2000\n",
      "Policy Loss: 0.0162, Value Loss: 0.0013\n",
      "Iteration 496/2000\n",
      "Policy Loss: 0.0286, Value Loss: 0.0005\n",
      "Iteration 497/2000\n",
      "Policy Loss: 0.0585, Value Loss: 0.0013\n",
      "Iteration 498/2000\n",
      "Policy Loss: 0.1892, Value Loss: 0.0001\n",
      "Iteration 499/2000\n",
      "Policy Loss: 0.0046, Value Loss: 0.0001\n",
      "Iteration 500/2000\n",
      "Policy Loss: 0.0808, Value Loss: 0.0000\n",
      "Iteration 501/2000\n",
      "Policy Loss: 0.1172, Value Loss: 0.0006\n",
      "Iteration 502/2000\n",
      "Policy Loss: 0.0241, Value Loss: 0.0000\n",
      "Iteration 503/2000\n",
      "Policy Loss: 0.0220, Value Loss: 0.0004\n",
      "Iteration 504/2000\n",
      "Policy Loss: 0.0293, Value Loss: 0.0000\n",
      "Iteration 505/2000\n",
      "Policy Loss: 0.0088, Value Loss: 0.0001\n",
      "Iteration 506/2000\n",
      "Policy Loss: 0.0065, Value Loss: 0.0001\n",
      "Iteration 507/2000\n",
      "Policy Loss: 0.6330, Value Loss: 0.0014\n",
      "Iteration 508/2000\n",
      "Policy Loss: 0.0066, Value Loss: 0.0000\n",
      "Iteration 509/2000\n",
      "Policy Loss: 0.3564, Value Loss: 0.0000\n",
      "Iteration 510/2000\n",
      "Policy Loss: 0.1062, Value Loss: 0.0003\n",
      "Iteration 511/2000\n",
      "Policy Loss: 0.0094, Value Loss: 0.0000\n",
      "Iteration 512/2000\n",
      "Policy Loss: 0.0493, Value Loss: 0.0000\n",
      "Iteration 513/2000\n",
      "Policy Loss: 0.2491, Value Loss: 0.0001\n",
      "Iteration 514/2000\n",
      "Policy Loss: 0.0288, Value Loss: 0.0002\n",
      "Iteration 515/2000\n",
      "Policy Loss: 0.0251, Value Loss: 0.0002\n",
      "Iteration 516/2000\n",
      "Policy Loss: 0.0475, Value Loss: 0.0000\n",
      "Iteration 517/2000\n",
      "Policy Loss: 0.4961, Value Loss: 0.0000\n",
      "Iteration 518/2000\n",
      "Policy Loss: 0.0139, Value Loss: 0.0003\n",
      "Iteration 519/2000\n",
      "Policy Loss: 0.0289, Value Loss: 0.0019\n",
      "Iteration 520/2000\n",
      "Policy Loss: 0.8896, Value Loss: 0.0002\n",
      "Iteration 521/2000\n",
      "Policy Loss: 0.1287, Value Loss: 0.0001\n",
      "Iteration 522/2000\n",
      "Policy Loss: 0.0752, Value Loss: 0.0002\n",
      "Iteration 523/2000\n",
      "Policy Loss: 0.0067, Value Loss: 0.0000\n",
      "Iteration 524/2000\n",
      "Policy Loss: 0.0603, Value Loss: 0.0000\n",
      "Iteration 525/2000\n",
      "Policy Loss: 0.1065, Value Loss: 0.0022\n",
      "Iteration 526/2000\n",
      "Policy Loss: 0.1005, Value Loss: 0.0003\n",
      "Iteration 527/2000\n",
      "Policy Loss: 0.0127, Value Loss: 0.0000\n",
      "Iteration 528/2000\n",
      "Policy Loss: 0.0087, Value Loss: 0.0114\n",
      "Iteration 529/2000\n",
      "Policy Loss: 0.0894, Value Loss: 0.0009\n",
      "Iteration 530/2000\n",
      "Policy Loss: 0.0824, Value Loss: 0.0014\n",
      "Iteration 531/2000\n",
      "Policy Loss: 0.1058, Value Loss: 0.0000\n",
      "Iteration 532/2000\n",
      "Policy Loss: 0.1251, Value Loss: 0.0176\n",
      "Iteration 533/2000\n",
      "Policy Loss: 0.1271, Value Loss: 0.0000\n",
      "Iteration 534/2000\n",
      "Policy Loss: 0.0412, Value Loss: 0.0010\n",
      "Iteration 535/2000\n",
      "Policy Loss: 0.0504, Value Loss: 0.0005\n",
      "Iteration 536/2000\n",
      "Policy Loss: 0.0071, Value Loss: 0.0002\n",
      "Iteration 537/2000\n",
      "Policy Loss: 0.1487, Value Loss: 0.0014\n",
      "Iteration 538/2000\n",
      "Policy Loss: 1.6406, Value Loss: 0.0015\n",
      "Iteration 539/2000\n",
      "Policy Loss: 0.0433, Value Loss: 0.0177\n",
      "Iteration 540/2000\n",
      "Policy Loss: 0.0135, Value Loss: 0.0013\n",
      "Iteration 541/2000\n",
      "Policy Loss: 0.1776, Value Loss: 0.0032\n",
      "Iteration 542/2000\n",
      "Policy Loss: 0.0265, Value Loss: 0.0020\n",
      "Iteration 543/2000\n",
      "Policy Loss: 1.7821, Value Loss: 0.0824\n",
      "Iteration 544/2000\n",
      "Policy Loss: 0.2331, Value Loss: 0.0007\n",
      "Iteration 545/2000\n",
      "Policy Loss: 0.0159, Value Loss: 0.0001\n",
      "Iteration 546/2000\n",
      "Policy Loss: 0.2441, Value Loss: 0.0003\n",
      "Iteration 547/2000\n",
      "Policy Loss: 0.1090, Value Loss: 0.0000\n",
      "Iteration 548/2000\n",
      "Policy Loss: 0.0739, Value Loss: 0.0015\n",
      "Iteration 549/2000\n",
      "Policy Loss: 0.0824, Value Loss: 0.0044\n",
      "Iteration 550/2000\n",
      "Policy Loss: 0.5386, Value Loss: 0.0100\n",
      "Iteration 551/2000\n",
      "Policy Loss: 0.1088, Value Loss: 0.0000\n",
      "Iteration 552/2000\n",
      "Policy Loss: 0.0618, Value Loss: 0.0004\n",
      "Iteration 553/2000\n",
      "Policy Loss: 0.1624, Value Loss: 0.0022\n",
      "Iteration 554/2000\n",
      "Policy Loss: 0.0885, Value Loss: 0.0091\n",
      "Iteration 555/2000\n",
      "Policy Loss: 0.0496, Value Loss: 0.0108\n",
      "Iteration 556/2000\n",
      "Policy Loss: 0.0576, Value Loss: 0.0014\n",
      "Iteration 557/2000\n",
      "Policy Loss: 0.2088, Value Loss: 0.0003\n",
      "Iteration 558/2000\n",
      "Policy Loss: 0.0319, Value Loss: 0.0001\n",
      "Iteration 559/2000\n",
      "Policy Loss: 0.3790, Value Loss: 0.0316\n",
      "Iteration 560/2000\n",
      "Policy Loss: 0.0140, Value Loss: 0.0009\n",
      "Iteration 561/2000\n",
      "Policy Loss: 0.0155, Value Loss: 0.0155\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 562/2000\n",
      "Policy Loss: 0.1492, Value Loss: 0.0001\n",
      "Iteration 563/2000\n",
      "Policy Loss: 0.0270, Value Loss: 0.0000\n",
      "Iteration 564/2000\n",
      "Policy Loss: 0.2505, Value Loss: 0.0002\n",
      "Iteration 565/2000\n",
      "Policy Loss: 0.1116, Value Loss: 0.0008\n",
      "Iteration 566/2000\n",
      "Policy Loss: 0.0600, Value Loss: 0.0027\n",
      "Iteration 567/2000\n",
      "Policy Loss: 0.0832, Value Loss: 0.0000\n",
      "Iteration 568/2000\n",
      "Policy Loss: 0.0545, Value Loss: 0.0020\n",
      "Iteration 569/2000\n",
      "Policy Loss: 0.0764, Value Loss: 0.0009\n",
      "Iteration 570/2000\n",
      "Policy Loss: 0.1019, Value Loss: 0.0007\n",
      "Iteration 571/2000\n",
      "Policy Loss: 0.1237, Value Loss: 0.0003\n",
      "Iteration 572/2000\n",
      "Policy Loss: 0.0156, Value Loss: 0.0005\n",
      "Iteration 573/2000\n",
      "Policy Loss: 0.1740, Value Loss: 0.0136\n",
      "Iteration 574/2000\n",
      "Policy Loss: 0.1509, Value Loss: 0.0000\n",
      "Iteration 575/2000\n",
      "Policy Loss: 0.0069, Value Loss: 0.0003\n",
      "Iteration 576/2000\n",
      "Policy Loss: 0.0080, Value Loss: 0.0095\n",
      "Iteration 577/2000\n",
      "Policy Loss: 0.0408, Value Loss: 0.0003\n",
      "Iteration 578/2000\n",
      "Policy Loss: 0.0164, Value Loss: 0.0015\n",
      "Iteration 579/2000\n",
      "Policy Loss: 0.0154, Value Loss: 0.0000\n",
      "Iteration 580/2000\n",
      "Policy Loss: 0.0051, Value Loss: 0.0021\n",
      "Iteration 581/2000\n",
      "Policy Loss: 0.1566, Value Loss: 0.0009\n",
      "Iteration 582/2000\n",
      "Policy Loss: 0.0048, Value Loss: 0.0098\n",
      "Iteration 583/2000\n",
      "Policy Loss: 0.0089, Value Loss: 0.0011\n",
      "Iteration 584/2000\n",
      "Policy Loss: 0.1224, Value Loss: 0.0000\n",
      "Iteration 585/2000\n",
      "Policy Loss: 0.0957, Value Loss: 0.0002\n",
      "Iteration 586/2000\n",
      "Policy Loss: 0.0057, Value Loss: 0.0000\n",
      "Iteration 587/2000\n",
      "Policy Loss: 0.1011, Value Loss: 0.0001\n",
      "Iteration 588/2000\n",
      "Policy Loss: 0.0367, Value Loss: 0.0000\n",
      "Iteration 589/2000\n",
      "Policy Loss: 0.0054, Value Loss: 0.0000\n",
      "Iteration 590/2000\n",
      "Policy Loss: 0.0158, Value Loss: 0.0158\n",
      "Iteration 591/2000\n",
      "Policy Loss: 0.4162, Value Loss: 0.0002\n",
      "Iteration 592/2000\n",
      "Policy Loss: 0.4979, Value Loss: 0.0000\n",
      "Iteration 593/2000\n",
      "Policy Loss: 0.0021, Value Loss: 0.0000\n",
      "Iteration 594/2000\n",
      "Policy Loss: 0.0349, Value Loss: 0.0090\n",
      "Iteration 595/2000\n",
      "Policy Loss: 0.0096, Value Loss: 0.0000\n",
      "Iteration 596/2000\n",
      "Policy Loss: 0.3931, Value Loss: 0.0001\n",
      "Iteration 597/2000\n",
      "Policy Loss: 0.0271, Value Loss: 0.0010\n",
      "Iteration 598/2000\n",
      "Policy Loss: 0.0354, Value Loss: 0.0062\n",
      "Iteration 599/2000\n",
      "Policy Loss: 0.1040, Value Loss: 0.0000\n",
      "Iteration 600/2000\n",
      "Policy Loss: 0.0554, Value Loss: 0.0006\n",
      "Iteration 601/2000\n",
      "Policy Loss: 0.1088, Value Loss: 0.0009\n",
      "Iteration 602/2000\n",
      "Policy Loss: 0.0083, Value Loss: 0.0068\n",
      "Iteration 603/2000\n",
      "Policy Loss: 0.0040, Value Loss: 0.0003\n",
      "Iteration 604/2000\n",
      "Policy Loss: 0.0052, Value Loss: 0.0000\n",
      "Iteration 605/2000\n",
      "Policy Loss: 0.0195, Value Loss: 0.0001\n",
      "Iteration 606/2000\n",
      "Policy Loss: 0.0749, Value Loss: 0.0000\n",
      "Iteration 607/2000\n",
      "Policy Loss: 0.0104, Value Loss: 0.0003\n",
      "Iteration 608/2000\n",
      "Policy Loss: 0.0195, Value Loss: 0.0000\n",
      "Iteration 609/2000\n",
      "Policy Loss: 0.0173, Value Loss: 0.0006\n",
      "Iteration 610/2000\n",
      "Policy Loss: 0.0265, Value Loss: 0.0003\n",
      "Iteration 611/2000\n",
      "Policy Loss: 0.0066, Value Loss: 0.0023\n",
      "Iteration 612/2000\n",
      "Policy Loss: 0.2652, Value Loss: 0.0000\n",
      "Iteration 613/2000\n",
      "Policy Loss: 0.0497, Value Loss: 0.0001\n",
      "Iteration 614/2000\n",
      "Policy Loss: 0.3122, Value Loss: 0.0002\n",
      "Iteration 615/2000\n",
      "Policy Loss: 0.0024, Value Loss: 0.0004\n",
      "Iteration 616/2000\n",
      "Policy Loss: 0.1558, Value Loss: 0.0001\n",
      "Iteration 617/2000\n",
      "Policy Loss: 0.0412, Value Loss: 0.0001\n",
      "Iteration 618/2000\n",
      "Policy Loss: 0.0496, Value Loss: 0.0017\n",
      "Iteration 619/2000\n",
      "Policy Loss: 0.0062, Value Loss: 0.0000\n",
      "Iteration 620/2000\n",
      "Policy Loss: 0.0102, Value Loss: 0.0014\n",
      "Iteration 621/2000\n",
      "Policy Loss: 0.3943, Value Loss: 0.0012\n",
      "Iteration 622/2000\n",
      "Policy Loss: 0.1888, Value Loss: 0.0002\n",
      "Iteration 623/2000\n",
      "Policy Loss: 0.0066, Value Loss: 0.0004\n",
      "Iteration 624/2000\n",
      "Policy Loss: 0.1109, Value Loss: 0.0002\n",
      "Iteration 625/2000\n",
      "Policy Loss: 0.0041, Value Loss: 0.0000\n",
      "Iteration 626/2000\n",
      "Policy Loss: 0.0785, Value Loss: 0.0000\n",
      "Iteration 627/2000\n",
      "Policy Loss: 0.0978, Value Loss: 0.0000\n",
      "Iteration 628/2000\n",
      "Policy Loss: 0.0049, Value Loss: 0.0014\n",
      "Iteration 629/2000\n",
      "Policy Loss: 0.0079, Value Loss: 0.0035\n",
      "Iteration 630/2000\n",
      "Policy Loss: 0.2789, Value Loss: 0.0021\n",
      "Iteration 631/2000\n",
      "Policy Loss: 0.2042, Value Loss: 0.0000\n",
      "Iteration 632/2000\n",
      "Policy Loss: 0.0025, Value Loss: 0.0004\n",
      "Iteration 633/2000\n",
      "Policy Loss: 0.1489, Value Loss: 0.0000\n",
      "Iteration 634/2000\n",
      "Policy Loss: 0.1046, Value Loss: 0.0001\n",
      "Iteration 635/2000\n",
      "Policy Loss: 0.0404, Value Loss: 0.0000\n",
      "Iteration 636/2000\n",
      "Policy Loss: 0.0918, Value Loss: 0.0000\n",
      "Iteration 637/2000\n",
      "Policy Loss: 0.0008, Value Loss: 0.0016\n",
      "Iteration 638/2000\n",
      "Policy Loss: 0.2101, Value Loss: 0.0000\n",
      "Iteration 639/2000\n",
      "Policy Loss: 0.0240, Value Loss: 0.0000\n",
      "Iteration 640/2000\n",
      "Policy Loss: 0.2097, Value Loss: 0.0005\n",
      "Iteration 641/2000\n",
      "Policy Loss: 0.0093, Value Loss: 0.0017\n",
      "Iteration 642/2000\n",
      "Policy Loss: 0.0085, Value Loss: 0.0003\n",
      "Iteration 643/2000\n",
      "Policy Loss: 0.0028, Value Loss: 0.0000\n",
      "Iteration 644/2000\n",
      "Policy Loss: 0.1048, Value Loss: 0.0000\n",
      "Iteration 645/2000\n",
      "Policy Loss: 0.0031, Value Loss: 0.0001\n",
      "Iteration 646/2000\n",
      "Policy Loss: 0.0864, Value Loss: 0.0000\n",
      "Iteration 647/2000\n",
      "Policy Loss: 0.0035, Value Loss: 0.0012\n",
      "Iteration 648/2000\n",
      "Policy Loss: 0.0565, Value Loss: 0.0010\n",
      "Iteration 649/2000\n",
      "Policy Loss: 0.0518, Value Loss: 0.0000\n",
      "Iteration 650/2000\n",
      "Policy Loss: 0.0056, Value Loss: 0.0001\n",
      "Iteration 651/2000\n",
      "Policy Loss: 0.0071, Value Loss: 0.0001\n",
      "Iteration 652/2000\n",
      "Policy Loss: 0.0194, Value Loss: 0.0001\n",
      "Iteration 653/2000\n",
      "Policy Loss: 0.0040, Value Loss: 0.0000\n",
      "Iteration 654/2000\n",
      "Policy Loss: 0.0263, Value Loss: 0.0000\n",
      "Iteration 655/2000\n",
      "Policy Loss: 0.0216, Value Loss: 0.0002\n",
      "Iteration 656/2000\n",
      "Policy Loss: 0.0194, Value Loss: 0.0000\n",
      "Iteration 657/2000\n",
      "Policy Loss: 0.0123, Value Loss: 0.0010\n",
      "Iteration 658/2000\n",
      "Policy Loss: 0.2630, Value Loss: 0.0000\n",
      "Iteration 659/2000\n",
      "Policy Loss: 0.0160, Value Loss: 0.0000\n",
      "Iteration 660/2000\n",
      "Policy Loss: 0.0022, Value Loss: 0.0001\n",
      "Iteration 661/2000\n",
      "Policy Loss: 0.0073, Value Loss: 0.0001\n",
      "Iteration 662/2000\n",
      "Policy Loss: 0.0092, Value Loss: 0.0001\n",
      "Iteration 663/2000\n",
      "Policy Loss: 0.0058, Value Loss: 0.0006\n",
      "Iteration 664/2000\n",
      "Policy Loss: 0.2331, Value Loss: 0.0002\n",
      "Iteration 665/2000\n",
      "Policy Loss: 0.2018, Value Loss: 0.0002\n",
      "Iteration 666/2000\n",
      "Policy Loss: 0.0548, Value Loss: 0.0021\n",
      "Iteration 667/2000\n",
      "Policy Loss: 0.0289, Value Loss: 0.0007\n",
      "Iteration 668/2000\n",
      "Policy Loss: 0.0986, Value Loss: 0.0000\n",
      "Iteration 669/2000\n",
      "Policy Loss: 0.0059, Value Loss: 0.0000\n",
      "Iteration 670/2000\n",
      "Policy Loss: 0.0030, Value Loss: 0.0003\n",
      "Iteration 671/2000\n",
      "Policy Loss: 0.0040, Value Loss: 0.0017\n",
      "Iteration 672/2000\n",
      "Policy Loss: 0.0576, Value Loss: 0.0003\n",
      "Iteration 673/2000\n",
      "Policy Loss: 0.0025, Value Loss: 0.0003\n",
      "Iteration 674/2000\n",
      "Policy Loss: 0.0513, Value Loss: 0.0010\n",
      "Iteration 675/2000\n",
      "Policy Loss: 0.1433, Value Loss: 0.0000\n",
      "Iteration 676/2000\n",
      "Policy Loss: 0.0406, Value Loss: 0.0000\n",
      "Iteration 677/2000\n",
      "Policy Loss: 0.0270, Value Loss: 0.0000\n",
      "Iteration 678/2000\n",
      "Policy Loss: 0.0976, Value Loss: 0.0095\n",
      "Iteration 679/2000\n",
      "Policy Loss: 0.0215, Value Loss: 0.0000\n",
      "Iteration 680/2000\n",
      "Policy Loss: 0.0168, Value Loss: 0.0000\n",
      "Iteration 681/2000\n",
      "Policy Loss: 0.0240, Value Loss: 0.0005\n",
      "Iteration 682/2000\n",
      "Policy Loss: 0.0101, Value Loss: 0.0003\n",
      "Iteration 683/2000\n",
      "Policy Loss: 0.0141, Value Loss: 0.0001\n",
      "Iteration 684/2000\n",
      "Policy Loss: 0.0431, Value Loss: 0.0009\n",
      "Iteration 685/2000\n",
      "Policy Loss: 0.0498, Value Loss: 0.0000\n",
      "Iteration 686/2000\n",
      "Policy Loss: 0.0199, Value Loss: 0.0000\n",
      "Iteration 687/2000\n",
      "Policy Loss: 0.0184, Value Loss: 0.0000\n",
      "Iteration 688/2000\n",
      "Policy Loss: 0.0083, Value Loss: 0.0000\n",
      "Iteration 689/2000\n",
      "Policy Loss: 0.0052, Value Loss: 0.0019\n",
      "Iteration 690/2000\n",
      "Policy Loss: 0.0135, Value Loss: 0.0000\n",
      "Iteration 691/2000\n",
      "Policy Loss: 0.2291, Value Loss: 0.0016\n",
      "Iteration 692/2000\n",
      "Policy Loss: 0.0199, Value Loss: 0.0000\n",
      "Iteration 693/2000\n",
      "Policy Loss: 0.0063, Value Loss: 0.0005\n",
      "Iteration 694/2000\n",
      "Policy Loss: 0.1305, Value Loss: 0.0002\n",
      "Iteration 695/2000\n",
      "Policy Loss: 0.1882, Value Loss: 0.0000\n",
      "Iteration 696/2000\n",
      "Policy Loss: 0.0387, Value Loss: 0.0000\n",
      "Iteration 697/2000\n",
      "Policy Loss: 0.0147, Value Loss: 0.0173\n",
      "Iteration 698/2000\n",
      "Policy Loss: 0.0256, Value Loss: 0.0000\n",
      "Iteration 699/2000\n",
      "Policy Loss: 0.5223, Value Loss: 0.0002\n",
      "Iteration 700/2000\n",
      "Policy Loss: 0.6490, Value Loss: 0.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 701/2000\n",
      "Policy Loss: 0.0009, Value Loss: 0.0008\n",
      "Iteration 702/2000\n",
      "Policy Loss: 0.0023, Value Loss: 0.0001\n",
      "Iteration 703/2000\n",
      "Policy Loss: 0.0075, Value Loss: 0.0000\n",
      "Iteration 704/2000\n",
      "Policy Loss: 0.7079, Value Loss: 0.0000\n",
      "Iteration 705/2000\n",
      "Policy Loss: 0.0618, Value Loss: 0.0020\n",
      "Iteration 706/2000\n",
      "Policy Loss: 0.4196, Value Loss: 0.0022\n",
      "Iteration 707/2000\n",
      "Policy Loss: 0.0307, Value Loss: 0.0010\n",
      "Iteration 708/2000\n",
      "Policy Loss: 0.1791, Value Loss: 0.0000\n",
      "Iteration 709/2000\n",
      "Policy Loss: 0.0268, Value Loss: 0.0001\n",
      "Iteration 710/2000\n",
      "Policy Loss: 0.4023, Value Loss: 0.0000\n",
      "Iteration 711/2000\n",
      "Policy Loss: 0.0324, Value Loss: 0.0000\n",
      "Iteration 712/2000\n",
      "Policy Loss: 0.0332, Value Loss: 0.0010\n",
      "Iteration 713/2000\n",
      "Policy Loss: 0.0913, Value Loss: 0.0000\n",
      "Iteration 714/2000\n",
      "Policy Loss: 0.0330, Value Loss: 0.0001\n",
      "Iteration 715/2000\n",
      "Policy Loss: 0.3064, Value Loss: 0.0001\n",
      "Iteration 716/2000\n",
      "Policy Loss: 0.2972, Value Loss: 0.0000\n",
      "Iteration 717/2000\n",
      "Policy Loss: 0.0984, Value Loss: 0.0000\n",
      "Iteration 718/2000\n",
      "Policy Loss: 0.0267, Value Loss: 0.0007\n",
      "Iteration 719/2000\n",
      "Policy Loss: 0.1623, Value Loss: 0.0004\n",
      "Iteration 720/2000\n",
      "Policy Loss: 0.0387, Value Loss: 0.0016\n",
      "Iteration 721/2000\n",
      "Policy Loss: 0.0083, Value Loss: 0.0000\n",
      "Iteration 722/2000\n",
      "Policy Loss: 0.0495, Value Loss: 0.0000\n",
      "Iteration 723/2000\n",
      "Policy Loss: 0.0933, Value Loss: 0.0000\n",
      "Iteration 724/2000\n",
      "Policy Loss: 0.1057, Value Loss: 0.0000\n",
      "Iteration 725/2000\n",
      "Policy Loss: 0.0773, Value Loss: 0.0003\n",
      "Iteration 726/2000\n",
      "Policy Loss: 0.4182, Value Loss: 0.0000\n",
      "Iteration 727/2000\n",
      "Policy Loss: 0.0564, Value Loss: 0.0000\n",
      "Iteration 728/2000\n",
      "Policy Loss: 0.0583, Value Loss: 0.0018\n",
      "Iteration 729/2000\n",
      "Policy Loss: 0.0188, Value Loss: 0.0005\n",
      "Iteration 730/2000\n",
      "Policy Loss: 0.9598, Value Loss: 0.0000\n",
      "Iteration 731/2000\n",
      "Policy Loss: 0.0481, Value Loss: 0.0035\n",
      "Iteration 732/2000\n",
      "Policy Loss: 0.0956, Value Loss: 0.0008\n",
      "Iteration 733/2000\n",
      "Policy Loss: 0.2268, Value Loss: 0.0020\n",
      "Iteration 734/2000\n",
      "Policy Loss: 0.1059, Value Loss: 0.0025\n",
      "Iteration 735/2000\n",
      "Policy Loss: 0.1111, Value Loss: 0.0001\n",
      "Iteration 736/2000\n",
      "Policy Loss: 0.0547, Value Loss: 0.0001\n",
      "Iteration 737/2000\n",
      "Policy Loss: 0.0240, Value Loss: 0.0015\n",
      "Iteration 738/2000\n",
      "Policy Loss: 0.0507, Value Loss: 0.0002\n",
      "Iteration 739/2000\n",
      "Policy Loss: 0.0324, Value Loss: 0.0003\n",
      "Iteration 740/2000\n",
      "Policy Loss: 0.1363, Value Loss: 0.0013\n",
      "Iteration 741/2000\n",
      "Policy Loss: 0.1470, Value Loss: 0.0003\n",
      "Iteration 742/2000\n",
      "Policy Loss: 0.0145, Value Loss: 0.0000\n",
      "Iteration 743/2000\n",
      "Policy Loss: 0.0331, Value Loss: 0.0005\n",
      "Iteration 744/2000\n",
      "Policy Loss: 0.0124, Value Loss: 0.0009\n",
      "Iteration 745/2000\n",
      "Policy Loss: 0.0524, Value Loss: 0.0000\n",
      "Iteration 746/2000\n",
      "Policy Loss: 0.1222, Value Loss: 0.0004\n",
      "Iteration 747/2000\n",
      "Policy Loss: 0.4958, Value Loss: 0.0000\n",
      "Iteration 748/2000\n",
      "Policy Loss: 0.3920, Value Loss: 0.0001\n",
      "Iteration 749/2000\n",
      "Policy Loss: 0.1507, Value Loss: 0.0000\n",
      "Iteration 750/2000\n",
      "Policy Loss: 0.1980, Value Loss: 0.0001\n",
      "Iteration 751/2000\n",
      "Policy Loss: 0.0041, Value Loss: 0.0001\n",
      "Iteration 752/2000\n",
      "Policy Loss: 0.0108, Value Loss: 0.0000\n",
      "Iteration 753/2000\n",
      "Policy Loss: 0.1077, Value Loss: 0.0006\n",
      "Iteration 754/2000\n",
      "Policy Loss: 0.0667, Value Loss: 0.0003\n",
      "Iteration 755/2000\n",
      "Policy Loss: 0.1437, Value Loss: 0.0002\n",
      "Iteration 756/2000\n",
      "Policy Loss: 0.1864, Value Loss: 0.0000\n",
      "Iteration 757/2000\n",
      "Policy Loss: 0.0647, Value Loss: 0.0000\n",
      "Iteration 758/2000\n",
      "Policy Loss: 0.0124, Value Loss: 0.0017\n",
      "Iteration 759/2000\n",
      "Policy Loss: 0.2784, Value Loss: 0.0000\n",
      "Iteration 760/2000\n",
      "Policy Loss: 0.0143, Value Loss: 0.0006\n",
      "Iteration 761/2000\n",
      "Policy Loss: 0.6491, Value Loss: 0.0000\n",
      "Iteration 762/2000\n",
      "Policy Loss: 0.2700, Value Loss: 0.0015\n",
      "Iteration 763/2000\n",
      "Policy Loss: 0.2602, Value Loss: 0.0000\n",
      "Iteration 764/2000\n",
      "Policy Loss: 0.1765, Value Loss: 0.0001\n",
      "Iteration 765/2000\n",
      "Policy Loss: 0.0457, Value Loss: 0.0006\n",
      "Iteration 766/2000\n",
      "Policy Loss: 0.2219, Value Loss: 0.0000\n",
      "Iteration 767/2000\n",
      "Policy Loss: 0.1376, Value Loss: 0.0018\n",
      "Iteration 768/2000\n",
      "Policy Loss: 0.0518, Value Loss: 0.0000\n",
      "Iteration 769/2000\n",
      "Policy Loss: 0.1295, Value Loss: 0.0011\n",
      "Iteration 770/2000\n",
      "Policy Loss: 0.0187, Value Loss: 0.0000\n",
      "Iteration 771/2000\n",
      "Policy Loss: 0.0198, Value Loss: 0.0030\n",
      "Iteration 772/2000\n",
      "Policy Loss: 0.0158, Value Loss: 0.0003\n",
      "Iteration 773/2000\n",
      "Policy Loss: 0.1917, Value Loss: 0.0042\n",
      "Iteration 774/2000\n",
      "Policy Loss: 0.1891, Value Loss: 0.0000\n",
      "Iteration 775/2000\n",
      "Policy Loss: 0.0538, Value Loss: 0.0005\n",
      "Iteration 776/2000\n",
      "Policy Loss: 0.0127, Value Loss: 0.0011\n",
      "Iteration 777/2000\n",
      "Policy Loss: 0.2414, Value Loss: 0.0000\n",
      "Iteration 778/2000\n",
      "Policy Loss: 0.3478, Value Loss: 0.0006\n",
      "Iteration 779/2000\n",
      "Policy Loss: 0.3646, Value Loss: 0.0000\n",
      "Iteration 780/2000\n",
      "Policy Loss: 0.2446, Value Loss: 0.0000\n",
      "Iteration 781/2000\n",
      "Policy Loss: 0.0957, Value Loss: 0.0004\n",
      "Iteration 782/2000\n",
      "Policy Loss: 0.1780, Value Loss: 0.0001\n",
      "Iteration 783/2000\n",
      "Policy Loss: 0.1704, Value Loss: 0.0000\n",
      "Iteration 784/2000\n",
      "Policy Loss: 0.3263, Value Loss: 0.0000\n",
      "Iteration 785/2000\n",
      "Policy Loss: 0.1466, Value Loss: 0.0000\n",
      "Iteration 786/2000\n",
      "Policy Loss: 0.0985, Value Loss: 0.0000\n",
      "Iteration 787/2000\n",
      "Policy Loss: 0.0828, Value Loss: 0.0001\n",
      "Iteration 788/2000\n",
      "Policy Loss: 0.2140, Value Loss: 0.0000\n",
      "Iteration 789/2000\n",
      "Policy Loss: 0.1614, Value Loss: 0.0002\n",
      "Iteration 790/2000\n",
      "Policy Loss: 0.1215, Value Loss: 0.0166\n",
      "Iteration 791/2000\n",
      "Policy Loss: 0.1341, Value Loss: 0.0003\n",
      "Iteration 792/2000\n",
      "Policy Loss: 0.0849, Value Loss: 0.0000\n",
      "Iteration 793/2000\n",
      "Policy Loss: 0.1356, Value Loss: 0.0008\n",
      "Iteration 794/2000\n",
      "Policy Loss: 0.0672, Value Loss: 0.0006\n",
      "Iteration 795/2000\n",
      "Policy Loss: 0.0719, Value Loss: 0.0004\n",
      "Iteration 796/2000\n",
      "Policy Loss: 0.0623, Value Loss: 0.0006\n",
      "Iteration 797/2000\n",
      "Policy Loss: 0.0182, Value Loss: 0.0000\n",
      "Iteration 798/2000\n",
      "Policy Loss: 0.0865, Value Loss: 0.0001\n",
      "Iteration 799/2000\n",
      "Policy Loss: 0.0684, Value Loss: 0.0000\n",
      "Iteration 800/2000\n",
      "Policy Loss: 0.0427, Value Loss: 0.0033\n",
      "Iteration 801/2000\n",
      "Policy Loss: 0.0245, Value Loss: 0.0000\n",
      "Iteration 802/2000\n",
      "Policy Loss: 0.3463, Value Loss: 0.0001\n",
      "Iteration 803/2000\n",
      "Policy Loss: 0.2364, Value Loss: 0.0001\n",
      "Iteration 804/2000\n",
      "Policy Loss: 0.1919, Value Loss: 0.0017\n",
      "Iteration 805/2000\n",
      "Policy Loss: 0.1606, Value Loss: 0.0002\n",
      "Iteration 806/2000\n",
      "Policy Loss: 0.0224, Value Loss: 0.0027\n",
      "Iteration 807/2000\n",
      "Policy Loss: 0.0612, Value Loss: 0.0001\n",
      "Iteration 808/2000\n",
      "Policy Loss: 0.1894, Value Loss: 0.0001\n",
      "Iteration 809/2000\n",
      "Policy Loss: 0.1958, Value Loss: 0.0004\n",
      "Iteration 810/2000\n",
      "Policy Loss: 0.0768, Value Loss: 0.0031\n",
      "Iteration 811/2000\n",
      "Policy Loss: 0.2203, Value Loss: 0.0006\n",
      "Iteration 812/2000\n",
      "Policy Loss: 0.0800, Value Loss: 0.0000\n",
      "Iteration 813/2000\n",
      "Policy Loss: 0.0039, Value Loss: 0.0002\n",
      "Iteration 814/2000\n",
      "Policy Loss: 0.0040, Value Loss: 0.0001\n",
      "Iteration 815/2000\n",
      "Policy Loss: 0.6756, Value Loss: 0.0027\n",
      "Iteration 816/2000\n",
      "Policy Loss: 0.0458, Value Loss: 0.0001\n",
      "Iteration 817/2000\n",
      "Policy Loss: 0.2136, Value Loss: 0.0000\n",
      "Iteration 818/2000\n",
      "Policy Loss: 0.1011, Value Loss: 0.0000\n",
      "Iteration 819/2000\n",
      "Policy Loss: 0.0416, Value Loss: 0.0004\n",
      "Iteration 820/2000\n",
      "Policy Loss: 0.0046, Value Loss: 0.0007\n",
      "Iteration 821/2000\n",
      "Policy Loss: 0.1117, Value Loss: 0.0001\n",
      "Iteration 822/2000\n",
      "Policy Loss: 0.1543, Value Loss: 0.0000\n",
      "Iteration 823/2000\n",
      "Policy Loss: 0.0088, Value Loss: 0.0006\n",
      "Iteration 824/2000\n",
      "Policy Loss: 0.0896, Value Loss: 0.0001\n",
      "Iteration 825/2000\n",
      "Policy Loss: 0.0580, Value Loss: 0.0005\n",
      "Iteration 826/2000\n",
      "Policy Loss: 0.0812, Value Loss: 0.0006\n",
      "Iteration 827/2000\n",
      "Policy Loss: 0.0478, Value Loss: 0.0000\n",
      "Iteration 828/2000\n",
      "Policy Loss: 0.0154, Value Loss: 0.0001\n",
      "Iteration 829/2000\n",
      "Policy Loss: 0.2060, Value Loss: 0.0022\n",
      "Iteration 830/2000\n",
      "Policy Loss: 0.2171, Value Loss: 0.0000\n",
      "Iteration 831/2000\n",
      "Policy Loss: 0.0957, Value Loss: 0.0001\n",
      "Iteration 832/2000\n",
      "Policy Loss: 0.6709, Value Loss: 0.0001\n",
      "Iteration 833/2000\n",
      "Policy Loss: 0.1620, Value Loss: 0.0000\n",
      "Iteration 834/2000\n",
      "Policy Loss: 0.0367, Value Loss: 0.0002\n",
      "Iteration 835/2000\n",
      "Policy Loss: 0.1212, Value Loss: 0.0000\n",
      "Iteration 836/2000\n",
      "Policy Loss: 0.1745, Value Loss: 0.0004\n",
      "Iteration 837/2000\n",
      "Policy Loss: 0.2116, Value Loss: 0.0001\n",
      "Iteration 838/2000\n",
      "Policy Loss: 0.2361, Value Loss: 0.0000\n",
      "Iteration 839/2000\n",
      "Policy Loss: 0.0213, Value Loss: 0.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 840/2000\n",
      "Policy Loss: 0.1005, Value Loss: 0.0000\n",
      "Iteration 841/2000\n",
      "Policy Loss: 0.3942, Value Loss: 0.0000\n",
      "Iteration 842/2000\n",
      "Policy Loss: 0.0178, Value Loss: 0.0012\n",
      "Iteration 843/2000\n",
      "Policy Loss: 0.0397, Value Loss: 0.0000\n",
      "Iteration 844/2000\n",
      "Policy Loss: 0.0133, Value Loss: 0.0002\n",
      "Iteration 845/2000\n",
      "Policy Loss: 0.0882, Value Loss: 0.0000\n",
      "Iteration 846/2000\n",
      "Policy Loss: 0.2113, Value Loss: 0.0003\n",
      "Iteration 847/2000\n",
      "Policy Loss: 0.2101, Value Loss: 0.0000\n",
      "Iteration 848/2000\n",
      "Policy Loss: 0.0096, Value Loss: 0.0020\n",
      "Iteration 849/2000\n",
      "Policy Loss: 0.0927, Value Loss: 0.0021\n",
      "Iteration 850/2000\n",
      "Policy Loss: 0.0138, Value Loss: 0.0000\n",
      "Iteration 851/2000\n",
      "Policy Loss: 0.1811, Value Loss: 0.0007\n",
      "Iteration 852/2000\n",
      "Policy Loss: 0.1695, Value Loss: 0.0002\n",
      "Iteration 853/2000\n",
      "Policy Loss: 0.0936, Value Loss: 0.0000\n",
      "Iteration 854/2000\n",
      "Policy Loss: 0.3585, Value Loss: 0.0000\n",
      "Iteration 855/2000\n",
      "Policy Loss: 0.1484, Value Loss: 0.0001\n",
      "Iteration 856/2000\n",
      "Policy Loss: 0.0313, Value Loss: 0.0003\n",
      "Iteration 857/2000\n",
      "Policy Loss: 0.1223, Value Loss: 0.0070\n",
      "Iteration 858/2000\n",
      "Policy Loss: 0.0216, Value Loss: 0.0000\n",
      "Iteration 859/2000\n",
      "Policy Loss: 0.0196, Value Loss: 0.0000\n",
      "Iteration 860/2000\n",
      "Policy Loss: 0.2708, Value Loss: 0.0038\n",
      "Iteration 861/2000\n",
      "Policy Loss: 0.0559, Value Loss: 0.0000\n",
      "Iteration 862/2000\n",
      "Policy Loss: 0.0690, Value Loss: 0.0000\n",
      "Iteration 863/2000\n",
      "Policy Loss: 0.0346, Value Loss: 0.0001\n",
      "Iteration 864/2000\n",
      "Policy Loss: 0.1840, Value Loss: 0.0002\n",
      "Iteration 865/2000\n",
      "Policy Loss: 0.0916, Value Loss: 0.0013\n",
      "Iteration 866/2000\n",
      "Policy Loss: 0.0682, Value Loss: 0.0003\n",
      "Iteration 867/2000\n",
      "Policy Loss: 0.0182, Value Loss: 0.0002\n",
      "Iteration 868/2000\n",
      "Policy Loss: 0.1123, Value Loss: 0.0000\n",
      "Iteration 869/2000\n",
      "Policy Loss: 0.0044, Value Loss: 0.0000\n",
      "Iteration 870/2000\n",
      "Policy Loss: 0.1677, Value Loss: 0.0001\n",
      "Iteration 871/2000\n",
      "Policy Loss: 0.0255, Value Loss: 0.0000\n",
      "Iteration 872/2000\n",
      "Policy Loss: 0.0229, Value Loss: 0.0000\n",
      "Iteration 873/2000\n",
      "Policy Loss: 0.0314, Value Loss: 0.0000\n",
      "Iteration 874/2000\n",
      "Policy Loss: 0.0190, Value Loss: 0.0011\n",
      "Iteration 875/2000\n",
      "Policy Loss: 0.1095, Value Loss: 0.0046\n",
      "Iteration 876/2000\n",
      "Policy Loss: 0.0932, Value Loss: 0.0000\n",
      "Iteration 877/2000\n",
      "Policy Loss: 0.0484, Value Loss: 0.0000\n",
      "Iteration 878/2000\n",
      "Policy Loss: 0.0412, Value Loss: 0.0003\n",
      "Iteration 879/2000\n",
      "Policy Loss: 0.0175, Value Loss: 0.0002\n",
      "Iteration 880/2000\n",
      "Policy Loss: 0.0256, Value Loss: 0.0000\n",
      "Iteration 881/2000\n",
      "Policy Loss: 0.3696, Value Loss: 0.0000\n",
      "Iteration 882/2000\n",
      "Policy Loss: 0.1644, Value Loss: 0.0002\n",
      "Iteration 883/2000\n",
      "Policy Loss: 0.0192, Value Loss: 0.0000\n",
      "Iteration 884/2000\n",
      "Policy Loss: 0.1218, Value Loss: 0.0001\n",
      "Iteration 885/2000\n",
      "Policy Loss: 0.0095, Value Loss: 0.0000\n",
      "Iteration 886/2000\n",
      "Policy Loss: 0.0375, Value Loss: 0.0000\n",
      "Iteration 887/2000\n",
      "Policy Loss: 0.1377, Value Loss: 0.0000\n",
      "Iteration 888/2000\n",
      "Policy Loss: 0.1496, Value Loss: 0.0000\n",
      "Iteration 889/2000\n",
      "Policy Loss: 0.0373, Value Loss: 0.0025\n",
      "Iteration 890/2000\n",
      "Policy Loss: 0.0910, Value Loss: 0.0001\n",
      "Iteration 891/2000\n",
      "Policy Loss: 0.0400, Value Loss: 0.0006\n",
      "Iteration 892/2000\n",
      "Policy Loss: 0.0064, Value Loss: 0.0002\n",
      "Iteration 893/2000\n",
      "Policy Loss: 0.0040, Value Loss: 0.0000\n",
      "Iteration 894/2000\n",
      "Policy Loss: 0.1279, Value Loss: 0.0000\n",
      "Iteration 895/2000\n",
      "Policy Loss: 0.5374, Value Loss: 0.0000\n",
      "Iteration 896/2000\n",
      "Policy Loss: 0.1395, Value Loss: 0.0001\n",
      "Iteration 897/2000\n",
      "Policy Loss: 0.1249, Value Loss: 0.0000\n",
      "Iteration 898/2000\n",
      "Policy Loss: 0.2265, Value Loss: 0.0000\n",
      "Iteration 899/2000\n",
      "Policy Loss: 0.2746, Value Loss: 0.0000\n",
      "Iteration 900/2000\n",
      "Policy Loss: 0.0189, Value Loss: 0.0002\n",
      "Iteration 901/2000\n",
      "Policy Loss: 0.0138, Value Loss: 0.0001\n",
      "Iteration 902/2000\n",
      "Policy Loss: 0.2044, Value Loss: 0.0005\n",
      "Iteration 903/2000\n",
      "Policy Loss: 0.0538, Value Loss: 0.0000\n",
      "Iteration 904/2000\n",
      "Policy Loss: 0.0078, Value Loss: 0.0005\n",
      "Iteration 905/2000\n",
      "Policy Loss: 0.1077, Value Loss: 0.0003\n",
      "Iteration 906/2000\n",
      "Policy Loss: 0.0959, Value Loss: 0.0000\n",
      "Iteration 907/2000\n",
      "Policy Loss: 0.0068, Value Loss: 0.0000\n",
      "Iteration 908/2000\n",
      "Policy Loss: 0.0075, Value Loss: 0.0000\n",
      "Iteration 909/2000\n",
      "Policy Loss: 0.0875, Value Loss: 0.0000\n",
      "Iteration 910/2000\n",
      "Policy Loss: 0.1461, Value Loss: 0.0000\n",
      "Iteration 911/2000\n",
      "Policy Loss: 0.1176, Value Loss: 0.0001\n",
      "Iteration 912/2000\n",
      "Policy Loss: 0.1463, Value Loss: 0.0000\n",
      "Iteration 913/2000\n",
      "Policy Loss: 0.0224, Value Loss: 0.0012\n",
      "Iteration 914/2000\n",
      "Policy Loss: 0.1399, Value Loss: 0.0018\n",
      "Iteration 915/2000\n",
      "Policy Loss: 0.1088, Value Loss: 0.0000\n",
      "Iteration 916/2000\n",
      "Policy Loss: 0.0809, Value Loss: 0.0000\n",
      "Iteration 917/2000\n",
      "Policy Loss: 0.0387, Value Loss: 0.0001\n",
      "Iteration 918/2000\n",
      "Policy Loss: 0.0791, Value Loss: 0.0004\n",
      "Iteration 919/2000\n",
      "Policy Loss: 0.0516, Value Loss: 0.0000\n",
      "Iteration 920/2000\n",
      "Policy Loss: 0.0973, Value Loss: 0.0000\n",
      "Iteration 921/2000\n",
      "Policy Loss: 0.0548, Value Loss: 0.0000\n",
      "Iteration 922/2000\n",
      "Policy Loss: 0.1215, Value Loss: 0.0021\n",
      "Iteration 923/2000\n",
      "Policy Loss: 0.4273, Value Loss: 0.0003\n",
      "Iteration 924/2000\n",
      "Policy Loss: 0.0643, Value Loss: 0.0001\n",
      "Iteration 925/2000\n",
      "Policy Loss: 0.0118, Value Loss: 0.0000\n",
      "Iteration 926/2000\n",
      "Policy Loss: 0.0297, Value Loss: 0.0000\n",
      "Iteration 927/2000\n",
      "Policy Loss: 0.0099, Value Loss: 0.0001\n",
      "Iteration 928/2000\n",
      "Policy Loss: 0.0240, Value Loss: 0.0003\n",
      "Iteration 929/2000\n",
      "Policy Loss: 0.0767, Value Loss: 0.0011\n",
      "Iteration 930/2000\n",
      "Policy Loss: 0.0263, Value Loss: 0.0000\n",
      "Iteration 931/2000\n",
      "Policy Loss: 0.0262, Value Loss: 0.0000\n",
      "Iteration 932/2000\n",
      "Policy Loss: 0.0589, Value Loss: 0.0000\n",
      "Iteration 933/2000\n",
      "Policy Loss: 0.0720, Value Loss: 0.0007\n",
      "Iteration 934/2000\n",
      "Policy Loss: 0.1050, Value Loss: 0.0000\n",
      "Iteration 935/2000\n",
      "Policy Loss: 0.0652, Value Loss: 0.0003\n",
      "Iteration 936/2000\n",
      "Policy Loss: 0.0079, Value Loss: 0.0005\n",
      "Iteration 937/2000\n",
      "Policy Loss: 0.2625, Value Loss: 0.0004\n",
      "Iteration 938/2000\n",
      "Policy Loss: 0.2584, Value Loss: 0.0001\n",
      "Iteration 939/2000\n",
      "Policy Loss: 0.1877, Value Loss: 0.0003\n",
      "Iteration 940/2000\n",
      "Policy Loss: 0.0707, Value Loss: 0.0006\n",
      "Iteration 941/2000\n",
      "Policy Loss: 0.0288, Value Loss: 0.0000\n",
      "Iteration 942/2000\n",
      "Policy Loss: 0.0499, Value Loss: 0.0000\n",
      "Iteration 943/2000\n",
      "Policy Loss: 0.0633, Value Loss: 0.0000\n",
      "Iteration 944/2000\n",
      "Policy Loss: 0.1209, Value Loss: 0.0000\n",
      "Iteration 945/2000\n",
      "Policy Loss: 0.0235, Value Loss: 0.0002\n",
      "Iteration 946/2000\n",
      "Policy Loss: 0.2197, Value Loss: 0.0002\n",
      "Iteration 947/2000\n",
      "Policy Loss: 0.0156, Value Loss: 0.0055\n",
      "Iteration 948/2000\n",
      "Policy Loss: 0.1336, Value Loss: 0.0000\n",
      "Iteration 949/2000\n",
      "Policy Loss: 0.0032, Value Loss: 0.0000\n",
      "Iteration 950/2000\n",
      "Policy Loss: 0.0029, Value Loss: 0.0000\n",
      "Iteration 951/2000\n",
      "Policy Loss: 0.0041, Value Loss: 0.0002\n",
      "Iteration 952/2000\n",
      "Policy Loss: 0.1620, Value Loss: 0.0061\n",
      "Iteration 953/2000\n",
      "Policy Loss: 0.2422, Value Loss: 0.0000\n",
      "Iteration 954/2000\n",
      "Policy Loss: 0.2402, Value Loss: 0.0004\n",
      "Iteration 955/2000\n",
      "Policy Loss: 0.0194, Value Loss: 0.0005\n",
      "Iteration 956/2000\n",
      "Policy Loss: 0.0066, Value Loss: 0.0000\n",
      "Iteration 957/2000\n",
      "Policy Loss: 0.1326, Value Loss: 0.0000\n",
      "Iteration 958/2000\n",
      "Policy Loss: 0.0116, Value Loss: 0.0000\n",
      "Iteration 959/2000\n",
      "Policy Loss: 0.0037, Value Loss: 0.0006\n",
      "Iteration 960/2000\n",
      "Policy Loss: 0.2376, Value Loss: 0.0000\n",
      "Iteration 961/2000\n",
      "Policy Loss: 0.0063, Value Loss: 0.0002\n",
      "Iteration 962/2000\n",
      "Policy Loss: 0.0120, Value Loss: 0.0001\n",
      "Iteration 963/2000\n",
      "Policy Loss: 0.0166, Value Loss: 0.0041\n",
      "Iteration 964/2000\n",
      "Policy Loss: 0.0036, Value Loss: 0.0000\n",
      "Iteration 965/2000\n",
      "Policy Loss: 0.1023, Value Loss: 0.0000\n",
      "Iteration 966/2000\n",
      "Policy Loss: 0.0062, Value Loss: 0.0000\n",
      "Iteration 967/2000\n",
      "Policy Loss: 0.0150, Value Loss: 0.0000\n",
      "Iteration 968/2000\n",
      "Policy Loss: 0.1188, Value Loss: 0.0100\n",
      "Iteration 969/2000\n",
      "Policy Loss: 0.2267, Value Loss: 0.0000\n",
      "Iteration 970/2000\n",
      "Policy Loss: 0.0079, Value Loss: 0.0000\n",
      "Iteration 971/2000\n",
      "Policy Loss: 0.0080, Value Loss: 0.0000\n",
      "Iteration 972/2000\n",
      "Policy Loss: 0.0084, Value Loss: 0.0001\n",
      "Iteration 973/2000\n",
      "Policy Loss: 0.0108, Value Loss: 0.0000\n",
      "Iteration 974/2000\n",
      "Policy Loss: 0.0521, Value Loss: 0.0004\n",
      "Iteration 975/2000\n",
      "Policy Loss: 0.0103, Value Loss: 0.0000\n",
      "Iteration 976/2000\n",
      "Policy Loss: 0.0222, Value Loss: 0.0000\n",
      "Iteration 977/2000\n",
      "Policy Loss: 0.0197, Value Loss: 0.0001\n",
      "Iteration 978/2000\n",
      "Policy Loss: 0.0857, Value Loss: 0.0038\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 979/2000\n",
      "Policy Loss: 0.0537, Value Loss: 0.0000\n",
      "Iteration 980/2000\n",
      "Policy Loss: 0.0082, Value Loss: 0.0000\n",
      "Iteration 981/2000\n",
      "Policy Loss: 0.1135, Value Loss: 0.0000\n",
      "Iteration 982/2000\n",
      "Policy Loss: 0.0033, Value Loss: 0.0001\n",
      "Iteration 983/2000\n",
      "Policy Loss: 0.0399, Value Loss: 0.0003\n",
      "Iteration 984/2000\n",
      "Policy Loss: 0.0386, Value Loss: 0.0001\n",
      "Iteration 985/2000\n",
      "Policy Loss: 0.0242, Value Loss: 0.0002\n",
      "Iteration 986/2000\n",
      "Policy Loss: 0.0043, Value Loss: 0.0003\n",
      "Iteration 987/2000\n",
      "Policy Loss: 0.0110, Value Loss: 0.0002\n",
      "Iteration 988/2000\n",
      "Policy Loss: 0.0051, Value Loss: 0.0000\n",
      "Iteration 989/2000\n",
      "Policy Loss: 0.0114, Value Loss: 0.0000\n",
      "Iteration 990/2000\n",
      "Policy Loss: 0.0007, Value Loss: 0.0005\n",
      "Iteration 991/2000\n",
      "Policy Loss: 0.0065, Value Loss: 0.0001\n",
      "Iteration 992/2000\n",
      "Policy Loss: 0.0033, Value Loss: 0.0000\n",
      "Iteration 993/2000\n",
      "Policy Loss: 0.1725, Value Loss: 0.0008\n",
      "Iteration 994/2000\n",
      "Policy Loss: 0.0072, Value Loss: 0.0001\n",
      "Iteration 995/2000\n",
      "Policy Loss: 0.0097, Value Loss: 0.0000\n",
      "Iteration 996/2000\n",
      "Policy Loss: 0.0033, Value Loss: 0.0000\n",
      "Iteration 997/2000\n",
      "Policy Loss: 0.1466, Value Loss: 0.0000\n",
      "Iteration 998/2000\n",
      "Policy Loss: 0.0009, Value Loss: 0.0005\n",
      "Iteration 999/2000\n",
      "Policy Loss: 0.2078, Value Loss: 0.0000\n",
      "Iteration 1000/2000\n",
      "Policy Loss: 0.0136, Value Loss: 0.0000\n",
      "Iteration 1001/2000\n",
      "Policy Loss: 0.0010, Value Loss: 0.0013\n",
      "Iteration 1002/2000\n",
      "Policy Loss: 0.0810, Value Loss: 0.0004\n",
      "Iteration 1003/2000\n",
      "Policy Loss: 0.1979, Value Loss: 0.0002\n",
      "Iteration 1004/2000\n",
      "Policy Loss: 0.1412, Value Loss: 0.0000\n",
      "Iteration 1005/2000\n",
      "Policy Loss: 0.1761, Value Loss: 0.0000\n",
      "Iteration 1006/2000\n",
      "Policy Loss: 0.0193, Value Loss: 0.0000\n",
      "Iteration 1007/2000\n",
      "Policy Loss: 0.0014, Value Loss: 0.0001\n",
      "Iteration 1008/2000\n",
      "Policy Loss: 0.0065, Value Loss: 0.0001\n",
      "Iteration 1009/2000\n",
      "Policy Loss: 0.2613, Value Loss: 0.0083\n",
      "Iteration 1010/2000\n",
      "Policy Loss: 0.0032, Value Loss: 0.0001\n",
      "Iteration 1011/2000\n",
      "Policy Loss: 0.1481, Value Loss: 0.0050\n",
      "Iteration 1012/2000\n",
      "Policy Loss: 0.2318, Value Loss: 0.0009\n",
      "Iteration 1013/2000\n",
      "Policy Loss: 0.3748, Value Loss: 0.0000\n",
      "Iteration 1014/2000\n",
      "Policy Loss: 0.0008, Value Loss: 0.0001\n",
      "Iteration 1015/2000\n",
      "Policy Loss: 0.0088, Value Loss: 0.0001\n",
      "Iteration 1016/2000\n",
      "Policy Loss: 0.0103, Value Loss: 0.0000\n",
      "Iteration 1017/2000\n",
      "Policy Loss: 0.0734, Value Loss: 0.0000\n",
      "Iteration 1018/2000\n",
      "Policy Loss: 0.0559, Value Loss: 0.0000\n",
      "Iteration 1019/2000\n",
      "Policy Loss: 0.0157, Value Loss: 0.0000\n",
      "Iteration 1020/2000\n",
      "Policy Loss: 0.0171, Value Loss: 0.0000\n",
      "Iteration 1021/2000\n",
      "Policy Loss: 0.1454, Value Loss: 0.0032\n",
      "Iteration 1022/2000\n",
      "Policy Loss: 0.0252, Value Loss: 0.0076\n",
      "Iteration 1023/2000\n",
      "Policy Loss: 0.1665, Value Loss: 0.0235\n",
      "Iteration 1024/2000\n",
      "Policy Loss: 0.3071, Value Loss: 0.0000\n",
      "Iteration 1025/2000\n",
      "Policy Loss: 0.0339, Value Loss: 0.0001\n",
      "Iteration 1026/2000\n",
      "Policy Loss: 0.1101, Value Loss: 0.0000\n",
      "Iteration 1027/2000\n",
      "Policy Loss: 0.0176, Value Loss: 0.0002\n",
      "Iteration 1028/2000\n",
      "Policy Loss: 0.0031, Value Loss: 0.0007\n",
      "Iteration 1029/2000\n",
      "Policy Loss: 0.0889, Value Loss: 0.0171\n",
      "Iteration 1030/2000\n",
      "Policy Loss: 0.0302, Value Loss: 0.0001\n",
      "Iteration 1031/2000\n",
      "Policy Loss: 0.1273, Value Loss: 0.0006\n",
      "Iteration 1032/2000\n",
      "Policy Loss: 0.0819, Value Loss: 0.0107\n",
      "Iteration 1033/2000\n",
      "Policy Loss: 0.0086, Value Loss: 0.0080\n",
      "Iteration 1034/2000\n",
      "Policy Loss: 0.0091, Value Loss: 0.0000\n",
      "Iteration 1035/2000\n",
      "Policy Loss: 0.1325, Value Loss: 0.0063\n",
      "Iteration 1036/2000\n",
      "Policy Loss: 0.0041, Value Loss: 0.0004\n",
      "Iteration 1037/2000\n",
      "Policy Loss: 0.0571, Value Loss: 0.0002\n",
      "Iteration 1038/2000\n",
      "Policy Loss: 0.0010, Value Loss: 0.0005\n",
      "Iteration 1039/2000\n",
      "Policy Loss: 0.0113, Value Loss: 0.0008\n",
      "Iteration 1040/2000\n",
      "Policy Loss: 0.1665, Value Loss: 0.0096\n",
      "Iteration 1041/2000\n",
      "Policy Loss: 0.1070, Value Loss: 0.0003\n",
      "Iteration 1042/2000\n",
      "Policy Loss: 0.0063, Value Loss: 0.0001\n",
      "Iteration 1043/2000\n",
      "Policy Loss: 0.0018, Value Loss: 0.0001\n",
      "Iteration 1044/2000\n",
      "Policy Loss: 0.0725, Value Loss: 0.0106\n",
      "Iteration 1045/2000\n",
      "Policy Loss: 0.0014, Value Loss: 0.0000\n",
      "Iteration 1046/2000\n",
      "Policy Loss: 0.0043, Value Loss: 0.0019\n",
      "Iteration 1047/2000\n",
      "Policy Loss: 0.0016, Value Loss: 0.0002\n",
      "Iteration 1048/2000\n",
      "Policy Loss: 0.0283, Value Loss: 0.0002\n",
      "Iteration 1049/2000\n",
      "Policy Loss: 0.0713, Value Loss: 0.0000\n",
      "Iteration 1050/2000\n",
      "Policy Loss: 0.0202, Value Loss: 0.0018\n",
      "Iteration 1051/2000\n",
      "Policy Loss: 0.0343, Value Loss: 0.0001\n",
      "Iteration 1052/2000\n",
      "Policy Loss: 0.0026, Value Loss: 0.0008\n",
      "Iteration 1053/2000\n",
      "Policy Loss: 0.0328, Value Loss: 0.0002\n",
      "Iteration 1054/2000\n",
      "Policy Loss: 0.0025, Value Loss: 0.0000\n",
      "Iteration 1055/2000\n",
      "Policy Loss: 0.0038, Value Loss: 0.0002\n",
      "Iteration 1056/2000\n",
      "Policy Loss: 0.0097, Value Loss: 0.0000\n",
      "Iteration 1057/2000\n",
      "Policy Loss: 0.0186, Value Loss: 0.0000\n",
      "Iteration 1058/2000\n",
      "Policy Loss: 0.0060, Value Loss: 0.0000\n",
      "Iteration 1059/2000\n",
      "Policy Loss: 0.0078, Value Loss: 0.0000\n",
      "Iteration 1060/2000\n",
      "Policy Loss: 0.3638, Value Loss: 0.0001\n",
      "Iteration 1061/2000\n",
      "Policy Loss: 0.0068, Value Loss: 0.0011\n",
      "Iteration 1062/2000\n",
      "Policy Loss: 0.0031, Value Loss: 0.0002\n",
      "Iteration 1063/2000\n",
      "Policy Loss: 0.0187, Value Loss: 0.0003\n",
      "Iteration 1064/2000\n",
      "Policy Loss: 0.1561, Value Loss: 0.0000\n",
      "Iteration 1065/2000\n",
      "Policy Loss: 0.0039, Value Loss: 0.0048\n",
      "Iteration 1066/2000\n",
      "Policy Loss: 0.0632, Value Loss: 0.0000\n",
      "Iteration 1067/2000\n",
      "Policy Loss: 0.0201, Value Loss: 0.0000\n",
      "Iteration 1068/2000\n",
      "Policy Loss: 0.0222, Value Loss: 0.0000\n",
      "Iteration 1069/2000\n",
      "Policy Loss: 0.0184, Value Loss: 0.0356\n",
      "Iteration 1070/2000\n",
      "Policy Loss: 0.0086, Value Loss: 0.0005\n",
      "Iteration 1071/2000\n",
      "Policy Loss: 0.0933, Value Loss: 0.0002\n",
      "Iteration 1072/2000\n",
      "Policy Loss: 0.0028, Value Loss: 0.0005\n",
      "Iteration 1073/2000\n",
      "Policy Loss: 0.0553, Value Loss: 0.0002\n",
      "Iteration 1074/2000\n",
      "Policy Loss: 0.0057, Value Loss: 0.0010\n",
      "Iteration 1075/2000\n",
      "Policy Loss: 0.0043, Value Loss: 0.0022\n",
      "Iteration 1076/2000\n",
      "Policy Loss: 0.0526, Value Loss: 0.0000\n",
      "Iteration 1077/2000\n",
      "Policy Loss: 0.2020, Value Loss: 0.0000\n",
      "Iteration 1078/2000\n",
      "Policy Loss: 0.0554, Value Loss: 0.0000\n",
      "Iteration 1079/2000\n",
      "Policy Loss: 0.0042, Value Loss: 0.0000\n",
      "Iteration 1080/2000\n",
      "Policy Loss: 0.0124, Value Loss: 0.0008\n",
      "Iteration 1081/2000\n",
      "Policy Loss: 0.2105, Value Loss: 0.0000\n",
      "Iteration 1082/2000\n",
      "Policy Loss: 0.0517, Value Loss: 0.0001\n",
      "Iteration 1083/2000\n",
      "Policy Loss: 0.0018, Value Loss: 0.0008\n",
      "Iteration 1084/2000\n",
      "Policy Loss: 0.0013, Value Loss: 0.0000\n",
      "Iteration 1085/2000\n",
      "Policy Loss: 0.0038, Value Loss: 0.0000\n",
      "Iteration 1086/2000\n",
      "Policy Loss: 0.0070, Value Loss: 0.0000\n",
      "Iteration 1087/2000\n",
      "Policy Loss: 0.1136, Value Loss: 0.0000\n",
      "Iteration 1088/2000\n",
      "Policy Loss: 0.0459, Value Loss: 0.0004\n",
      "Iteration 1089/2000\n",
      "Policy Loss: 0.0888, Value Loss: 0.0000\n",
      "Iteration 1090/2000\n",
      "Policy Loss: 0.0035, Value Loss: 0.0001\n",
      "Iteration 1091/2000\n",
      "Policy Loss: 0.0724, Value Loss: 0.0001\n",
      "Iteration 1092/2000\n",
      "Policy Loss: 0.0326, Value Loss: 0.0001\n",
      "Iteration 1093/2000\n",
      "Policy Loss: 0.1079, Value Loss: 0.0000\n",
      "Iteration 1094/2000\n",
      "Policy Loss: 0.1338, Value Loss: 0.0001\n",
      "Iteration 1095/2000\n",
      "Policy Loss: 0.0681, Value Loss: 0.0002\n",
      "Iteration 1096/2000\n",
      "Policy Loss: 0.0030, Value Loss: 0.0000\n",
      "Iteration 1097/2000\n",
      "Policy Loss: 0.0083, Value Loss: 0.0002\n",
      "Iteration 1098/2000\n",
      "Policy Loss: 0.0014, Value Loss: 0.0001\n",
      "Iteration 1099/2000\n",
      "Policy Loss: 0.1020, Value Loss: 0.0000\n",
      "Iteration 1100/2000\n",
      "Policy Loss: 0.0718, Value Loss: 0.0017\n",
      "Iteration 1101/2000\n",
      "Policy Loss: 0.0019, Value Loss: 0.0000\n",
      "Iteration 1102/2000\n",
      "Policy Loss: 0.0906, Value Loss: 0.0000\n",
      "Iteration 1103/2000\n",
      "Policy Loss: 0.0666, Value Loss: 0.0004\n",
      "Iteration 1104/2000\n",
      "Policy Loss: 0.0528, Value Loss: 0.0005\n",
      "Iteration 1105/2000\n",
      "Policy Loss: 0.0514, Value Loss: 0.0000\n",
      "Iteration 1106/2000\n",
      "Policy Loss: 0.0015, Value Loss: 0.0000\n",
      "Iteration 1107/2000\n",
      "Policy Loss: 0.1343, Value Loss: 0.0004\n",
      "Iteration 1108/2000\n",
      "Policy Loss: 0.0184, Value Loss: 0.0000\n",
      "Iteration 1109/2000\n",
      "Policy Loss: 0.0280, Value Loss: 0.0000\n",
      "Iteration 1110/2000\n",
      "Policy Loss: 0.0073, Value Loss: 0.0000\n",
      "Iteration 1111/2000\n",
      "Policy Loss: 0.0038, Value Loss: 0.0000\n",
      "Iteration 1112/2000\n",
      "Policy Loss: 0.2679, Value Loss: 0.0000\n",
      "Iteration 1113/2000\n",
      "Policy Loss: 0.0015, Value Loss: 0.0000\n",
      "Iteration 1114/2000\n",
      "Policy Loss: 0.0066, Value Loss: 0.0000\n",
      "Iteration 1115/2000\n",
      "Policy Loss: 0.0032, Value Loss: 0.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1116/2000\n",
      "Policy Loss: 0.0026, Value Loss: 0.0000\n",
      "Iteration 1117/2000\n",
      "Policy Loss: 0.0034, Value Loss: 0.0000\n",
      "Iteration 1118/2000\n",
      "Policy Loss: 0.2522, Value Loss: 0.0000\n",
      "Iteration 1119/2000\n",
      "Policy Loss: 0.1861, Value Loss: 0.0001\n",
      "Iteration 1120/2000\n",
      "Policy Loss: 0.0102, Value Loss: 0.0000\n",
      "Iteration 1121/2000\n",
      "Policy Loss: 0.0022, Value Loss: 0.0000\n",
      "Iteration 1122/2000\n",
      "Policy Loss: 0.1042, Value Loss: 0.0000\n",
      "Iteration 1123/2000\n",
      "Policy Loss: 0.2052, Value Loss: 0.0001\n",
      "Iteration 1124/2000\n",
      "Policy Loss: 0.0879, Value Loss: 0.0000\n",
      "Iteration 1125/2000\n",
      "Policy Loss: 0.0488, Value Loss: 0.0001\n",
      "Iteration 1126/2000\n",
      "Policy Loss: 0.0620, Value Loss: 0.0000\n",
      "Iteration 1127/2000\n",
      "Policy Loss: 0.1274, Value Loss: 0.0000\n",
      "Iteration 1128/2000\n",
      "Policy Loss: 0.1437, Value Loss: 0.0000\n",
      "Iteration 1129/2000\n",
      "Policy Loss: 0.1321, Value Loss: 0.0001\n",
      "Iteration 1130/2000\n",
      "Policy Loss: 0.1205, Value Loss: 0.0000\n",
      "Iteration 1131/2000\n",
      "Policy Loss: 0.0471, Value Loss: 0.0000\n",
      "Iteration 1132/2000\n",
      "Policy Loss: 0.1602, Value Loss: 0.0001\n",
      "Iteration 1133/2000\n",
      "Policy Loss: 0.0282, Value Loss: 0.0000\n",
      "Iteration 1134/2000\n",
      "Policy Loss: 0.0163, Value Loss: 0.0000\n",
      "Iteration 1135/2000\n",
      "Policy Loss: 0.0137, Value Loss: 0.0002\n",
      "Iteration 1136/2000\n",
      "Policy Loss: 0.0604, Value Loss: 0.0000\n",
      "Iteration 1137/2000\n",
      "Policy Loss: 0.0047, Value Loss: 0.0000\n",
      "Iteration 1138/2000\n",
      "Policy Loss: 0.0041, Value Loss: 0.0005\n",
      "Iteration 1139/2000\n",
      "Policy Loss: 0.0399, Value Loss: 0.0003\n",
      "Iteration 1140/2000\n",
      "Policy Loss: 0.0700, Value Loss: 0.0000\n",
      "Iteration 1141/2000\n",
      "Policy Loss: 0.0058, Value Loss: 0.0000\n",
      "Iteration 1142/2000\n",
      "Policy Loss: 0.0115, Value Loss: 0.0000\n",
      "Iteration 1143/2000\n",
      "Policy Loss: 0.0277, Value Loss: 0.0000\n",
      "Iteration 1144/2000\n",
      "Policy Loss: 0.0082, Value Loss: 0.0001\n",
      "Iteration 1145/2000\n",
      "Policy Loss: 0.0091, Value Loss: 0.0000\n",
      "Iteration 1146/2000\n",
      "Policy Loss: 0.0096, Value Loss: 0.0000\n",
      "Iteration 1147/2000\n",
      "Policy Loss: 0.0132, Value Loss: 0.0002\n",
      "Iteration 1148/2000\n",
      "Policy Loss: 0.1393, Value Loss: 0.0000\n",
      "Iteration 1149/2000\n",
      "Policy Loss: 0.0286, Value Loss: 0.0001\n",
      "Iteration 1150/2000\n",
      "Policy Loss: 0.0058, Value Loss: 0.0000\n",
      "Iteration 1151/2000\n",
      "Policy Loss: 0.0049, Value Loss: 0.0002\n",
      "Iteration 1152/2000\n",
      "Policy Loss: 0.3088, Value Loss: 0.0009\n",
      "Iteration 1153/2000\n",
      "Policy Loss: 0.0026, Value Loss: 0.0001\n",
      "Iteration 1154/2000\n",
      "Policy Loss: 0.0071, Value Loss: 0.0000\n",
      "Iteration 1155/2000\n",
      "Policy Loss: 0.2689, Value Loss: 0.0000\n",
      "Iteration 1156/2000\n",
      "Policy Loss: 0.0045, Value Loss: 0.0000\n",
      "Iteration 1157/2000\n",
      "Policy Loss: 0.0029, Value Loss: 0.0000\n",
      "Iteration 1158/2000\n",
      "Policy Loss: 0.0023, Value Loss: 0.0001\n",
      "Iteration 1159/2000\n",
      "Policy Loss: 0.1193, Value Loss: 0.0002\n",
      "Iteration 1160/2000\n",
      "Policy Loss: 0.1573, Value Loss: 0.0004\n",
      "Iteration 1161/2000\n",
      "Policy Loss: 0.0341, Value Loss: 0.0001\n",
      "Iteration 1162/2000\n",
      "Policy Loss: 0.0271, Value Loss: 0.0066\n",
      "Iteration 1163/2000\n",
      "Policy Loss: 0.0047, Value Loss: 0.0000\n",
      "Iteration 1164/2000\n",
      "Policy Loss: 0.0269, Value Loss: 0.0001\n",
      "Iteration 1165/2000\n",
      "Policy Loss: 0.0253, Value Loss: 0.0000\n",
      "Iteration 1166/2000\n",
      "Policy Loss: 0.0042, Value Loss: 0.0003\n",
      "Iteration 1167/2000\n",
      "Policy Loss: 0.0767, Value Loss: 0.0000\n",
      "Iteration 1168/2000\n",
      "Policy Loss: 0.0679, Value Loss: 0.0003\n",
      "Iteration 1169/2000\n",
      "Policy Loss: 0.0366, Value Loss: 0.0000\n",
      "Iteration 1170/2000\n",
      "Policy Loss: 0.0576, Value Loss: 0.0000\n",
      "Iteration 1171/2000\n",
      "Policy Loss: 0.0393, Value Loss: 0.0048\n",
      "Iteration 1172/2000\n",
      "Policy Loss: 0.0337, Value Loss: 0.0001\n",
      "Iteration 1173/2000\n",
      "Policy Loss: 0.0396, Value Loss: 0.0000\n",
      "Iteration 1174/2000\n",
      "Policy Loss: 0.0072, Value Loss: 0.0000\n",
      "Iteration 1175/2000\n",
      "Policy Loss: 0.0270, Value Loss: 0.0000\n",
      "Iteration 1176/2000\n",
      "Policy Loss: 0.0543, Value Loss: 0.0000\n",
      "Iteration 1177/2000\n",
      "Policy Loss: 0.0192, Value Loss: 0.0003\n",
      "Iteration 1178/2000\n",
      "Policy Loss: 0.0171, Value Loss: 0.0000\n",
      "Iteration 1179/2000\n",
      "Policy Loss: 0.0090, Value Loss: 0.0000\n",
      "Iteration 1180/2000\n",
      "Policy Loss: 0.0151, Value Loss: 0.0025\n",
      "Iteration 1181/2000\n",
      "Policy Loss: 0.0097, Value Loss: 0.0000\n",
      "Iteration 1182/2000\n",
      "Policy Loss: 0.0032, Value Loss: 0.0000\n",
      "Iteration 1183/2000\n",
      "Policy Loss: 0.0405, Value Loss: 0.0033\n",
      "Iteration 1184/2000\n",
      "Policy Loss: 0.3971, Value Loss: 0.0000\n",
      "Iteration 1185/2000\n",
      "Policy Loss: 0.0088, Value Loss: 0.0001\n",
      "Iteration 1186/2000\n",
      "Policy Loss: 0.0074, Value Loss: 0.0000\n",
      "Iteration 1187/2000\n",
      "Policy Loss: 0.0260, Value Loss: 0.0017\n",
      "Iteration 1188/2000\n",
      "Policy Loss: 0.1208, Value Loss: 0.0000\n",
      "Iteration 1189/2000\n",
      "Policy Loss: 0.0249, Value Loss: 0.0000\n",
      "Iteration 1190/2000\n",
      "Policy Loss: 0.2034, Value Loss: 0.0000\n",
      "Iteration 1191/2000\n",
      "Policy Loss: 0.0009, Value Loss: 0.0002\n",
      "Iteration 1192/2000\n",
      "Policy Loss: 0.0010, Value Loss: 0.0000\n",
      "Iteration 1193/2000\n",
      "Policy Loss: 0.0051, Value Loss: 0.0037\n",
      "Iteration 1194/2000\n",
      "Policy Loss: 0.0107, Value Loss: 0.0000\n",
      "Iteration 1195/2000\n",
      "Policy Loss: 0.0185, Value Loss: 0.0001\n",
      "Iteration 1196/2000\n",
      "Policy Loss: 0.0044, Value Loss: 0.0000\n",
      "Iteration 1197/2000\n",
      "Policy Loss: 0.0242, Value Loss: 0.0001\n",
      "Iteration 1198/2000\n",
      "Policy Loss: 0.0097, Value Loss: 0.0000\n",
      "Iteration 1199/2000\n",
      "Policy Loss: 0.1307, Value Loss: 0.0000\n",
      "Iteration 1200/2000\n",
      "Policy Loss: 0.1789, Value Loss: 0.0000\n",
      "Iteration 1201/2000\n",
      "Policy Loss: 0.0018, Value Loss: 0.0000\n",
      "Iteration 1202/2000\n",
      "Policy Loss: 0.0053, Value Loss: 0.0000\n",
      "Iteration 1203/2000\n",
      "Policy Loss: 0.1290, Value Loss: 0.0000\n",
      "Iteration 1204/2000\n",
      "Policy Loss: 0.0907, Value Loss: 0.0023\n",
      "Iteration 1205/2000\n",
      "Policy Loss: 0.0027, Value Loss: 0.0001\n",
      "Iteration 1206/2000\n",
      "Policy Loss: 0.0092, Value Loss: 0.0001\n",
      "Iteration 1207/2000\n",
      "Policy Loss: 0.0442, Value Loss: 0.0002\n",
      "Iteration 1208/2000\n",
      "Policy Loss: 0.0889, Value Loss: 0.0000\n",
      "Iteration 1209/2000\n",
      "Policy Loss: 0.0049, Value Loss: 0.0032\n",
      "Iteration 1210/2000\n",
      "Policy Loss: 0.0071, Value Loss: 0.0000\n",
      "Iteration 1211/2000\n",
      "Policy Loss: 0.0037, Value Loss: 0.0000\n",
      "Iteration 1212/2000\n",
      "Policy Loss: 0.1014, Value Loss: 0.0000\n",
      "Iteration 1213/2000\n",
      "Policy Loss: 0.0040, Value Loss: 0.0000\n",
      "Iteration 1214/2000\n",
      "Policy Loss: 0.0037, Value Loss: 0.0000\n",
      "Iteration 1215/2000\n",
      "Policy Loss: 0.2635, Value Loss: 0.0000\n",
      "Iteration 1216/2000\n",
      "Policy Loss: 0.0005, Value Loss: 0.0000\n",
      "Iteration 1217/2000\n",
      "Policy Loss: 0.0028, Value Loss: 0.0000\n",
      "Iteration 1218/2000\n",
      "Policy Loss: 0.1020, Value Loss: 0.0001\n",
      "Iteration 1219/2000\n",
      "Policy Loss: 0.0028, Value Loss: 0.0000\n",
      "Iteration 1220/2000\n",
      "Policy Loss: 0.0146, Value Loss: 0.0000\n",
      "Iteration 1221/2000\n",
      "Policy Loss: 0.0031, Value Loss: 0.0000\n",
      "Iteration 1222/2000\n",
      "Policy Loss: 0.0273, Value Loss: 0.0000\n",
      "Iteration 1223/2000\n",
      "Policy Loss: 0.0037, Value Loss: 0.0036\n",
      "Iteration 1224/2000\n",
      "Policy Loss: 0.0378, Value Loss: 0.0000\n",
      "Iteration 1225/2000\n",
      "Policy Loss: 0.0226, Value Loss: 0.0000\n",
      "Iteration 1226/2000\n",
      "Policy Loss: 0.1215, Value Loss: 0.0000\n",
      "Iteration 1227/2000\n",
      "Policy Loss: 0.0003, Value Loss: 0.0000\n",
      "Iteration 1228/2000\n",
      "Policy Loss: 0.0225, Value Loss: 0.0022\n",
      "Iteration 1229/2000\n",
      "Policy Loss: 0.0004, Value Loss: 0.0084\n",
      "Iteration 1230/2000\n",
      "Policy Loss: 0.0064, Value Loss: 0.0000\n",
      "Iteration 1231/2000\n",
      "Policy Loss: 0.3635, Value Loss: 0.0000\n",
      "Iteration 1232/2000\n",
      "Policy Loss: 0.0016, Value Loss: 0.0000\n",
      "Iteration 1233/2000\n",
      "Policy Loss: 0.1341, Value Loss: 0.0000\n",
      "Iteration 1234/2000\n",
      "Policy Loss: 0.0023, Value Loss: 0.0000\n",
      "Iteration 1235/2000\n",
      "Policy Loss: 0.0682, Value Loss: 0.0004\n",
      "Iteration 1236/2000\n",
      "Policy Loss: 0.0460, Value Loss: 0.0000\n",
      "Iteration 1237/2000\n",
      "Policy Loss: 0.0548, Value Loss: 0.0000\n",
      "Iteration 1238/2000\n",
      "Policy Loss: 0.0040, Value Loss: 0.0002\n",
      "Iteration 1239/2000\n",
      "Policy Loss: 0.0167, Value Loss: 0.0002\n",
      "Iteration 1240/2000\n",
      "Policy Loss: 0.0956, Value Loss: 0.0000\n",
      "Iteration 1241/2000\n",
      "Policy Loss: 0.0021, Value Loss: 0.0000\n",
      "Iteration 1242/2000\n",
      "Policy Loss: 0.1304, Value Loss: 0.0004\n",
      "Iteration 1243/2000\n",
      "Policy Loss: 0.0368, Value Loss: 0.0000\n",
      "Iteration 1244/2000\n",
      "Policy Loss: 0.0045, Value Loss: 0.0000\n",
      "Iteration 1245/2000\n",
      "Policy Loss: 0.0068, Value Loss: 0.0005\n",
      "Iteration 1246/2000\n",
      "Policy Loss: 0.0428, Value Loss: 0.0001\n",
      "Iteration 1247/2000\n",
      "Policy Loss: 0.1642, Value Loss: 0.0000\n",
      "Iteration 1248/2000\n",
      "Policy Loss: 0.0428, Value Loss: 0.0019\n",
      "Iteration 1249/2000\n",
      "Policy Loss: 0.0512, Value Loss: 0.0000\n",
      "Iteration 1250/2000\n",
      "Policy Loss: 0.0882, Value Loss: 0.0000\n",
      "Iteration 1251/2000\n",
      "Policy Loss: 0.0071, Value Loss: 0.0045\n",
      "Iteration 1252/2000\n",
      "Policy Loss: 0.1609, Value Loss: 0.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1253/2000\n",
      "Policy Loss: 0.1229, Value Loss: 0.0014\n",
      "Iteration 1254/2000\n",
      "Policy Loss: 0.1189, Value Loss: 0.0027\n",
      "Iteration 1255/2000\n",
      "Policy Loss: 0.0473, Value Loss: 0.0000\n",
      "Iteration 1256/2000\n",
      "Policy Loss: 0.0060, Value Loss: 0.0000\n",
      "Iteration 1257/2000\n",
      "Policy Loss: 0.0237, Value Loss: 0.0011\n",
      "Iteration 1258/2000\n",
      "Policy Loss: 0.0329, Value Loss: 0.0000\n",
      "Iteration 1259/2000\n",
      "Policy Loss: 0.0256, Value Loss: 0.0000\n",
      "Iteration 1260/2000\n",
      "Policy Loss: 0.0025, Value Loss: 0.0000\n",
      "Iteration 1261/2000\n",
      "Policy Loss: 0.0183, Value Loss: 0.0000\n",
      "Iteration 1262/2000\n",
      "Policy Loss: 0.1107, Value Loss: 0.0000\n",
      "Iteration 1263/2000\n",
      "Policy Loss: 0.0012, Value Loss: 0.0000\n",
      "Iteration 1264/2000\n",
      "Policy Loss: 0.1088, Value Loss: 0.0005\n",
      "Iteration 1265/2000\n",
      "Policy Loss: 0.0131, Value Loss: 0.0000\n",
      "Iteration 1266/2000\n",
      "Policy Loss: 0.0006, Value Loss: 0.0000\n",
      "Iteration 1267/2000\n",
      "Policy Loss: 0.0330, Value Loss: 0.0000\n",
      "Iteration 1268/2000\n",
      "Policy Loss: 0.0711, Value Loss: 0.0000\n",
      "Iteration 1269/2000\n",
      "Policy Loss: 0.0041, Value Loss: 0.0000\n",
      "Iteration 1270/2000\n",
      "Policy Loss: 0.0369, Value Loss: 0.0000\n",
      "Iteration 1271/2000\n",
      "Policy Loss: 0.0374, Value Loss: 0.0000\n",
      "Iteration 1272/2000\n",
      "Policy Loss: 0.0307, Value Loss: 0.0000\n",
      "Iteration 1273/2000\n",
      "Policy Loss: 0.0391, Value Loss: 0.0001\n",
      "Iteration 1274/2000\n",
      "Policy Loss: 0.0652, Value Loss: 0.0000\n",
      "Iteration 1275/2000\n",
      "Policy Loss: 0.0023, Value Loss: 0.0001\n",
      "Iteration 1276/2000\n",
      "Policy Loss: 0.0292, Value Loss: 0.0000\n",
      "Iteration 1277/2000\n",
      "Policy Loss: 0.1409, Value Loss: 0.0000\n",
      "Iteration 1278/2000\n",
      "Policy Loss: 0.1065, Value Loss: 0.0001\n",
      "Iteration 1279/2000\n",
      "Policy Loss: 0.0166, Value Loss: 0.0001\n",
      "Iteration 1280/2000\n",
      "Policy Loss: 0.0203, Value Loss: 0.0072\n",
      "Iteration 1281/2000\n",
      "Policy Loss: 0.0151, Value Loss: 0.0002\n",
      "Iteration 1282/2000\n",
      "Policy Loss: 0.0039, Value Loss: 0.0033\n",
      "Iteration 1283/2000\n",
      "Policy Loss: 0.1298, Value Loss: 0.0000\n",
      "Iteration 1284/2000\n",
      "Policy Loss: 0.0185, Value Loss: 0.0007\n",
      "Iteration 1285/2000\n",
      "Policy Loss: 0.0132, Value Loss: 0.0000\n",
      "Iteration 1286/2000\n",
      "Policy Loss: 0.0049, Value Loss: 0.0000\n",
      "Iteration 1287/2000\n",
      "Policy Loss: 0.0372, Value Loss: 0.0001\n",
      "Iteration 1288/2000\n",
      "Policy Loss: 0.1618, Value Loss: 0.0000\n",
      "Iteration 1289/2000\n",
      "Policy Loss: 0.1112, Value Loss: 0.0000\n",
      "Iteration 1290/2000\n",
      "Policy Loss: 0.0189, Value Loss: 0.0000\n",
      "Iteration 1291/2000\n",
      "Policy Loss: 0.0011, Value Loss: 0.0000\n",
      "Iteration 1292/2000\n",
      "Policy Loss: 0.0120, Value Loss: 0.0000\n",
      "Iteration 1293/2000\n",
      "Policy Loss: 0.1284, Value Loss: 0.0002\n",
      "Iteration 1294/2000\n",
      "Policy Loss: 0.0032, Value Loss: 0.0034\n",
      "Iteration 1295/2000\n",
      "Policy Loss: 0.0245, Value Loss: 0.0000\n",
      "Iteration 1296/2000\n",
      "Policy Loss: 0.0235, Value Loss: 0.0004\n",
      "Iteration 1297/2000\n",
      "Policy Loss: 0.0020, Value Loss: 0.0000\n",
      "Iteration 1298/2000\n",
      "Policy Loss: 0.0274, Value Loss: 0.0000\n",
      "Iteration 1299/2000\n",
      "Policy Loss: 0.0020, Value Loss: 0.0000\n",
      "Iteration 1300/2000\n",
      "Policy Loss: 0.0689, Value Loss: 0.0000\n",
      "Iteration 1301/2000\n",
      "Policy Loss: 0.0011, Value Loss: 0.0001\n",
      "Iteration 1302/2000\n",
      "Policy Loss: 0.0267, Value Loss: 0.0000\n",
      "Iteration 1303/2000\n",
      "Policy Loss: 0.0729, Value Loss: 0.0001\n",
      "Iteration 1304/2000\n",
      "Policy Loss: 0.0286, Value Loss: 0.0000\n",
      "Iteration 1305/2000\n",
      "Policy Loss: 0.0020, Value Loss: 0.0000\n",
      "Iteration 1306/2000\n",
      "Policy Loss: 0.0338, Value Loss: 0.0000\n",
      "Iteration 1307/2000\n",
      "Policy Loss: 0.0275, Value Loss: 0.0000\n",
      "Iteration 1308/2000\n",
      "Policy Loss: 0.0010, Value Loss: 0.0004\n",
      "Iteration 1309/2000\n",
      "Policy Loss: 0.1904, Value Loss: 0.0015\n",
      "Iteration 1310/2000\n",
      "Policy Loss: 0.0214, Value Loss: 0.0000\n",
      "Iteration 1311/2000\n",
      "Policy Loss: 0.1016, Value Loss: 0.0000\n",
      "Iteration 1312/2000\n",
      "Policy Loss: 0.0887, Value Loss: 0.0000\n",
      "Iteration 1313/2000\n",
      "Policy Loss: 0.0281, Value Loss: 0.0001\n",
      "Iteration 1314/2000\n",
      "Policy Loss: 0.0010, Value Loss: 0.0000\n",
      "Iteration 1315/2000\n",
      "Policy Loss: 0.0874, Value Loss: 0.0000\n",
      "Iteration 1316/2000\n",
      "Policy Loss: 0.0508, Value Loss: 0.0001\n",
      "Iteration 1317/2000\n",
      "Policy Loss: 0.0069, Value Loss: 0.0000\n",
      "Iteration 1318/2000\n",
      "Policy Loss: 0.0357, Value Loss: 0.0039\n",
      "Iteration 1319/2000\n",
      "Policy Loss: 0.0005, Value Loss: 0.0003\n",
      "Iteration 1320/2000\n",
      "Policy Loss: 0.0004, Value Loss: 0.0008\n",
      "Iteration 1321/2000\n",
      "Policy Loss: 0.0016, Value Loss: 0.0001\n",
      "Iteration 1322/2000\n",
      "Policy Loss: 0.0127, Value Loss: 0.0000\n",
      "Iteration 1323/2000\n",
      "Policy Loss: 0.0698, Value Loss: 0.0000\n",
      "Iteration 1324/2000\n",
      "Policy Loss: 0.0036, Value Loss: 0.0000\n",
      "Iteration 1325/2000\n",
      "Policy Loss: 0.0015, Value Loss: 0.0003\n",
      "Iteration 1326/2000\n",
      "Policy Loss: 0.1048, Value Loss: 0.0003\n",
      "Iteration 1327/2000\n",
      "Policy Loss: 0.0030, Value Loss: 0.0000\n",
      "Iteration 1328/2000\n",
      "Policy Loss: 0.0006, Value Loss: 0.0025\n",
      "Iteration 1329/2000\n",
      "Policy Loss: 0.0016, Value Loss: 0.0000\n",
      "Iteration 1330/2000\n",
      "Policy Loss: 0.0261, Value Loss: 0.0152\n",
      "Iteration 1331/2000\n",
      "Policy Loss: 0.0788, Value Loss: 0.0002\n",
      "Iteration 1332/2000\n",
      "Policy Loss: 0.0465, Value Loss: 0.0003\n",
      "Iteration 1333/2000\n",
      "Policy Loss: 0.0808, Value Loss: 0.0000\n",
      "Iteration 1334/2000\n",
      "Policy Loss: 0.0244, Value Loss: 0.0000\n",
      "Iteration 1335/2000\n",
      "Policy Loss: 0.0259, Value Loss: 0.0000\n",
      "Iteration 1336/2000\n",
      "Policy Loss: 0.0713, Value Loss: 0.0000\n",
      "Iteration 1337/2000\n",
      "Policy Loss: 0.0027, Value Loss: 0.0000\n",
      "Iteration 1338/2000\n",
      "Policy Loss: 0.0040, Value Loss: 0.0000\n",
      "Iteration 1339/2000\n",
      "Policy Loss: 0.0492, Value Loss: 0.0000\n",
      "Iteration 1340/2000\n",
      "Policy Loss: 0.0036, Value Loss: 0.0000\n",
      "Iteration 1341/2000\n",
      "Policy Loss: 0.0605, Value Loss: 0.0000\n",
      "Iteration 1342/2000\n",
      "Policy Loss: 0.0001, Value Loss: 0.0000\n",
      "Iteration 1343/2000\n",
      "Policy Loss: 0.0676, Value Loss: 0.0401\n",
      "Iteration 1344/2000\n",
      "Policy Loss: 0.0018, Value Loss: 0.0000\n",
      "Iteration 1345/2000\n",
      "Policy Loss: 0.0215, Value Loss: 0.0276\n",
      "Iteration 1346/2000\n",
      "Policy Loss: 0.0870, Value Loss: 0.0000\n",
      "Iteration 1347/2000\n",
      "Policy Loss: 0.0822, Value Loss: 0.0000\n",
      "Iteration 1348/2000\n",
      "Policy Loss: 0.0422, Value Loss: 0.0000\n",
      "Iteration 1349/2000\n",
      "Policy Loss: 0.0003, Value Loss: 0.0000\n",
      "Iteration 1350/2000\n",
      "Policy Loss: 0.0451, Value Loss: 0.0000\n",
      "Iteration 1351/2000\n",
      "Policy Loss: 0.0397, Value Loss: 0.0010\n",
      "Iteration 1352/2000\n",
      "Policy Loss: 0.0010, Value Loss: 0.0038\n",
      "Iteration 1353/2000\n",
      "Policy Loss: 0.0009, Value Loss: 0.0000\n",
      "Iteration 1354/2000\n",
      "Policy Loss: 0.0246, Value Loss: 0.0061\n",
      "Iteration 1355/2000\n",
      "Policy Loss: 0.0009, Value Loss: 0.0001\n",
      "Iteration 1356/2000\n",
      "Policy Loss: 0.0144, Value Loss: 0.0009\n",
      "Iteration 1357/2000\n",
      "Policy Loss: 0.0114, Value Loss: 0.0000\n",
      "Iteration 1358/2000\n",
      "Policy Loss: 0.0006, Value Loss: 0.0000\n",
      "Iteration 1359/2000\n",
      "Policy Loss: 0.1344, Value Loss: 0.0007\n",
      "Iteration 1360/2000\n",
      "Policy Loss: 0.1235, Value Loss: 0.0041\n",
      "Iteration 1361/2000\n",
      "Policy Loss: 0.0005, Value Loss: 0.0000\n",
      "Iteration 1362/2000\n",
      "Policy Loss: 0.0014, Value Loss: 0.0000\n",
      "Iteration 1363/2000\n",
      "Policy Loss: 0.0015, Value Loss: 0.0002\n",
      "Iteration 1364/2000\n",
      "Policy Loss: 0.0118, Value Loss: 0.0000\n",
      "Iteration 1365/2000\n",
      "Policy Loss: 0.0010, Value Loss: 0.0026\n",
      "Iteration 1366/2000\n",
      "Policy Loss: 0.0006, Value Loss: 0.0013\n",
      "Iteration 1367/2000\n",
      "Policy Loss: 0.0049, Value Loss: 0.0085\n",
      "Iteration 1368/2000\n",
      "Policy Loss: 0.0041, Value Loss: 0.0000\n",
      "Iteration 1369/2000\n",
      "Policy Loss: 0.0012, Value Loss: 0.0000\n",
      "Iteration 1370/2000\n",
      "Policy Loss: 0.0009, Value Loss: 0.0002\n",
      "Iteration 1371/2000\n",
      "Policy Loss: 0.0259, Value Loss: 0.0007\n",
      "Iteration 1372/2000\n",
      "Policy Loss: 0.2481, Value Loss: 0.0000\n",
      "Iteration 1373/2000\n",
      "Policy Loss: 0.0030, Value Loss: 0.0001\n",
      "Iteration 1374/2000\n",
      "Policy Loss: 0.0008, Value Loss: 0.0000\n",
      "Iteration 1375/2000\n",
      "Policy Loss: 0.0055, Value Loss: 0.0000\n",
      "Iteration 1376/2000\n",
      "Policy Loss: 0.1200, Value Loss: 0.0000\n",
      "Iteration 1377/2000\n",
      "Policy Loss: 0.0009, Value Loss: 0.0047\n",
      "Iteration 1378/2000\n",
      "Policy Loss: 0.0012, Value Loss: 0.0003\n",
      "Iteration 1379/2000\n",
      "Policy Loss: 0.0015, Value Loss: 0.0002\n",
      "Iteration 1380/2000\n",
      "Policy Loss: 0.0023, Value Loss: 0.0000\n",
      "Iteration 1381/2000\n",
      "Policy Loss: 0.0012, Value Loss: 0.0002\n",
      "Iteration 1382/2000\n",
      "Policy Loss: 0.0124, Value Loss: 0.0000\n",
      "Iteration 1383/2000\n",
      "Policy Loss: 0.0127, Value Loss: 0.0001\n",
      "Iteration 1384/2000\n",
      "Policy Loss: 0.0181, Value Loss: 0.0002\n",
      "Iteration 1385/2000\n",
      "Policy Loss: 0.0028, Value Loss: 0.0001\n",
      "Iteration 1386/2000\n",
      "Policy Loss: 0.0012, Value Loss: 0.0000\n",
      "Iteration 1387/2000\n",
      "Policy Loss: 0.0097, Value Loss: 0.0001\n",
      "Iteration 1388/2000\n",
      "Policy Loss: 0.0224, Value Loss: 0.0000\n",
      "Iteration 1389/2000\n",
      "Policy Loss: 0.0012, Value Loss: 0.0001\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1390/2000\n",
      "Policy Loss: 0.0014, Value Loss: 0.0009\n",
      "Iteration 1391/2000\n",
      "Policy Loss: 0.0086, Value Loss: 0.0005\n",
      "Iteration 1392/2000\n",
      "Policy Loss: 0.0150, Value Loss: 0.0001\n",
      "Iteration 1393/2000\n",
      "Policy Loss: 0.0086, Value Loss: 0.0001\n",
      "Iteration 1394/2000\n",
      "Policy Loss: 0.0120, Value Loss: 0.0038\n",
      "Iteration 1395/2000\n",
      "Policy Loss: 0.0012, Value Loss: 0.0003\n",
      "Iteration 1396/2000\n",
      "Policy Loss: 0.0038, Value Loss: 0.0002\n",
      "Iteration 1397/2000\n",
      "Policy Loss: 0.1917, Value Loss: 0.0000\n",
      "Iteration 1398/2000\n",
      "Policy Loss: 0.1338, Value Loss: 0.0000\n",
      "Iteration 1399/2000\n",
      "Policy Loss: 0.0007, Value Loss: 0.0000\n",
      "Iteration 1400/2000\n",
      "Policy Loss: 0.0009, Value Loss: 0.0000\n",
      "Iteration 1401/2000\n",
      "Policy Loss: 0.0069, Value Loss: 0.0004\n",
      "Iteration 1402/2000\n",
      "Policy Loss: 0.1426, Value Loss: 0.0009\n",
      "Iteration 1403/2000\n",
      "Policy Loss: 0.0130, Value Loss: 0.0000\n",
      "Iteration 1404/2000\n",
      "Policy Loss: 0.0034, Value Loss: 0.0000\n",
      "Iteration 1405/2000\n",
      "Policy Loss: 0.0022, Value Loss: 0.0000\n",
      "Iteration 1406/2000\n",
      "Policy Loss: 0.0802, Value Loss: 0.0000\n",
      "Iteration 1407/2000\n",
      "Policy Loss: 0.0710, Value Loss: 0.0000\n",
      "Iteration 1408/2000\n",
      "Policy Loss: 0.0019, Value Loss: 0.0000\n",
      "Iteration 1409/2000\n",
      "Policy Loss: 0.0011, Value Loss: 0.0005\n",
      "Iteration 1410/2000\n",
      "Policy Loss: 0.1390, Value Loss: 0.0000\n",
      "Iteration 1411/2000\n",
      "Policy Loss: 0.0013, Value Loss: 0.0003\n",
      "Iteration 1412/2000\n",
      "Policy Loss: 0.2101, Value Loss: 0.0000\n",
      "Iteration 1413/2000\n",
      "Policy Loss: 0.0707, Value Loss: 0.0000\n",
      "Iteration 1414/2000\n",
      "Policy Loss: 0.0461, Value Loss: 0.0000\n",
      "Iteration 1415/2000\n",
      "Policy Loss: 0.0003, Value Loss: 0.0016\n",
      "Iteration 1416/2000\n",
      "Policy Loss: 0.0498, Value Loss: 0.0000\n",
      "Iteration 1417/2000\n",
      "Policy Loss: 0.0023, Value Loss: 0.0002\n",
      "Iteration 1418/2000\n",
      "Policy Loss: 0.0597, Value Loss: 0.0000\n",
      "Iteration 1419/2000\n",
      "Policy Loss: 0.0599, Value Loss: 0.0012\n",
      "Iteration 1420/2000\n",
      "Policy Loss: 0.0032, Value Loss: 0.0000\n",
      "Iteration 1421/2000\n",
      "Policy Loss: 0.0008, Value Loss: 0.0000\n",
      "Iteration 1422/2000\n",
      "Policy Loss: 0.0425, Value Loss: 0.0000\n",
      "Iteration 1423/2000\n",
      "Policy Loss: 0.0026, Value Loss: 0.0027\n",
      "Iteration 1424/2000\n",
      "Policy Loss: 0.0379, Value Loss: 0.0000\n",
      "Iteration 1425/2000\n",
      "Policy Loss: 0.0291, Value Loss: 0.0000\n",
      "Iteration 1426/2000\n",
      "Policy Loss: 0.0588, Value Loss: 0.0000\n",
      "Iteration 1427/2000\n",
      "Policy Loss: 0.0229, Value Loss: 0.0000\n",
      "Iteration 1428/2000\n",
      "Policy Loss: 0.1939, Value Loss: 0.0000\n",
      "Iteration 1429/2000\n",
      "Policy Loss: 0.1097, Value Loss: 0.0000\n",
      "Iteration 1430/2000\n",
      "Policy Loss: 0.0013, Value Loss: 0.0009\n",
      "Iteration 1431/2000\n",
      "Policy Loss: 0.0005, Value Loss: 0.0001\n",
      "Iteration 1432/2000\n",
      "Policy Loss: 0.0164, Value Loss: 0.0002\n",
      "Iteration 1433/2000\n",
      "Policy Loss: 0.0030, Value Loss: 0.0002\n",
      "Iteration 1434/2000\n",
      "Policy Loss: 0.1197, Value Loss: 0.0000\n",
      "Iteration 1435/2000\n",
      "Policy Loss: 0.0010, Value Loss: 0.0002\n",
      "Iteration 1436/2000\n",
      "Policy Loss: 0.0003, Value Loss: 0.0008\n",
      "Iteration 1437/2000\n",
      "Policy Loss: 0.0031, Value Loss: 0.0000\n",
      "Iteration 1438/2000\n",
      "Policy Loss: 0.0944, Value Loss: 0.0000\n",
      "Iteration 1439/2000\n",
      "Policy Loss: 0.1393, Value Loss: 0.0001\n",
      "Iteration 1440/2000\n",
      "Policy Loss: 0.1285, Value Loss: 0.0000\n",
      "Iteration 1441/2000\n",
      "Policy Loss: 0.0006, Value Loss: 0.0001\n",
      "Iteration 1442/2000\n",
      "Policy Loss: 0.0579, Value Loss: 0.0000\n",
      "Iteration 1443/2000\n",
      "Policy Loss: 0.0663, Value Loss: 0.0000\n",
      "Iteration 1444/2000\n",
      "Policy Loss: 0.0018, Value Loss: 0.0002\n",
      "Iteration 1445/2000\n",
      "Policy Loss: 0.0038, Value Loss: 0.0000\n",
      "Iteration 1446/2000\n",
      "Policy Loss: 0.0007, Value Loss: 0.0002\n",
      "Iteration 1447/2000\n",
      "Policy Loss: 0.0904, Value Loss: 0.0000\n",
      "Iteration 1448/2000\n",
      "Policy Loss: 0.0184, Value Loss: 0.0000\n",
      "Iteration 1449/2000\n",
      "Policy Loss: 0.0038, Value Loss: 0.0000\n",
      "Iteration 1450/2000\n",
      "Policy Loss: 0.0354, Value Loss: 0.0003\n",
      "Iteration 1451/2000\n",
      "Policy Loss: 0.1125, Value Loss: 0.0001\n",
      "Iteration 1452/2000\n",
      "Policy Loss: 0.0011, Value Loss: 0.0000\n",
      "Iteration 1453/2000\n",
      "Policy Loss: 0.0862, Value Loss: 0.0000\n",
      "Iteration 1454/2000\n",
      "Policy Loss: 0.0013, Value Loss: 0.0000\n",
      "Iteration 1455/2000\n",
      "Policy Loss: 0.0007, Value Loss: 0.0000\n",
      "Iteration 1456/2000\n",
      "Policy Loss: 0.0006, Value Loss: 0.0000\n",
      "Iteration 1457/2000\n",
      "Policy Loss: 0.0075, Value Loss: 0.0000\n",
      "Iteration 1458/2000\n",
      "Policy Loss: 0.0022, Value Loss: 0.0000\n",
      "Iteration 1459/2000\n",
      "Policy Loss: 0.0333, Value Loss: 0.0000\n",
      "Iteration 1460/2000\n",
      "Policy Loss: 0.0363, Value Loss: 0.0002\n",
      "Iteration 1461/2000\n",
      "Policy Loss: 0.0145, Value Loss: 0.0000\n",
      "Iteration 1462/2000\n",
      "Policy Loss: 0.0003, Value Loss: 0.0000\n",
      "Iteration 1463/2000\n",
      "Policy Loss: 0.0682, Value Loss: 0.0000\n",
      "Iteration 1464/2000\n",
      "Policy Loss: 0.0454, Value Loss: 0.0001\n",
      "Iteration 1465/2000\n",
      "Policy Loss: 0.0164, Value Loss: 0.0000\n",
      "Iteration 1466/2000\n",
      "Policy Loss: 0.0013, Value Loss: 0.0001\n",
      "Iteration 1467/2000\n",
      "Policy Loss: 0.0014, Value Loss: 0.0000\n",
      "Iteration 1468/2000\n",
      "Policy Loss: 0.1534, Value Loss: 0.0000\n",
      "Iteration 1469/2000\n",
      "Policy Loss: 0.0021, Value Loss: 0.0000\n",
      "Iteration 1470/2000\n",
      "Policy Loss: 0.0012, Value Loss: 0.0000\n",
      "Iteration 1471/2000\n",
      "Policy Loss: 0.0006, Value Loss: 0.0000\n",
      "Iteration 1472/2000\n",
      "Policy Loss: 0.0018, Value Loss: 0.0000\n",
      "Iteration 1473/2000\n",
      "Policy Loss: 0.0168, Value Loss: 0.0000\n",
      "Iteration 1474/2000\n",
      "Policy Loss: 0.0159, Value Loss: 0.0000\n",
      "Iteration 1475/2000\n",
      "Policy Loss: 0.0149, Value Loss: 0.0000\n",
      "Iteration 1476/2000\n",
      "Policy Loss: 0.2646, Value Loss: 0.0001\n",
      "Iteration 1477/2000\n",
      "Policy Loss: 0.1104, Value Loss: 0.0000\n",
      "Iteration 1478/2000\n",
      "Policy Loss: 0.0173, Value Loss: 0.0000\n",
      "Iteration 1479/2000\n",
      "Policy Loss: 0.0174, Value Loss: 0.0000\n",
      "Iteration 1480/2000\n",
      "Policy Loss: 0.0022, Value Loss: 0.0000\n",
      "Iteration 1481/2000\n",
      "Policy Loss: 0.2396, Value Loss: 0.0000\n",
      "Iteration 1482/2000\n",
      "Policy Loss: 0.0835, Value Loss: 0.0000\n",
      "Iteration 1483/2000\n",
      "Policy Loss: 0.0025, Value Loss: 0.0000\n",
      "Iteration 1484/2000\n",
      "Policy Loss: 0.0952, Value Loss: 0.0007\n",
      "Iteration 1485/2000\n",
      "Policy Loss: 0.0121, Value Loss: 0.0000\n",
      "Iteration 1486/2000\n",
      "Policy Loss: 0.0014, Value Loss: 0.0000\n",
      "Iteration 1487/2000\n",
      "Policy Loss: 0.0595, Value Loss: 0.0001\n",
      "Iteration 1488/2000\n",
      "Policy Loss: 0.0387, Value Loss: 0.0000\n",
      "Iteration 1489/2000\n",
      "Policy Loss: 0.0342, Value Loss: 0.0000\n",
      "Iteration 1490/2000\n",
      "Policy Loss: 0.0007, Value Loss: 0.0001\n",
      "Iteration 1491/2000\n",
      "Policy Loss: 0.0196, Value Loss: 0.0000\n",
      "Iteration 1492/2000\n",
      "Policy Loss: 0.0020, Value Loss: 0.0000\n",
      "Iteration 1493/2000\n",
      "Policy Loss: 0.0389, Value Loss: 0.0000\n",
      "Iteration 1494/2000\n",
      "Policy Loss: 0.0011, Value Loss: 0.0001\n",
      "Iteration 1495/2000\n",
      "Policy Loss: 0.0007, Value Loss: 0.0000\n",
      "Iteration 1496/2000\n",
      "Policy Loss: 0.1285, Value Loss: 0.0001\n",
      "Iteration 1497/2000\n",
      "Policy Loss: 0.0023, Value Loss: 0.0000\n",
      "Iteration 1498/2000\n",
      "Policy Loss: 0.0034, Value Loss: 0.0001\n",
      "Iteration 1499/2000\n",
      "Policy Loss: 0.0165, Value Loss: 0.0000\n",
      "Iteration 1500/2000\n",
      "Policy Loss: 0.0012, Value Loss: 0.0000\n",
      "Iteration 1501/2000\n",
      "Policy Loss: 0.0014, Value Loss: 0.0000\n",
      "Iteration 1502/2000\n",
      "Policy Loss: 0.1083, Value Loss: 0.0000\n",
      "Iteration 1503/2000\n",
      "Policy Loss: 0.0008, Value Loss: 0.0000\n",
      "Iteration 1504/2000\n",
      "Policy Loss: 0.0020, Value Loss: 0.0002\n",
      "Iteration 1505/2000\n",
      "Policy Loss: 0.0284, Value Loss: 0.0000\n",
      "Iteration 1506/2000\n",
      "Policy Loss: 0.0005, Value Loss: 0.0004\n",
      "Iteration 1507/2000\n",
      "Policy Loss: 0.0005, Value Loss: 0.0000\n",
      "Iteration 1508/2000\n",
      "Policy Loss: 0.0008, Value Loss: 0.0000\n",
      "Iteration 1509/2000\n",
      "Policy Loss: 0.1226, Value Loss: 0.0000\n",
      "Iteration 1510/2000\n",
      "Policy Loss: 0.0339, Value Loss: 0.0000\n",
      "Iteration 1511/2000\n",
      "Policy Loss: 0.0032, Value Loss: 0.0002\n",
      "Iteration 1512/2000\n",
      "Policy Loss: 0.0346, Value Loss: 0.0000\n",
      "Iteration 1513/2000\n",
      "Policy Loss: 0.0030, Value Loss: 0.0000\n",
      "Iteration 1514/2000\n",
      "Policy Loss: 0.0003, Value Loss: 0.0000\n",
      "Iteration 1515/2000\n",
      "Policy Loss: 0.0059, Value Loss: 0.0001\n",
      "Iteration 1516/2000\n",
      "Policy Loss: 0.0667, Value Loss: 0.0000\n",
      "Iteration 1517/2000\n",
      "Policy Loss: 0.0025, Value Loss: 0.0000\n",
      "Iteration 1518/2000\n",
      "Policy Loss: 0.0006, Value Loss: 0.0003\n",
      "Iteration 1519/2000\n",
      "Policy Loss: 0.0009, Value Loss: 0.0000\n",
      "Iteration 1520/2000\n",
      "Policy Loss: 0.0348, Value Loss: 0.0000\n",
      "Iteration 1521/2000\n",
      "Policy Loss: 0.0338, Value Loss: 0.0000\n",
      "Iteration 1522/2000\n",
      "Policy Loss: 0.0224, Value Loss: 0.0000\n",
      "Iteration 1523/2000\n",
      "Policy Loss: 0.0019, Value Loss: 0.0000\n",
      "Iteration 1524/2000\n",
      "Policy Loss: 0.0011, Value Loss: 0.0000\n",
      "Iteration 1525/2000\n",
      "Policy Loss: 0.0180, Value Loss: 0.0000\n",
      "Iteration 1526/2000\n",
      "Policy Loss: 0.0010, Value Loss: 0.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1527/2000\n",
      "Policy Loss: 0.0008, Value Loss: 0.0000\n",
      "Iteration 1528/2000\n",
      "Policy Loss: 0.1026, Value Loss: 0.0000\n",
      "Iteration 1529/2000\n",
      "Policy Loss: 0.0006, Value Loss: 0.0000\n",
      "Iteration 1530/2000\n",
      "Policy Loss: 0.0013, Value Loss: 0.0001\n",
      "Iteration 1531/2000\n",
      "Policy Loss: 0.0010, Value Loss: 0.0000\n",
      "Iteration 1532/2000\n",
      "Policy Loss: 0.0007, Value Loss: 0.0000\n",
      "Iteration 1533/2000\n",
      "Policy Loss: 0.0469, Value Loss: 0.0001\n",
      "Iteration 1534/2000\n",
      "Policy Loss: 0.1022, Value Loss: 0.0000\n",
      "Iteration 1535/2000\n",
      "Policy Loss: 0.0203, Value Loss: 0.0003\n",
      "Iteration 1536/2000\n",
      "Policy Loss: 0.0021, Value Loss: 0.0000\n",
      "Iteration 1537/2000\n",
      "Policy Loss: 0.0012, Value Loss: 0.0000\n",
      "Iteration 1538/2000\n",
      "Policy Loss: 0.0015, Value Loss: 0.0000\n",
      "Iteration 1539/2000\n",
      "Policy Loss: 0.0679, Value Loss: 0.0000\n",
      "Iteration 1540/2000\n",
      "Policy Loss: 0.0336, Value Loss: 0.0000\n",
      "Iteration 1541/2000\n",
      "Policy Loss: 0.0014, Value Loss: 0.0000\n",
      "Iteration 1542/2000\n",
      "Policy Loss: 0.0010, Value Loss: 0.0001\n",
      "Iteration 1543/2000\n",
      "Policy Loss: 0.0098, Value Loss: 0.0000\n",
      "Iteration 1544/2000\n",
      "Policy Loss: 0.0484, Value Loss: 0.0000\n",
      "Iteration 1545/2000\n",
      "Policy Loss: 0.1391, Value Loss: 0.0000\n",
      "Iteration 1546/2000\n",
      "Policy Loss: 0.2562, Value Loss: 0.0000\n",
      "Iteration 1547/2000\n",
      "Policy Loss: 0.0568, Value Loss: 0.0000\n",
      "Iteration 1548/2000\n",
      "Policy Loss: 0.0459, Value Loss: 0.0000\n",
      "Iteration 1549/2000\n",
      "Policy Loss: 0.0006, Value Loss: 0.0000\n",
      "Iteration 1550/2000\n",
      "Policy Loss: 0.0008, Value Loss: 0.0000\n",
      "Iteration 1551/2000\n",
      "Policy Loss: 0.0003, Value Loss: 0.0000\n",
      "Iteration 1552/2000\n",
      "Policy Loss: 0.0001, Value Loss: 0.0000\n",
      "Iteration 1553/2000\n",
      "Policy Loss: 0.0003, Value Loss: 0.0000\n",
      "Iteration 1554/2000\n",
      "Policy Loss: 0.0017, Value Loss: 0.0002\n",
      "Iteration 1555/2000\n",
      "Policy Loss: 0.0004, Value Loss: 0.0000\n",
      "Iteration 1556/2000\n",
      "Policy Loss: 0.0296, Value Loss: 0.0000\n",
      "Iteration 1557/2000\n",
      "Policy Loss: 0.0292, Value Loss: 0.0000\n",
      "Iteration 1558/2000\n",
      "Policy Loss: 0.0373, Value Loss: 0.0000\n",
      "Iteration 1559/2000\n",
      "Policy Loss: 0.0050, Value Loss: 0.0000\n",
      "Iteration 1560/2000\n",
      "Policy Loss: 0.0124, Value Loss: 0.0000\n",
      "Iteration 1561/2000\n",
      "Policy Loss: 0.1937, Value Loss: 0.0000\n",
      "Iteration 1562/2000\n",
      "Policy Loss: 0.0004, Value Loss: 0.0000\n",
      "Iteration 1563/2000\n",
      "Policy Loss: 0.0001, Value Loss: 0.0000\n",
      "Iteration 1564/2000\n",
      "Policy Loss: 0.0036, Value Loss: 0.0000\n",
      "Iteration 1565/2000\n",
      "Policy Loss: 0.2198, Value Loss: 0.0000\n",
      "Iteration 1566/2000\n",
      "Policy Loss: 0.0010, Value Loss: 0.0001\n",
      "Iteration 1567/2000\n",
      "Policy Loss: 0.0015, Value Loss: 0.0000\n",
      "Iteration 1568/2000\n",
      "Policy Loss: 0.0295, Value Loss: 0.0001\n",
      "Iteration 1569/2000\n",
      "Policy Loss: 0.0062, Value Loss: 0.0000\n",
      "Iteration 1570/2000\n",
      "Policy Loss: 0.0133, Value Loss: 0.0000\n",
      "Iteration 1571/2000\n",
      "Policy Loss: 0.0025, Value Loss: 0.0001\n",
      "Iteration 1572/2000\n",
      "Policy Loss: 0.1279, Value Loss: 0.0000\n",
      "Iteration 1573/2000\n",
      "Policy Loss: 0.0051, Value Loss: 0.0000\n",
      "Iteration 1574/2000\n",
      "Policy Loss: 0.0006, Value Loss: 0.0001\n",
      "Iteration 1575/2000\n",
      "Policy Loss: 0.0114, Value Loss: 0.0000\n",
      "Iteration 1576/2000\n",
      "Policy Loss: 0.0050, Value Loss: 0.0000\n",
      "Iteration 1577/2000\n",
      "Policy Loss: 0.0044, Value Loss: 0.0000\n",
      "Iteration 1578/2000\n",
      "Policy Loss: 0.0003, Value Loss: 0.0000\n",
      "Iteration 1579/2000\n",
      "Policy Loss: 0.0013, Value Loss: 0.0001\n",
      "Iteration 1580/2000\n",
      "Policy Loss: 0.0011, Value Loss: 0.0000\n",
      "Iteration 1581/2000\n",
      "Policy Loss: 0.1231, Value Loss: 0.0002\n",
      "Iteration 1582/2000\n",
      "Policy Loss: 0.0160, Value Loss: 0.0000\n",
      "Iteration 1583/2000\n",
      "Policy Loss: 0.0021, Value Loss: 0.0000\n",
      "Iteration 1584/2000\n",
      "Policy Loss: 0.0007, Value Loss: 0.0000\n",
      "Iteration 1585/2000\n",
      "Policy Loss: 0.0384, Value Loss: 0.0000\n",
      "Iteration 1586/2000\n",
      "Policy Loss: 0.0030, Value Loss: 0.0002\n",
      "Iteration 1587/2000\n",
      "Policy Loss: 0.0027, Value Loss: 0.0000\n",
      "Iteration 1588/2000\n",
      "Policy Loss: 0.0027, Value Loss: 0.0000\n",
      "Iteration 1589/2000\n",
      "Policy Loss: 0.0023, Value Loss: 0.0001\n",
      "Iteration 1590/2000\n",
      "Policy Loss: 0.0327, Value Loss: 0.0001\n",
      "Iteration 1591/2000\n",
      "Policy Loss: 0.0006, Value Loss: 0.0000\n",
      "Iteration 1592/2000\n",
      "Policy Loss: 0.0005, Value Loss: 0.0000\n",
      "Iteration 1593/2000\n",
      "Policy Loss: 0.0004, Value Loss: 0.0015\n",
      "Iteration 1594/2000\n",
      "Policy Loss: 0.0039, Value Loss: 0.0000\n",
      "Iteration 1595/2000\n",
      "Policy Loss: 0.0236, Value Loss: 0.0000\n",
      "Iteration 1596/2000\n",
      "Policy Loss: 0.0029, Value Loss: 0.0000\n",
      "Iteration 1597/2000\n",
      "Policy Loss: 0.0010, Value Loss: 0.0000\n",
      "Iteration 1598/2000\n",
      "Policy Loss: 0.0021, Value Loss: 0.0000\n",
      "Iteration 1599/2000\n",
      "Policy Loss: 0.0013, Value Loss: 0.0000\n",
      "Iteration 1600/2000\n",
      "Policy Loss: 0.1292, Value Loss: 0.0000\n",
      "Iteration 1601/2000\n",
      "Policy Loss: 0.0291, Value Loss: 0.0000\n",
      "Iteration 1602/2000\n",
      "Policy Loss: 0.0015, Value Loss: 0.0000\n",
      "Iteration 1603/2000\n",
      "Policy Loss: 0.0508, Value Loss: 0.0000\n",
      "Iteration 1604/2000\n",
      "Policy Loss: 0.0137, Value Loss: 0.0000\n",
      "Iteration 1605/2000\n",
      "Policy Loss: 0.0116, Value Loss: 0.0005\n",
      "Iteration 1606/2000\n",
      "Policy Loss: 0.0373, Value Loss: 0.0000\n",
      "Iteration 1607/2000\n",
      "Policy Loss: 0.0008, Value Loss: 0.0000\n",
      "Iteration 1608/2000\n",
      "Policy Loss: 0.0013, Value Loss: 0.0000\n",
      "Iteration 1609/2000\n",
      "Policy Loss: 0.0012, Value Loss: 0.0000\n",
      "Iteration 1610/2000\n",
      "Policy Loss: 0.1030, Value Loss: 0.0000\n",
      "Iteration 1611/2000\n",
      "Policy Loss: 0.0007, Value Loss: 0.0000\n",
      "Iteration 1612/2000\n",
      "Policy Loss: 0.0195, Value Loss: 0.0001\n",
      "Iteration 1613/2000\n",
      "Policy Loss: 0.0893, Value Loss: 0.0000\n",
      "Iteration 1614/2000\n",
      "Policy Loss: 0.0007, Value Loss: 0.0001\n",
      "Iteration 1615/2000\n",
      "Policy Loss: 0.0095, Value Loss: 0.0000\n",
      "Iteration 1616/2000\n",
      "Policy Loss: 0.0011, Value Loss: 0.0000\n",
      "Iteration 1617/2000\n",
      "Policy Loss: 0.0011, Value Loss: 0.0000\n",
      "Iteration 1618/2000\n",
      "Policy Loss: 0.0045, Value Loss: 0.0000\n",
      "Iteration 1619/2000\n",
      "Policy Loss: 0.0005, Value Loss: 0.0000\n",
      "Iteration 1620/2000\n",
      "Policy Loss: 0.0588, Value Loss: 0.0000\n",
      "Iteration 1621/2000\n",
      "Policy Loss: 0.1471, Value Loss: 0.0000\n",
      "Iteration 1622/2000\n",
      "Policy Loss: 0.0040, Value Loss: 0.0000\n",
      "Iteration 1623/2000\n",
      "Policy Loss: 0.0046, Value Loss: 0.0000\n",
      "Iteration 1624/2000\n",
      "Policy Loss: 0.0042, Value Loss: 0.0000\n",
      "Iteration 1625/2000\n",
      "Policy Loss: 0.0013, Value Loss: 0.0000\n",
      "Iteration 1626/2000\n",
      "Policy Loss: 0.1791, Value Loss: 0.0000\n",
      "Iteration 1627/2000\n",
      "Policy Loss: 0.0098, Value Loss: 0.0000\n",
      "Iteration 1628/2000\n",
      "Policy Loss: 0.0018, Value Loss: 0.0000\n",
      "Iteration 1629/2000\n",
      "Policy Loss: 0.0010, Value Loss: 0.0000\n",
      "Iteration 1630/2000\n",
      "Policy Loss: 0.0001, Value Loss: 0.0000\n",
      "Iteration 1631/2000\n",
      "Policy Loss: 0.0211, Value Loss: 0.0000\n",
      "Iteration 1632/2000\n",
      "Policy Loss: 0.2088, Value Loss: 0.0000\n",
      "Iteration 1633/2000\n",
      "Policy Loss: 0.0025, Value Loss: 0.0000\n",
      "Iteration 1634/2000\n",
      "Policy Loss: 0.0072, Value Loss: 0.0000\n",
      "Iteration 1635/2000\n",
      "Policy Loss: 0.2150, Value Loss: 0.0002\n",
      "Iteration 1636/2000\n",
      "Policy Loss: 0.0007, Value Loss: 0.0001\n",
      "Iteration 1637/2000\n",
      "Policy Loss: 0.0010, Value Loss: 0.0000\n",
      "Iteration 1638/2000\n",
      "Policy Loss: 0.1237, Value Loss: 0.0000\n",
      "Iteration 1639/2000\n",
      "Policy Loss: 0.1057, Value Loss: 0.0000\n",
      "Iteration 1640/2000\n",
      "Policy Loss: 0.0884, Value Loss: 0.0000\n",
      "Iteration 1641/2000\n",
      "Policy Loss: 0.1325, Value Loss: 0.0000\n",
      "Iteration 1642/2000\n",
      "Policy Loss: 0.0003, Value Loss: 0.0000\n",
      "Iteration 1643/2000\n",
      "Policy Loss: 0.0162, Value Loss: 0.0000\n",
      "Iteration 1644/2000\n",
      "Policy Loss: 0.0019, Value Loss: 0.0000\n",
      "Iteration 1645/2000\n",
      "Policy Loss: 0.0013, Value Loss: 0.0000\n",
      "Iteration 1646/2000\n",
      "Policy Loss: 0.0020, Value Loss: 0.0001\n",
      "Iteration 1647/2000\n",
      "Policy Loss: 0.1329, Value Loss: 0.0000\n",
      "Iteration 1648/2000\n",
      "Policy Loss: 0.0038, Value Loss: 0.0000\n",
      "Iteration 1649/2000\n",
      "Policy Loss: 0.0027, Value Loss: 0.0000\n",
      "Iteration 1650/2000\n",
      "Policy Loss: 0.1364, Value Loss: 0.0000\n",
      "Iteration 1651/2000\n",
      "Policy Loss: 0.0027, Value Loss: 0.0000\n",
      "Iteration 1652/2000\n",
      "Policy Loss: 0.0022, Value Loss: 0.0000\n",
      "Iteration 1653/2000\n",
      "Policy Loss: 0.0034, Value Loss: 0.0000\n",
      "Iteration 1654/2000\n",
      "Policy Loss: 0.0476, Value Loss: 0.0000\n",
      "Iteration 1655/2000\n",
      "Policy Loss: 0.0030, Value Loss: 0.0003\n",
      "Iteration 1656/2000\n",
      "Policy Loss: 0.1393, Value Loss: 0.0018\n",
      "Iteration 1657/2000\n",
      "Policy Loss: 0.0157, Value Loss: 0.0000\n",
      "Iteration 1658/2000\n",
      "Policy Loss: 0.0199, Value Loss: 0.0001\n",
      "Iteration 1659/2000\n",
      "Policy Loss: 0.0110, Value Loss: 0.0008\n",
      "Iteration 1660/2000\n",
      "Policy Loss: 0.2314, Value Loss: 0.0000\n",
      "Iteration 1661/2000\n",
      "Policy Loss: 0.0071, Value Loss: 0.0000\n",
      "Iteration 1662/2000\n",
      "Policy Loss: 0.0126, Value Loss: 0.0005\n",
      "Iteration 1663/2000\n",
      "Policy Loss: 0.0207, Value Loss: 0.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1664/2000\n",
      "Policy Loss: 0.1899, Value Loss: 0.0000\n",
      "Iteration 1665/2000\n",
      "Policy Loss: 0.1578, Value Loss: 0.0000\n",
      "Iteration 1666/2000\n",
      "Policy Loss: 0.1001, Value Loss: 0.0000\n",
      "Iteration 1667/2000\n",
      "Policy Loss: 0.1382, Value Loss: 0.0003\n",
      "Iteration 1668/2000\n",
      "Policy Loss: 0.0922, Value Loss: 0.0000\n",
      "Iteration 1669/2000\n",
      "Policy Loss: 0.0544, Value Loss: 0.0000\n",
      "Iteration 1670/2000\n",
      "Policy Loss: 0.0113, Value Loss: 0.0001\n",
      "Iteration 1671/2000\n",
      "Policy Loss: 0.0044, Value Loss: 0.0000\n",
      "Iteration 1672/2000\n",
      "Policy Loss: 0.0571, Value Loss: 0.0001\n",
      "Iteration 1673/2000\n",
      "Policy Loss: 0.0063, Value Loss: 0.0001\n",
      "Iteration 1674/2000\n",
      "Policy Loss: 0.1067, Value Loss: 0.0002\n",
      "Iteration 1675/2000\n",
      "Policy Loss: 0.0954, Value Loss: 0.0000\n",
      "Iteration 1676/2000\n",
      "Policy Loss: 0.0781, Value Loss: 0.0000\n",
      "Iteration 1677/2000\n",
      "Policy Loss: 0.0317, Value Loss: 0.0000\n",
      "Iteration 1678/2000\n",
      "Policy Loss: 0.0290, Value Loss: 0.0003\n",
      "Iteration 1679/2000\n",
      "Policy Loss: 0.0070, Value Loss: 0.0003\n",
      "Iteration 1680/2000\n",
      "Policy Loss: 0.0221, Value Loss: 0.0001\n",
      "Iteration 1681/2000\n",
      "Policy Loss: 0.0101, Value Loss: 0.0000\n",
      "Iteration 1682/2000\n",
      "Policy Loss: 0.0008, Value Loss: 0.0000\n",
      "Iteration 1683/2000\n",
      "Policy Loss: 0.0104, Value Loss: 0.0000\n",
      "Iteration 1684/2000\n",
      "Policy Loss: 0.0023, Value Loss: 0.0002\n",
      "Iteration 1685/2000\n",
      "Policy Loss: 0.2597, Value Loss: 0.0001\n",
      "Iteration 1686/2000\n",
      "Policy Loss: 0.0009, Value Loss: 0.0006\n",
      "Iteration 1687/2000\n",
      "Policy Loss: 0.0057, Value Loss: 0.0000\n",
      "Iteration 1688/2000\n",
      "Policy Loss: 0.0016, Value Loss: 0.0000\n",
      "Iteration 1689/2000\n",
      "Policy Loss: 0.0474, Value Loss: 0.0000\n",
      "Iteration 1690/2000\n",
      "Policy Loss: 0.1007, Value Loss: 0.0000\n",
      "Iteration 1691/2000\n",
      "Policy Loss: 0.0020, Value Loss: 0.0000\n",
      "Iteration 1692/2000\n",
      "Policy Loss: 0.0994, Value Loss: 0.0000\n",
      "Iteration 1693/2000\n",
      "Policy Loss: 0.0789, Value Loss: 0.0000\n",
      "Iteration 1694/2000\n",
      "Policy Loss: 0.0043, Value Loss: 0.0000\n",
      "Iteration 1695/2000\n",
      "Policy Loss: 0.0007, Value Loss: 0.0001\n",
      "Iteration 1696/2000\n",
      "Policy Loss: 0.0021, Value Loss: 0.0000\n",
      "Iteration 1697/2000\n",
      "Policy Loss: 0.0083, Value Loss: 0.0000\n",
      "Iteration 1698/2000\n",
      "Policy Loss: 0.0625, Value Loss: 0.0000\n",
      "Iteration 1699/2000\n",
      "Policy Loss: 0.1430, Value Loss: 0.0000\n",
      "Iteration 1700/2000\n",
      "Policy Loss: 0.0010, Value Loss: 0.0000\n",
      "Iteration 1701/2000\n",
      "Policy Loss: 0.0048, Value Loss: 0.0000\n",
      "Iteration 1702/2000\n",
      "Policy Loss: 0.1318, Value Loss: 0.0000\n",
      "Iteration 1703/2000\n",
      "Policy Loss: 0.0019, Value Loss: 0.0000\n",
      "Iteration 1704/2000\n",
      "Policy Loss: 0.0043, Value Loss: 0.0000\n",
      "Iteration 1705/2000\n",
      "Policy Loss: 0.0017, Value Loss: 0.0000\n",
      "Iteration 1706/2000\n",
      "Policy Loss: 0.0745, Value Loss: 0.0000\n",
      "Iteration 1707/2000\n",
      "Policy Loss: 0.0010, Value Loss: 0.0000\n",
      "Iteration 1708/2000\n",
      "Policy Loss: 0.0005, Value Loss: 0.0000\n",
      "Iteration 1709/2000\n",
      "Policy Loss: 0.0957, Value Loss: 0.0000\n",
      "Iteration 1710/2000\n",
      "Policy Loss: 0.0459, Value Loss: 0.0000\n",
      "Iteration 1711/2000\n",
      "Policy Loss: 0.1007, Value Loss: 0.0000\n",
      "Iteration 1712/2000\n",
      "Policy Loss: 0.0016, Value Loss: 0.0000\n",
      "Iteration 1713/2000\n",
      "Policy Loss: 0.0037, Value Loss: 0.0000\n",
      "Iteration 1714/2000\n",
      "Policy Loss: 0.0858, Value Loss: 0.0000\n",
      "Iteration 1715/2000\n",
      "Policy Loss: 0.0319, Value Loss: 0.0000\n",
      "Iteration 1716/2000\n",
      "Policy Loss: 0.0116, Value Loss: 0.0000\n",
      "Iteration 1717/2000\n",
      "Policy Loss: 0.0011, Value Loss: 0.0000\n",
      "Iteration 1718/2000\n",
      "Policy Loss: 0.0004, Value Loss: 0.0000\n",
      "Iteration 1719/2000\n",
      "Policy Loss: 0.0020, Value Loss: 0.0000\n",
      "Iteration 1720/2000\n",
      "Policy Loss: 0.0295, Value Loss: 0.0000\n",
      "Iteration 1721/2000\n",
      "Policy Loss: 0.0039, Value Loss: 0.0000\n",
      "Iteration 1722/2000\n",
      "Policy Loss: 0.0010, Value Loss: 0.0000\n",
      "Iteration 1723/2000\n",
      "Policy Loss: 0.1013, Value Loss: 0.0000\n",
      "Iteration 1724/2000\n",
      "Policy Loss: 0.0006, Value Loss: 0.0000\n",
      "Iteration 1725/2000\n",
      "Policy Loss: 0.0209, Value Loss: 0.0000\n",
      "Iteration 1726/2000\n",
      "Policy Loss: 0.0229, Value Loss: 0.0000\n",
      "Iteration 1727/2000\n",
      "Policy Loss: 0.0003, Value Loss: 0.0000\n",
      "Iteration 1728/2000\n",
      "Policy Loss: 0.0391, Value Loss: 0.0000\n",
      "Iteration 1729/2000\n",
      "Policy Loss: 0.0140, Value Loss: 0.0000\n",
      "Iteration 1730/2000\n",
      "Policy Loss: 0.0141, Value Loss: 0.0000\n",
      "Iteration 1731/2000\n",
      "Policy Loss: 0.0004, Value Loss: 0.0042\n",
      "Iteration 1732/2000\n",
      "Policy Loss: 0.0123, Value Loss: 0.0000\n",
      "Iteration 1733/2000\n",
      "Policy Loss: 0.1274, Value Loss: 0.0000\n",
      "Iteration 1734/2000\n",
      "Policy Loss: 0.0004, Value Loss: 0.0000\n",
      "Iteration 1735/2000\n",
      "Policy Loss: 0.0116, Value Loss: 0.0000\n",
      "Iteration 1736/2000\n",
      "Policy Loss: 0.0020, Value Loss: 0.0000\n",
      "Iteration 1737/2000\n",
      "Policy Loss: 0.0021, Value Loss: 0.0000\n",
      "Iteration 1738/2000\n",
      "Policy Loss: 0.0080, Value Loss: 0.0016\n",
      "Iteration 1739/2000\n",
      "Policy Loss: 0.1753, Value Loss: 0.0000\n",
      "Iteration 1740/2000\n",
      "Policy Loss: 0.0076, Value Loss: 0.0000\n",
      "Iteration 1741/2000\n",
      "Policy Loss: 0.0004, Value Loss: 0.0000\n",
      "Iteration 1742/2000\n",
      "Policy Loss: 0.0179, Value Loss: 0.0000\n",
      "Iteration 1743/2000\n",
      "Policy Loss: 0.1338, Value Loss: 0.0000\n",
      "Iteration 1744/2000\n",
      "Policy Loss: 0.0096, Value Loss: 0.0000\n",
      "Iteration 1745/2000\n",
      "Policy Loss: 0.0153, Value Loss: 0.0000\n",
      "Iteration 1746/2000\n",
      "Policy Loss: 0.0004, Value Loss: 0.0009\n",
      "Iteration 1747/2000\n",
      "Policy Loss: 0.0214, Value Loss: 0.0000\n",
      "Iteration 1748/2000\n",
      "Policy Loss: 0.2899, Value Loss: 0.0000\n",
      "Iteration 1749/2000\n",
      "Policy Loss: 0.0048, Value Loss: 0.0018\n",
      "Iteration 1750/2000\n",
      "Policy Loss: 0.0028, Value Loss: 0.0000\n",
      "Iteration 1751/2000\n",
      "Policy Loss: 0.0206, Value Loss: 0.0000\n",
      "Iteration 1752/2000\n",
      "Policy Loss: 0.0161, Value Loss: 0.0000\n",
      "Iteration 1753/2000\n",
      "Policy Loss: 0.0287, Value Loss: 0.0002\n",
      "Iteration 1754/2000\n",
      "Policy Loss: 0.0002, Value Loss: 0.0001\n",
      "Iteration 1755/2000\n",
      "Policy Loss: 0.0010, Value Loss: 0.0006\n",
      "Iteration 1756/2000\n",
      "Policy Loss: 0.0004, Value Loss: 0.0000\n",
      "Iteration 1757/2000\n",
      "Policy Loss: 0.0062, Value Loss: 0.0011\n",
      "Iteration 1758/2000\n",
      "Policy Loss: 0.0452, Value Loss: 0.0005\n",
      "Iteration 1759/2000\n",
      "Policy Loss: 0.1048, Value Loss: 0.0000\n",
      "Iteration 1760/2000\n",
      "Policy Loss: 0.0024, Value Loss: 0.0000\n",
      "Iteration 1761/2000\n",
      "Policy Loss: 0.0086, Value Loss: 0.0000\n",
      "Iteration 1762/2000\n",
      "Policy Loss: 0.0011, Value Loss: 0.0002\n",
      "Iteration 1763/2000\n",
      "Policy Loss: 0.0006, Value Loss: 0.0002\n",
      "Iteration 1764/2000\n",
      "Policy Loss: 0.0034, Value Loss: 0.0000\n",
      "Iteration 1765/2000\n",
      "Policy Loss: 0.0029, Value Loss: 0.0001\n",
      "Iteration 1766/2000\n",
      "Policy Loss: 0.0049, Value Loss: 0.0000\n",
      "Iteration 1767/2000\n",
      "Policy Loss: 0.0011, Value Loss: 0.0000\n",
      "Iteration 1768/2000\n",
      "Policy Loss: 0.0724, Value Loss: 0.0000\n",
      "Iteration 1769/2000\n",
      "Policy Loss: 0.0299, Value Loss: 0.0000\n",
      "Iteration 1770/2000\n",
      "Policy Loss: 0.0021, Value Loss: 0.0000\n",
      "Iteration 1771/2000\n",
      "Policy Loss: 0.1893, Value Loss: 0.0000\n",
      "Iteration 1772/2000\n",
      "Policy Loss: 0.0482, Value Loss: 0.0000\n",
      "Iteration 1773/2000\n",
      "Policy Loss: 0.0885, Value Loss: 0.0001\n",
      "Iteration 1774/2000\n",
      "Policy Loss: 0.1189, Value Loss: 0.0001\n",
      "Iteration 1775/2000\n",
      "Policy Loss: 0.0661, Value Loss: 0.0002\n",
      "Iteration 1776/2000\n",
      "Policy Loss: 0.0001, Value Loss: 0.0000\n",
      "Iteration 1777/2000\n",
      "Policy Loss: 0.0022, Value Loss: 0.0000\n",
      "Iteration 1778/2000\n",
      "Policy Loss: 0.0045, Value Loss: 0.0001\n",
      "Iteration 1779/2000\n",
      "Policy Loss: 0.0928, Value Loss: 0.0000\n",
      "Iteration 1780/2000\n",
      "Policy Loss: 0.0009, Value Loss: 0.0035\n",
      "Iteration 1781/2000\n",
      "Policy Loss: 0.1088, Value Loss: 0.0001\n",
      "Iteration 1782/2000\n",
      "Policy Loss: 0.0025, Value Loss: 0.0000\n",
      "Iteration 1783/2000\n",
      "Policy Loss: 0.0005, Value Loss: 0.0005\n",
      "Iteration 1784/2000\n",
      "Policy Loss: 0.0340, Value Loss: 0.0002\n",
      "Iteration 1785/2000\n",
      "Policy Loss: 0.1158, Value Loss: 0.0000\n",
      "Iteration 1786/2000\n",
      "Policy Loss: 0.0810, Value Loss: 0.0000\n",
      "Iteration 1787/2000\n",
      "Policy Loss: 0.0292, Value Loss: 0.0000\n",
      "Iteration 1788/2000\n",
      "Policy Loss: 0.0007, Value Loss: 0.0001\n",
      "Iteration 1789/2000\n",
      "Policy Loss: 0.0205, Value Loss: 0.0000\n",
      "Iteration 1790/2000\n",
      "Policy Loss: 0.0004, Value Loss: 0.0001\n",
      "Iteration 1791/2000\n",
      "Policy Loss: 0.0354, Value Loss: 0.0000\n",
      "Iteration 1792/2000\n",
      "Policy Loss: 0.0964, Value Loss: 0.0015\n",
      "Iteration 1793/2000\n",
      "Policy Loss: 0.0173, Value Loss: 0.0001\n",
      "Iteration 1794/2000\n",
      "Policy Loss: 0.0006, Value Loss: 0.0000\n",
      "Iteration 1795/2000\n",
      "Policy Loss: 0.0012, Value Loss: 0.0001\n",
      "Iteration 1796/2000\n",
      "Policy Loss: 0.0011, Value Loss: 0.0000\n",
      "Iteration 1797/2000\n",
      "Policy Loss: 0.0009, Value Loss: 0.0001\n",
      "Iteration 1798/2000\n",
      "Policy Loss: 0.0018, Value Loss: 0.0001\n",
      "Iteration 1799/2000\n",
      "Policy Loss: 0.0009, Value Loss: 0.0000\n",
      "Iteration 1800/2000\n",
      "Policy Loss: 0.0309, Value Loss: 0.0008\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1801/2000\n",
      "Policy Loss: 0.0178, Value Loss: 0.0000\n",
      "Iteration 1802/2000\n",
      "Policy Loss: 0.0381, Value Loss: 0.0035\n",
      "Iteration 1803/2000\n",
      "Policy Loss: 0.0121, Value Loss: 0.0023\n",
      "Iteration 1804/2000\n",
      "Policy Loss: 0.0012, Value Loss: 0.0001\n",
      "Iteration 1805/2000\n",
      "Policy Loss: 0.0197, Value Loss: 0.0001\n",
      "Iteration 1806/2000\n",
      "Policy Loss: 0.0065, Value Loss: 0.0000\n",
      "Iteration 1807/2000\n",
      "Policy Loss: 0.0008, Value Loss: 0.0001\n",
      "Iteration 1808/2000\n",
      "Policy Loss: 0.0088, Value Loss: 0.0000\n",
      "Iteration 1809/2000\n",
      "Policy Loss: 0.0030, Value Loss: 0.0006\n",
      "Iteration 1810/2000\n",
      "Policy Loss: 0.0017, Value Loss: 0.0000\n",
      "Iteration 1811/2000\n",
      "Policy Loss: 0.1608, Value Loss: 0.0003\n",
      "Iteration 1812/2000\n",
      "Policy Loss: 0.0010, Value Loss: 0.0000\n",
      "Iteration 1813/2000\n",
      "Policy Loss: 0.0009, Value Loss: 0.0000\n",
      "Iteration 1814/2000\n",
      "Policy Loss: 0.0208, Value Loss: 0.0002\n",
      "Iteration 1815/2000\n",
      "Policy Loss: 0.0183, Value Loss: 0.0000\n",
      "Iteration 1816/2000\n",
      "Policy Loss: 0.0019, Value Loss: 0.0000\n",
      "Iteration 1817/2000\n",
      "Policy Loss: 0.0003, Value Loss: 0.0002\n",
      "Iteration 1818/2000\n",
      "Policy Loss: 0.0011, Value Loss: 0.0000\n",
      "Iteration 1819/2000\n",
      "Policy Loss: 0.0033, Value Loss: 0.0000\n",
      "Iteration 1820/2000\n",
      "Policy Loss: 0.1178, Value Loss: 0.0001\n",
      "Iteration 1821/2000\n",
      "Policy Loss: 0.0002, Value Loss: 0.0001\n",
      "Iteration 1822/2000\n",
      "Policy Loss: 0.0018, Value Loss: 0.0000\n",
      "Iteration 1823/2000\n",
      "Policy Loss: 0.0014, Value Loss: 0.0000\n",
      "Iteration 1824/2000\n",
      "Policy Loss: 0.0367, Value Loss: 0.0010\n",
      "Iteration 1825/2000\n",
      "Policy Loss: 0.0013, Value Loss: 0.0000\n",
      "Iteration 1826/2000\n",
      "Policy Loss: 0.0019, Value Loss: 0.0000\n",
      "Iteration 1827/2000\n",
      "Policy Loss: 0.0324, Value Loss: 0.0000\n",
      "Iteration 1828/2000\n",
      "Policy Loss: 0.0006, Value Loss: 0.0000\n",
      "Iteration 1829/2000\n",
      "Policy Loss: 0.3626, Value Loss: 0.0107\n",
      "Iteration 1830/2000\n",
      "Policy Loss: 0.0034, Value Loss: 0.0000\n",
      "Iteration 1831/2000\n",
      "Policy Loss: 0.0025, Value Loss: 0.0000\n",
      "Iteration 1832/2000\n",
      "Policy Loss: 0.0039, Value Loss: 0.0044\n",
      "Iteration 1833/2000\n",
      "Policy Loss: 0.0007, Value Loss: 0.0000\n",
      "Iteration 1834/2000\n",
      "Policy Loss: 0.0002, Value Loss: 0.0000\n",
      "Iteration 1835/2000\n",
      "Policy Loss: 0.0007, Value Loss: 0.0000\n",
      "Iteration 1836/2000\n",
      "Policy Loss: 0.1111, Value Loss: 0.0000\n",
      "Iteration 1837/2000\n",
      "Policy Loss: 0.0583, Value Loss: 0.0001\n",
      "Iteration 1838/2000\n",
      "Policy Loss: 0.0011, Value Loss: 0.0001\n",
      "Iteration 1839/2000\n",
      "Policy Loss: 0.1166, Value Loss: 0.0015\n",
      "Iteration 1840/2000\n",
      "Policy Loss: 0.1433, Value Loss: 0.0000\n",
      "Iteration 1841/2000\n",
      "Policy Loss: 0.0917, Value Loss: 0.0000\n",
      "Iteration 1842/2000\n",
      "Policy Loss: 0.0213, Value Loss: 0.0000\n",
      "Iteration 1843/2000\n",
      "Policy Loss: 0.0005, Value Loss: 0.0000\n",
      "Iteration 1844/2000\n",
      "Policy Loss: 0.0033, Value Loss: 0.0000\n",
      "Iteration 1845/2000\n",
      "Policy Loss: 0.0004, Value Loss: 0.0000\n",
      "Iteration 1846/2000\n",
      "Policy Loss: 0.0003, Value Loss: 0.0000\n",
      "Iteration 1847/2000\n",
      "Policy Loss: 0.0029, Value Loss: 0.0122\n",
      "Iteration 1848/2000\n",
      "Policy Loss: 0.0040, Value Loss: 0.0000\n",
      "Iteration 1849/2000\n",
      "Policy Loss: 0.0007, Value Loss: 0.0000\n",
      "Iteration 1850/2000\n",
      "Policy Loss: 0.0012, Value Loss: 0.0000\n",
      "Iteration 1851/2000\n",
      "Policy Loss: 0.0028, Value Loss: 0.0000\n",
      "Iteration 1852/2000\n",
      "Policy Loss: 0.0069, Value Loss: 0.0000\n",
      "Iteration 1853/2000\n",
      "Policy Loss: 0.0018, Value Loss: 0.0001\n",
      "Iteration 1854/2000\n",
      "Policy Loss: 0.0003, Value Loss: 0.0004\n",
      "Iteration 1855/2000\n",
      "Policy Loss: 0.0023, Value Loss: 0.0000\n",
      "Iteration 1856/2000\n",
      "Policy Loss: 0.0002, Value Loss: 0.0000\n",
      "Iteration 1857/2000\n",
      "Policy Loss: 0.0038, Value Loss: 0.0000\n",
      "Iteration 1858/2000\n",
      "Policy Loss: 0.0008, Value Loss: 0.0005\n",
      "Iteration 1859/2000\n",
      "Policy Loss: 0.0002, Value Loss: 0.0002\n",
      "Iteration 1860/2000\n",
      "Policy Loss: 0.0007, Value Loss: 0.0009\n",
      "Iteration 1861/2000\n",
      "Policy Loss: 0.0042, Value Loss: 0.0000\n",
      "Iteration 1862/2000\n",
      "Policy Loss: 0.0022, Value Loss: 0.0000\n",
      "Iteration 1863/2000\n",
      "Policy Loss: 0.0007, Value Loss: 0.0035\n",
      "Iteration 1864/2000\n",
      "Policy Loss: 0.0002, Value Loss: 0.0004\n",
      "Iteration 1865/2000\n",
      "Policy Loss: 0.0039, Value Loss: 0.0001\n",
      "Iteration 1866/2000\n",
      "Policy Loss: 0.0016, Value Loss: 0.0000\n",
      "Iteration 1867/2000\n",
      "Policy Loss: 0.0020, Value Loss: 0.0000\n",
      "Iteration 1868/2000\n",
      "Policy Loss: 0.0061, Value Loss: 0.0000\n",
      "Iteration 1869/2000\n",
      "Policy Loss: 0.0069, Value Loss: 0.0000\n",
      "Iteration 1870/2000\n",
      "Policy Loss: 0.0032, Value Loss: 0.0000\n",
      "Iteration 1871/2000\n",
      "Policy Loss: 0.0004, Value Loss: 0.0011\n",
      "Iteration 1872/2000\n",
      "Policy Loss: 0.0002, Value Loss: 0.0037\n",
      "Iteration 1873/2000\n",
      "Policy Loss: 0.3652, Value Loss: 0.0000\n",
      "Iteration 1874/2000\n",
      "Policy Loss: 0.0003, Value Loss: 0.0005\n",
      "Iteration 1875/2000\n",
      "Policy Loss: 0.0008, Value Loss: 0.0000\n",
      "Iteration 1876/2000\n",
      "Policy Loss: 0.0025, Value Loss: 0.0001\n",
      "Iteration 1877/2000\n",
      "Policy Loss: 0.0174, Value Loss: 0.0000\n",
      "Iteration 1878/2000\n",
      "Policy Loss: 0.0018, Value Loss: 0.0000\n",
      "Iteration 1879/2000\n",
      "Policy Loss: 0.0005, Value Loss: 0.0000\n",
      "Iteration 1880/2000\n",
      "Policy Loss: 0.0005, Value Loss: 0.0000\n",
      "Iteration 1881/2000\n",
      "Policy Loss: 0.0002, Value Loss: 0.0000\n",
      "Iteration 1882/2000\n",
      "Policy Loss: 0.0099, Value Loss: 0.0015\n",
      "Iteration 1883/2000\n",
      "Policy Loss: 0.0006, Value Loss: 0.0000\n",
      "Iteration 1884/2000\n",
      "Policy Loss: 0.0033, Value Loss: 0.0008\n",
      "Iteration 1885/2000\n",
      "Policy Loss: 0.0011, Value Loss: 0.0000\n",
      "Iteration 1886/2000\n",
      "Policy Loss: 0.0037, Value Loss: 0.0000\n",
      "Iteration 1887/2000\n",
      "Policy Loss: 0.0011, Value Loss: 0.0001\n",
      "Iteration 1888/2000\n",
      "Policy Loss: 0.0005, Value Loss: 0.0000\n",
      "Iteration 1889/2000\n",
      "Policy Loss: 0.0005, Value Loss: 0.0000\n",
      "Iteration 1890/2000\n",
      "Policy Loss: 0.0004, Value Loss: 0.0000\n",
      "Iteration 1891/2000\n",
      "Policy Loss: 0.0040, Value Loss: 0.0000\n",
      "Iteration 1892/2000\n",
      "Policy Loss: 0.0825, Value Loss: 0.0000\n",
      "Iteration 1893/2000\n",
      "Policy Loss: 0.2376, Value Loss: 0.0000\n",
      "Iteration 1894/2000\n",
      "Policy Loss: 0.0030, Value Loss: 0.0000\n",
      "Iteration 1895/2000\n",
      "Policy Loss: 0.0040, Value Loss: 0.0000\n",
      "Iteration 1896/2000\n",
      "Policy Loss: 0.0760, Value Loss: 0.0000\n",
      "Iteration 1897/2000\n",
      "Policy Loss: 0.0023, Value Loss: 0.0000\n",
      "Iteration 1898/2000\n",
      "Policy Loss: 0.0015, Value Loss: 0.0001\n",
      "Iteration 1899/2000\n",
      "Policy Loss: 0.0029, Value Loss: 0.0001\n",
      "Iteration 1900/2000\n",
      "Policy Loss: 0.0481, Value Loss: 0.0000\n",
      "Iteration 1901/2000\n",
      "Policy Loss: 0.0029, Value Loss: 0.0000\n",
      "Iteration 1902/2000\n",
      "Policy Loss: 0.0010, Value Loss: 0.0000\n",
      "Iteration 1903/2000\n",
      "Policy Loss: 0.0017, Value Loss: 0.0000\n",
      "Iteration 1904/2000\n",
      "Policy Loss: 0.0260, Value Loss: 0.0000\n",
      "Iteration 1905/2000\n",
      "Policy Loss: 0.0010, Value Loss: 0.0000\n",
      "Iteration 1906/2000\n",
      "Policy Loss: 0.0021, Value Loss: 0.0000\n",
      "Iteration 1907/2000\n",
      "Policy Loss: 0.2059, Value Loss: 0.0000\n",
      "Iteration 1908/2000\n",
      "Policy Loss: 0.0081, Value Loss: 0.0000\n",
      "Iteration 1909/2000\n",
      "Policy Loss: 0.0622, Value Loss: 0.0003\n",
      "Iteration 1910/2000\n",
      "Policy Loss: 0.0109, Value Loss: 0.0000\n",
      "Iteration 1911/2000\n",
      "Policy Loss: 0.1337, Value Loss: 0.0001\n",
      "Iteration 1912/2000\n",
      "Policy Loss: 0.0008, Value Loss: 0.0000\n",
      "Iteration 1913/2000\n",
      "Policy Loss: 0.1402, Value Loss: 0.0000\n",
      "Iteration 1914/2000\n",
      "Policy Loss: 0.0002, Value Loss: 0.0000\n",
      "Iteration 1915/2000\n",
      "Policy Loss: 0.0009, Value Loss: 0.0001\n",
      "Iteration 1916/2000\n",
      "Policy Loss: 0.0293, Value Loss: 0.0000\n",
      "Iteration 1917/2000\n",
      "Policy Loss: 0.0038, Value Loss: 0.0000\n",
      "Iteration 1918/2000\n",
      "Policy Loss: 0.0028, Value Loss: 0.0000\n",
      "Iteration 1919/2000\n",
      "Policy Loss: 0.0048, Value Loss: 0.0000\n",
      "Iteration 1920/2000\n",
      "Policy Loss: 0.1367, Value Loss: 0.0000\n",
      "Iteration 1921/2000\n",
      "Policy Loss: 0.0024, Value Loss: 0.0000\n",
      "Iteration 1922/2000\n",
      "Policy Loss: 0.0059, Value Loss: 0.0000\n",
      "Iteration 1923/2000\n",
      "Policy Loss: 0.0934, Value Loss: 0.0000\n",
      "Iteration 1924/2000\n",
      "Policy Loss: 0.0419, Value Loss: 0.0000\n",
      "Iteration 1925/2000\n",
      "Policy Loss: 0.0028, Value Loss: 0.0000\n",
      "Iteration 1926/2000\n",
      "Policy Loss: 0.0018, Value Loss: 0.0001\n",
      "Iteration 1927/2000\n",
      "Policy Loss: 0.0019, Value Loss: 0.0000\n",
      "Iteration 1928/2000\n",
      "Policy Loss: 0.0447, Value Loss: 0.0000\n",
      "Iteration 1929/2000\n",
      "Policy Loss: 0.0109, Value Loss: 0.0000\n",
      "Iteration 1930/2000\n",
      "Policy Loss: 0.0005, Value Loss: 0.0000\n",
      "Iteration 1931/2000\n",
      "Policy Loss: 0.1026, Value Loss: 0.0000\n",
      "Iteration 1932/2000\n",
      "Policy Loss: 0.0003, Value Loss: 0.0000\n",
      "Iteration 1933/2000\n",
      "Policy Loss: 0.0719, Value Loss: 0.0000\n",
      "Iteration 1934/2000\n",
      "Policy Loss: 0.0014, Value Loss: 0.0091\n",
      "Iteration 1935/2000\n",
      "Policy Loss: 0.0278, Value Loss: 0.0000\n",
      "Iteration 1936/2000\n",
      "Policy Loss: 0.0009, Value Loss: 0.0000\n",
      "Iteration 1937/2000\n",
      "Policy Loss: 0.0089, Value Loss: 0.0001\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 1938/2000\n",
      "Policy Loss: 0.0022, Value Loss: 0.0000\n",
      "Iteration 1939/2000\n",
      "Policy Loss: 0.0100, Value Loss: 0.0000\n",
      "Iteration 1940/2000\n",
      "Policy Loss: 0.0009, Value Loss: 0.0018\n",
      "Iteration 1941/2000\n",
      "Policy Loss: 0.0052, Value Loss: 0.0000\n",
      "Iteration 1942/2000\n",
      "Policy Loss: 0.0031, Value Loss: 0.0000\n",
      "Iteration 1943/2000\n",
      "Policy Loss: 0.0001, Value Loss: 0.0000\n",
      "Iteration 1944/2000\n",
      "Policy Loss: 0.0002, Value Loss: 0.0000\n",
      "Iteration 1945/2000\n",
      "Policy Loss: 0.2070, Value Loss: 0.0000\n",
      "Iteration 1946/2000\n",
      "Policy Loss: 0.0011, Value Loss: 0.0000\n",
      "Iteration 1947/2000\n",
      "Policy Loss: 0.0015, Value Loss: 0.0000\n",
      "Iteration 1948/2000\n",
      "Policy Loss: 0.4145, Value Loss: 0.0211\n",
      "Iteration 1949/2000\n",
      "Policy Loss: 0.1123, Value Loss: 0.0000\n",
      "Iteration 1950/2000\n",
      "Policy Loss: 0.0210, Value Loss: 0.0001\n",
      "Iteration 1951/2000\n",
      "Policy Loss: 0.0013, Value Loss: 0.0018\n",
      "Iteration 1952/2000\n",
      "Policy Loss: 0.0007, Value Loss: 0.0067\n",
      "Iteration 1953/2000\n",
      "Policy Loss: 0.0021, Value Loss: 0.0000\n",
      "Iteration 1954/2000\n",
      "Policy Loss: 0.0199, Value Loss: 0.0001\n",
      "Iteration 1955/2000\n",
      "Policy Loss: 0.1910, Value Loss: 0.0002\n",
      "Iteration 1956/2000\n",
      "Policy Loss: 0.0190, Value Loss: 0.0000\n",
      "Iteration 1957/2000\n",
      "Policy Loss: 0.1190, Value Loss: 0.0001\n",
      "Iteration 1958/2000\n",
      "Policy Loss: 0.0359, Value Loss: 0.0004\n",
      "Iteration 1959/2000\n",
      "Policy Loss: 0.0263, Value Loss: 0.0001\n",
      "Iteration 1960/2000\n",
      "Policy Loss: 0.0034, Value Loss: 0.0000\n",
      "Iteration 1961/2000\n",
      "Policy Loss: 0.0926, Value Loss: 0.0000\n",
      "Iteration 1962/2000\n",
      "Policy Loss: 0.0249, Value Loss: 0.0031\n",
      "Iteration 1963/2000\n",
      "Policy Loss: 0.0034, Value Loss: 0.0002\n",
      "Iteration 1964/2000\n",
      "Policy Loss: 0.0245, Value Loss: 0.0000\n",
      "Iteration 1965/2000\n",
      "Policy Loss: 0.0841, Value Loss: 0.0219\n",
      "Iteration 1966/2000\n",
      "Policy Loss: 0.0015, Value Loss: 0.0002\n",
      "Iteration 1967/2000\n",
      "Policy Loss: 0.0308, Value Loss: 0.0003\n",
      "Iteration 1968/2000\n",
      "Policy Loss: 0.0122, Value Loss: 0.0002\n",
      "Iteration 1969/2000\n",
      "Policy Loss: 0.0026, Value Loss: 0.0000\n",
      "Iteration 1970/2000\n",
      "Policy Loss: 0.0031, Value Loss: 0.0000\n",
      "Iteration 1971/2000\n",
      "Policy Loss: 0.0028, Value Loss: 0.0017\n",
      "Iteration 1972/2000\n",
      "Policy Loss: 0.0048, Value Loss: 0.0000\n",
      "Iteration 1973/2000\n",
      "Policy Loss: 0.0008, Value Loss: 0.0000\n",
      "Iteration 1974/2000\n",
      "Policy Loss: 0.1132, Value Loss: 0.0001\n",
      "Iteration 1975/2000\n",
      "Policy Loss: 0.1813, Value Loss: 0.0026\n",
      "Iteration 1976/2000\n",
      "Policy Loss: 0.0088, Value Loss: 0.0000\n",
      "Iteration 1977/2000\n",
      "Policy Loss: 0.0023, Value Loss: 0.0000\n",
      "Iteration 1978/2000\n",
      "Policy Loss: 0.0008, Value Loss: 0.0328\n",
      "Iteration 1979/2000\n",
      "Policy Loss: 0.0232, Value Loss: 0.0051\n",
      "Iteration 1980/2000\n",
      "Policy Loss: 0.1372, Value Loss: 0.0000\n",
      "Iteration 1981/2000\n",
      "Policy Loss: 0.0004, Value Loss: 0.0000\n",
      "Iteration 1982/2000\n",
      "Policy Loss: 0.0088, Value Loss: 0.0014\n",
      "Iteration 1983/2000\n",
      "Policy Loss: 0.0068, Value Loss: 0.0000\n",
      "Iteration 1984/2000\n",
      "Policy Loss: 0.0386, Value Loss: 0.0000\n",
      "Iteration 1985/2000\n",
      "Policy Loss: 0.0002, Value Loss: 0.0001\n",
      "Iteration 1986/2000\n",
      "Policy Loss: 0.0053, Value Loss: 0.0000\n",
      "Iteration 1987/2000\n",
      "Policy Loss: 0.0006, Value Loss: 0.0000\n",
      "Iteration 1988/2000\n",
      "Policy Loss: 0.0257, Value Loss: 0.0000\n",
      "Iteration 1989/2000\n",
      "Policy Loss: 0.0165, Value Loss: 0.0057\n",
      "Iteration 1990/2000\n",
      "Policy Loss: 0.0027, Value Loss: 0.0000\n",
      "Iteration 1991/2000\n",
      "Policy Loss: 0.0222, Value Loss: 0.0000\n",
      "Iteration 1992/2000\n",
      "Policy Loss: 0.0241, Value Loss: 0.0000\n",
      "Iteration 1993/2000\n",
      "Policy Loss: 0.0001, Value Loss: 0.0000\n",
      "Iteration 1994/2000\n",
      "Policy Loss: 0.0053, Value Loss: 0.0002\n",
      "Iteration 1995/2000\n",
      "Policy Loss: 0.0063, Value Loss: 0.0000\n",
      "Iteration 1996/2000\n",
      "Policy Loss: 0.0002, Value Loss: 0.0000\n",
      "Iteration 1997/2000\n",
      "Policy Loss: 0.4107, Value Loss: 0.0000\n",
      "Iteration 1998/2000\n",
      "Policy Loss: 0.0071, Value Loss: 0.0001\n",
      "Iteration 1999/2000\n",
      "Policy Loss: 0.0045, Value Loss: 0.0001\n",
      "Iteration 2000/2000\n",
      "Policy Loss: 0.1365, Value Loss: 0.0005\n",
      "Training complete. Weights saved to 'alphazero_weights.pth'.\n"
     ]
    }
   ],
   "source": [
    "board_size = 7\n",
    "model = AlphaZeroNet(board_size)\n",
    "\n",
    "\n",
    "\n",
    "policy_loss, value_loss = train_alphazero(\n",
    "                        model=model,\n",
    "                        board_size=board_size,\n",
    "                        iterations=2000,\n",
    "                        games_per_iteration=5,\n",
    "                        batch_size=16,\n",
    "                        mcts_simulations=20,\n",
    "                        alpha=0.5\n",
    "                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ZtmW2gphjeIo",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 430
    },
    "executionInfo": {
     "elapsed": 504,
     "status": "ok",
     "timestamp": 1733702084740,
     "user": {
      "displayName": "Siyi Wu",
      "userId": "06196688456534608936"
     },
     "user_tz": 360
    },
    "id": "ZtmW2gphjeIo",
    "outputId": "52935804-3cce-464b-b080-49b6be7aaf1c"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(policy_loss)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "EB1BlQub7NjO",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 430
    },
    "executionInfo": {
     "elapsed": 281,
     "status": "ok",
     "timestamp": 1733702094092,
     "user": {
      "displayName": "Siyi Wu",
      "userId": "06196688456534608936"
     },
     "user_tz": 360
    },
    "id": "EB1BlQub7NjO",
    "outputId": "c471d77f-08f0-4b29-b46b-fd0fbd0fc9c6"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(value_loss)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "qkRUTTmdsouH",
   "metadata": {
    "id": "qkRUTTmdsouH"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
