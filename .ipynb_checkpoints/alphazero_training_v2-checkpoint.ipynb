{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "jfTPpJsvdjZx",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 615,
     "status": "ok",
     "timestamp": 1733701384829,
     "user": {
      "displayName": "Siyi Wu",
      "userId": "06196688456534608936"
     },
     "user_tz": 360
    },
    "id": "jfTPpJsvdjZx",
    "outputId": "5b384f92-0fc8-4c1d-eae9-0eaa4b2d5896"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "96P8EsRKeGJT",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 101,
     "status": "ok",
     "timestamp": 1733701385266,
     "user": {
      "displayName": "Siyi Wu",
      "userId": "06196688456534608936"
     },
     "user_tz": 360
    },
    "id": "96P8EsRKeGJT",
    "outputId": "2aa9f03e-cec8-4dab-e260-ecea06b460a3"
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/content/drive/MyDrive/code/WZ'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [1]\u001b[0m, in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mos\u001b[39;00m\n\u001b[1;32m      2\u001b[0m path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/content/drive/MyDrive/code/WZ\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m----> 3\u001b[0m \u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mchdir\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(os\u001b[38;5;241m.\u001b[39mgetcwd())\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/drive/MyDrive/code/WZ'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "path = \"/content/drive/MyDrive/code/WZ\"\n",
    "os.chdir(path)\n",
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5397fffc",
   "metadata": {
    "executionInfo": {
     "elapsed": 9677,
     "status": "ok",
     "timestamp": 1733701395668,
     "user": {
      "displayName": "Siyi Wu",
      "userId": "06196688456534608936"
     },
     "user_tz": 360
    },
    "id": "5397fffc"
   },
   "outputs": [],
   "source": [
    "import importlib\n",
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import random\n",
    "\n",
    "from collections import deque\n",
    "\n",
    "\n",
    "sizef = 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9a318702",
   "metadata": {
    "id": "9a318702"
   },
   "outputs": [],
   "source": [
    "class Gomoku:\n",
    "    def __init__(self, size=sizef, black_strategy=None, white_strategy=None):\n",
    "        self.size = size  # 棋盘大小\n",
    "        self.board = [['.' for _ in range(size)] for _ in range(size)]  # 初始化棋盘\n",
    "        self.current_player = 'X'  # 当前玩家 ('X' or 'O')\n",
    "        self.black_strategy = black_strategy  # 黑棋策略函数\n",
    "        self.white_strategy = white_strategy  # 白棋策略函数\n",
    "\n",
    "    def display_board(self):\n",
    "        \"\"\"打印棋盘\"\"\"\n",
    "        print(\"   \" + \" \".join(f\"{i:2}\" for i in range(self.size)))\n",
    "        for i, row in enumerate(self.board):\n",
    "            print(f\"{i:2} \" + \" \".join(row))\n",
    "\n",
    "    def is_valid_move(self, x, y):\n",
    "        \"\"\"检查落子是否合法\"\"\"\n",
    "        return 0 <= x < self.size and 0 <= y < self.size and self.board[x][y] == '.'\n",
    "\n",
    "    def make_move(self, x, y):\n",
    "        \"\"\"下棋\"\"\"\n",
    "        if self.is_valid_move(x, y):\n",
    "            self.board[x][y] = self.current_player\n",
    "            return True\n",
    "        else:\n",
    "            print(f\"Invalid move by player {self.current_player} at ({x}, {y}).\")\n",
    "            return False\n",
    "\n",
    "    def check_winner(self, x, y):\n",
    "        \"\"\"检查当前玩家是否获胜\"\"\"\n",
    "        directions = [(1, 0), (0, 1), (1, 1), (1, -1)]  # 四个方向：水平、垂直、正斜线、反斜线\n",
    "        for dx, dy in directions:\n",
    "            count = 1\n",
    "            # 检查正方向\n",
    "            for step in range(1, 5):\n",
    "                nx, ny = x + step * dx, y + step * dy\n",
    "                if 0 <= nx < self.size and 0 <= ny < self.size and self.board[nx][ny] == self.current_player:\n",
    "                    count += 1\n",
    "                else:\n",
    "                    break\n",
    "            # 检查反方向\n",
    "            for step in range(1, 5):\n",
    "                nx, ny = x - step * dx, y - step * dy\n",
    "                if 0 <= nx < self.size and 0 <= ny < self.size and self.board[nx][ny] == self.current_player:\n",
    "                    count += 1\n",
    "                else:\n",
    "                    break\n",
    "            if count >= 5:  # 连续五子\n",
    "                return True\n",
    "        return False\n",
    "\n",
    "    def switch_player(self):\n",
    "        \"\"\"切换玩家\"\"\"\n",
    "        self.current_player = 'O' if self.current_player == 'X' else 'X'\n",
    "\n",
    "    def play(self):\n",
    "        \"\"\"游戏主循环\"\"\"\n",
    "        print(\"Starting Gomoku!\")\n",
    "        self.display_board()\n",
    "\n",
    "        # 检查是否有 GPU 可用\n",
    "        device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "        print(f\"Running on device: {device}\")\n",
    "\n",
    "        while True:\n",
    "            if self.current_player == 'X':\n",
    "                if self.black_strategy:\n",
    "                    # 将策略函数运行在指定设备上\n",
    "                    move = self.black_strategy(self.board, 'X', device=device)\n",
    "                else:\n",
    "                    move = self.get_human_move()\n",
    "            else:\n",
    "                if self.white_strategy:\n",
    "                    # 将策略函数运行在指定设备上\n",
    "                    move = self.white_strategy(self.board, 'O', device=device)\n",
    "                else:\n",
    "                    move = self.get_human_move()\n",
    "\n",
    "            if not move or len(move) != 2:\n",
    "                print(f\"Invalid move returned by player {self.current_player}.\")\n",
    "                break\n",
    "\n",
    "            x, y = move\n",
    "            if self.make_move(x, y):\n",
    "                print(f\"Player {self.current_player} places at ({x}, {y})\")\n",
    "                self.display_board()\n",
    "                if self.check_winner(x, y):\n",
    "                    print(f\"Player {self.current_player} wins!\")\n",
    "                    break\n",
    "                self.switch_player()\n",
    "            else:\n",
    "                print(\"Game Over due to invalid move.\")\n",
    "                break\n",
    "\n",
    "        print(\"Game Over!\")\n",
    "\n",
    "    def get_human_move(self):\n",
    "        \"\"\"获取玩家的落子\"\"\"\n",
    "        while True:\n",
    "            try:\n",
    "                move = input(f\"Player {self.current_player}, enter your move (row col): \").strip()\n",
    "                x, y = map(int, move.split())\n",
    "                if self.is_valid_move(x, y):\n",
    "                    return x, y\n",
    "                else:\n",
    "                    print(\"Invalid move. Try again.\")\n",
    "            except ValueError:\n",
    "                print(\"Invalid input. Please enter row and column numbers separated by a space.\")\n",
    "\n",
    "\n",
    "def load_strategy(file_name):\n",
    "    \"\"\"从本地文件加载策略\"\"\"\n",
    "    if not os.path.exists(file_name):\n",
    "        raise FileNotFoundError(f\"Strategy file {file_name} not found.\")\n",
    "\n",
    "    module_name = os.path.splitext(os.path.basename(file_name))[0]\n",
    "    spec = importlib.util.spec_from_file_location(module_name, file_name)\n",
    "    module = importlib.util.module_from_spec(spec)\n",
    "    spec.loader.exec_module(module)\n",
    "    return module.play  # 假设策略文件中定义了一个 play 函数\n",
    "\n",
    "\n",
    "\n",
    "def print_strategy_files(directory):\n",
    "    try:\n",
    "        for root, dirs, files in os.walk(directory):\n",
    "            for file in files:\n",
    "                if file.endswith(\"strategy.py\"):\n",
    "                    print(file)\n",
    "    except Exception as e:\n",
    "        print(f\"Invaid: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "90c801a2",
   "metadata": {
    "id": "90c801a2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Welcome to Gomoku!\n",
      "Choose game mode:\n",
      "1. Human vs AI\n",
      "2. AI vs AI\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "Interrupted by user",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [3]\u001b[0m, in \u001b[0;36m<cell line: 5>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m1. Human vs AI\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m2. AI vs AI\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m----> 5\u001b[0m mode \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43minput\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mEnter 1 or 2: \u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mstrip()\n\u001b[1;32m      7\u001b[0m black_strategy \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m      8\u001b[0m white_strategy \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/opt/miniconda3/lib/python3.9/site-packages/ipykernel/kernelbase.py:1075\u001b[0m, in \u001b[0;36mKernel.raw_input\u001b[0;34m(self, prompt)\u001b[0m\n\u001b[1;32m   1071\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_allow_stdin:\n\u001b[1;32m   1072\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m StdinNotImplementedError(\n\u001b[1;32m   1073\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mraw_input was called, but this frontend does not support input requests.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1074\u001b[0m     )\n\u001b[0;32m-> 1075\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_input_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1076\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mstr\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1077\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_parent_ident\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mshell\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1078\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_parent\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mshell\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1079\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpassword\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m   1080\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/opt/miniconda3/lib/python3.9/site-packages/ipykernel/kernelbase.py:1120\u001b[0m, in \u001b[0;36mKernel._input_request\u001b[0;34m(self, prompt, ident, parent, password)\u001b[0m\n\u001b[1;32m   1117\u001b[0m             \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[1;32m   1118\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyboardInterrupt\u001b[39;00m:\n\u001b[1;32m   1119\u001b[0m     \u001b[38;5;66;03m# re-raise KeyboardInterrupt, to truncate traceback\u001b[39;00m\n\u001b[0;32m-> 1120\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyboardInterrupt\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInterrupted by user\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1121\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[1;32m   1122\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlog\u001b[38;5;241m.\u001b[39mwarning(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mInvalid Message:\u001b[39m\u001b[38;5;124m\"\u001b[39m, exc_info\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: Interrupted by user"
     ]
    }
   ],
   "source": [
    "print(\"Welcome to Gomoku!\")\n",
    "print(\"Choose game mode:\")\n",
    "print(\"1. Human vs AI\")\n",
    "print(\"2. AI vs AI\")\n",
    "mode = input(\"Enter 1 or 2: \").strip()\n",
    "\n",
    "black_strategy = None\n",
    "white_strategy = None\n",
    "\n",
    "if mode == \"1\":\n",
    "    print(\"You will play as 'X'.\")\n",
    "    print_strategy_files(os.getcwd())\n",
    "    white_strategy_file = input(\"Enter the AI strategy file for 'O' (e.g., white_strategy.py): \").strip()\n",
    "    white_strategy = load_strategy(white_strategy_file)\n",
    "elif mode == \"2\":\n",
    "    print_strategy_files(os.getcwd())\n",
    "    black_strategy_file = input(\"Enter the AI strategy file for 'X' (e.g., black_strategy.py): \").strip()\n",
    "    white_strategy_file = input(\"Enter the AI strategy file for 'O' (e.g., white_strategy.py): \").strip()\n",
    "    black_strategy = load_strategy(black_strategy_file)\n",
    "    white_strategy = load_strategy(white_strategy_file)\n",
    "else:\n",
    "    print(\"Invalid choice. Exiting.\")\n",
    "\n",
    "game = Gomoku(black_strategy=black_strategy, white_strategy=white_strategy)\n",
    "game.play()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c5873910",
   "metadata": {
    "executionInfo": {
     "elapsed": 327,
     "status": "ok",
     "timestamp": 1733701425464,
     "user": {
      "displayName": "Siyi Wu",
      "userId": "06196688456534608936"
     },
     "user_tz": 360
    },
    "id": "c5873910"
   },
   "outputs": [],
   "source": [
    "from alpha0v2_strategy_v2 import AlphaZeroNet\n",
    "from alpha0v2_strategy_v2 import MCTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "r3lQPHih7ez9",
   "metadata": {
    "executionInfo": {
     "elapsed": 118,
     "status": "ok",
     "timestamp": 1733701428317,
     "user": {
      "displayName": "Siyi Wu",
      "userId": "06196688456534608936"
     },
     "user_tz": 360
    },
    "id": "r3lQPHih7ez9"
   },
   "outputs": [],
   "source": [
    "# ------------------------------\n",
    "# Data Generation via Self-Play\n",
    "# ------------------------------\n",
    "def self_play_game(model, board_size, mcts_simulations=5):\n",
    "    \"\"\"Generate training data via self-play\"\"\"\n",
    "    # 检查是否有 GPU 并将模型移动到 GPU\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    model = model.to(device)\n",
    "\n",
    "    # 初始化棋盘和 MCTS\n",
    "    board = [['.' for _ in range(board_size)] for _ in range(board_size)]\n",
    "    mcts = MCTS(model, board_size)\n",
    "    current_player = 'X'\n",
    "    last_move = None\n",
    "    game_data = []  # Store (state, policy, value) for training\n",
    "    winner = None\n",
    "\n",
    "    while True:\n",
    "\n",
    "        # Run MCTS to get the move and actions\n",
    "        move, actions = mcts.run(board, current_player, mcts_simulations, last_move=last_move)\n",
    "\n",
    "        # Step 1: 提取所有 (action, Q + u) 对\n",
    "        action_values = [(action, node.get_value(c_puct=5.0)) for action, node in actions.items()]\n",
    "\n",
    "        # Step 2: 计算所有 (Q + u) 的 softmax 概率\n",
    "        values = np.array([value for _, value in action_values])\n",
    "        exp_values = np.exp(values - np.max(values))  # 稳定的 softmax 计算\n",
    "        probabilities = exp_values / np.sum(exp_values)\n",
    "\n",
    "        # Step 3: 生成结果数组\n",
    "        action_probs = [(action, prob) for (action, _), prob in zip(action_values, probabilities)]\n",
    "        \n",
    "        state = mcts.board_to_tensor(board, current_player, last_move).squeeze(0).detach().cpu().numpy()\n",
    "\n",
    "        # Make the move\n",
    "        board = mcts.make_move(board, move, current_player)\n",
    "\n",
    "        # Store state and policy\n",
    "#         state = np.zeros((4, board_size, board_size))\n",
    "\n",
    "#         # 当前玩家的棋子位置\n",
    "#         for x in range(board_size):\n",
    "#             for y in range(board_size):\n",
    "#                 if board[x][y] == current_player:\n",
    "#                     state[0][x][y] = 1.0\n",
    "#                 elif board[x][y] != '.':  # 对手的棋子位置\n",
    "#                     state[1][x][y] = 1.0\n",
    "\n",
    "#         # 最近一次落子的位置\n",
    "#         if last_move is not None:\n",
    "#             state[2][last_move[0]][last_move[1]] = 1.0\n",
    "\n",
    "#         # 当前轮到谁下棋\n",
    "#         if current_player == 'O':  # 如果是偶数回合，轮到白棋\n",
    "#             state[3][:, :] = 1.0\n",
    "\n",
    "        # 更新 last_move\n",
    "        last_move = move\n",
    "\n",
    "        # 转换动作概率\n",
    "        action_probs_np = np.zeros((board_size, board_size))\n",
    "        for (x, y), prob in action_probs:\n",
    "            action_probs_np[x, y] = prob\n",
    "\n",
    "        # 检查胜利条件\n",
    "        if mcts.check_winner(board, current_player):\n",
    "            winner = current_player\n",
    "            game_data.append([state, action_probs_np, 1 if winner == 'X' else -1])\n",
    "            break\n",
    "\n",
    "        # 检查平局\n",
    "        if not mcts.get_legal_moves(board):\n",
    "            winner = None  # Draw\n",
    "            game_data.append([state, action_probs_np, 0])\n",
    "            break\n",
    "\n",
    "        # 切换玩家\n",
    "        current_player = 'O' if current_player == 'X' else 'X'\n",
    "\n",
    "    return game_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "qi-k2QvkfIsv",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 106,
     "status": "ok",
     "timestamp": 1733614684667,
     "user": {
      "displayName": "Siyi Wu",
      "userId": "06196688456534608936"
     },
     "user_tz": 360
    },
    "id": "qi-k2QvkfIsv",
    "outputId": "a9010201-2a2d-4fc0-dcbd-47b1f849db96"
   },
   "outputs": [],
   "source": [
    "def compute_softmax_probabilities(children):\n",
    "    # Step 1: 提取所有 (action, value_sum) 对\n",
    "    action_values = [(action, node.value_sum) for action, node in children.items()]\n",
    "\n",
    "    # Step 2: 计算所有 value_sum 的 softmax 概率\n",
    "    values = np.array([value_sum for _, value_sum in action_values])\n",
    "    exp_values = np.exp(values - np.max(values))\n",
    "    probabilities = exp_values / np.sum(exp_values)\n",
    "\n",
    "    # Step 3: 生成结果数组\n",
    "    result = [(action, prob) for (action, _), prob in zip(action_values, probabilities)]\n",
    "    return result\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d531a64b",
   "metadata": {
    "executionInfo": {
     "elapsed": 148,
     "status": "ok",
     "timestamp": 1733701435807,
     "user": {
      "displayName": "Siyi Wu",
      "userId": "06196688456534608936"
     },
     "user_tz": 360
    },
    "id": "d531a64b"
   },
   "outputs": [],
   "source": [
    "def train_alphazero(model, board_size, iterations=100, games_per_iteration=10, \n",
    "                    batch_size=32, mcts_simulations=100, alpha=0.5, l2_lambda=1e-4, entropy_alpha=1e-3):\n",
    "    \"\"\"Train AlphaZero model\"\"\"\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    print(f\"Using device: {device}\")\n",
    "\n",
    "    # Move model to GPU if available\n",
    "    model = model.to(device)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.002)\n",
    "    replay_buffer = deque(maxlen=10000)  # Replay buffer to store training data\n",
    "    loss_fn_policy = nn.CrossEntropyLoss()\n",
    "    loss_fn_value = nn.MSELoss()\n",
    "\n",
    "    policy_loss_list = []\n",
    "    value_loss_list = []\n",
    "\n",
    "    for iteration in range(iterations):\n",
    "\n",
    "        # Generate self-play data\n",
    "        for _ in range(games_per_iteration):\n",
    "\n",
    "            game_data = self_play_game(model, board_size, mcts_simulations)\n",
    "            #print(game_data)\n",
    "            replay_buffer.extend(game_data)\n",
    "        \n",
    "        #print(len(replay_buffer))\n",
    "        # Sample a batch from replay buffer\n",
    "        if len(replay_buffer) < batch_size:\n",
    "            continue\n",
    "\n",
    "        batch = random.sample(replay_buffer, batch_size)\n",
    "        states, policies, values = zip(*batch)\n",
    "\n",
    "        # Move data to GPU\n",
    "        states = torch.tensor(np.stack(states), dtype=torch.float32).to(device)\n",
    "        policies = torch.tensor(np.stack(policies), dtype=torch.float32).view(batch_size, \n",
    "                                                        board_size * board_size).to(device)\n",
    "        values = torch.tensor(values, dtype=torch.float32).view(-1, 1).to(device)\n",
    "\n",
    "        # Forward pass\n",
    "        pred_policies, pred_values = model(states)\n",
    "\n",
    "        # Compute losses\n",
    "        policy_loss = loss_fn_policy(pred_policies, policies)\n",
    "        value_loss = loss_fn_value(pred_values, values)\n",
    "\n",
    "        l2_reg = sum(param.pow(2).sum() for param in model.parameters())\n",
    "        #entropy = -torch.sum(pred_policies * torch.log(pred_policies + 1e-8), dim=1).mean()\n",
    "\n",
    "        loss = (policy_loss * alpha + value_loss * (1 - alpha)\n",
    "                + l2_lambda)\n",
    "\n",
    "        # Backward pass and optimization\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        policy_loss_list.append(policy_loss.item())\n",
    "        value_loss_list.append(value_loss.item())\n",
    "\n",
    "        print(f\"Iteration {iteration + 1}/{iterations}\")\n",
    "        print(f\"Policy Loss: {policy_loss.item():.4f}, Value Loss: {value_loss.item():.4f}\")\n",
    "\n",
    "    # Save model weights\n",
    "    torch.save(model.state_dict(), \"alphazero_weights.pth\")\n",
    "    print(\"Training complete. Weights saved to 'alphazero_weights.pth'.\")\n",
    "\n",
    "    return policy_loss_list, value_loss_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "Y0ZrFDw7iblB",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 628229,
     "status": "ok",
     "timestamp": 1733702079186,
     "user": {
      "displayName": "Siyi Wu",
      "userId": "06196688456534608936"
     },
     "user_tz": 360
    },
    "id": "Y0ZrFDw7iblB",
    "outputId": "9da28a17-622b-4058-8bff-9520f6c32ad1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cpu\n",
      "Iteration 4/2000\n",
      "Policy Loss: 3.9260, Value Loss: 0.9793\n",
      "Iteration 5/2000\n",
      "Policy Loss: 3.8827, Value Loss: 0.9624\n",
      "Iteration 6/2000\n",
      "Policy Loss: 3.8612, Value Loss: 0.9456\n",
      "Iteration 7/2000\n",
      "Policy Loss: 3.7873, Value Loss: 0.9293\n",
      "Iteration 8/2000\n",
      "Policy Loss: 3.6960, Value Loss: 0.9409\n",
      "Iteration 9/2000\n",
      "Policy Loss: 3.5369, Value Loss: 0.9321\n",
      "Iteration 10/2000\n",
      "Policy Loss: 3.1771, Value Loss: 0.8652\n",
      "Iteration 11/2000\n",
      "Policy Loss: 2.9392, Value Loss: 0.6914\n",
      "Iteration 12/2000\n",
      "Policy Loss: 3.5882, Value Loss: 0.4920\n",
      "Iteration 13/2000\n",
      "Policy Loss: 3.2989, Value Loss: 0.5201\n",
      "Iteration 14/2000\n",
      "Policy Loss: 3.2554, Value Loss: 0.8188\n",
      "Iteration 15/2000\n",
      "Policy Loss: 2.8203, Value Loss: 0.6447\n",
      "Iteration 16/2000\n",
      "Policy Loss: 3.1837, Value Loss: 0.9550\n",
      "Iteration 17/2000\n",
      "Policy Loss: 3.2630, Value Loss: 0.6131\n",
      "Iteration 18/2000\n",
      "Policy Loss: 3.2076, Value Loss: 0.4540\n",
      "Iteration 19/2000\n",
      "Policy Loss: 2.9703, Value Loss: 0.4296\n",
      "Iteration 20/2000\n",
      "Policy Loss: 2.6618, Value Loss: 0.3909\n",
      "Iteration 21/2000\n",
      "Policy Loss: 3.2641, Value Loss: 0.3347\n",
      "Iteration 22/2000\n",
      "Policy Loss: 4.4075, Value Loss: 0.4408\n",
      "Iteration 23/2000\n",
      "Policy Loss: 3.3670, Value Loss: 0.6134\n",
      "Iteration 24/2000\n",
      "Policy Loss: 3.8220, Value Loss: 0.4677\n",
      "Iteration 25/2000\n",
      "Policy Loss: 3.3681, Value Loss: 0.4178\n",
      "Iteration 26/2000\n",
      "Policy Loss: 3.4497, Value Loss: 0.5420\n",
      "Iteration 27/2000\n",
      "Policy Loss: 3.5521, Value Loss: 0.7226\n",
      "Iteration 28/2000\n",
      "Policy Loss: 3.6841, Value Loss: 0.7461\n",
      "Iteration 29/2000\n",
      "Policy Loss: 3.0794, Value Loss: 0.3422\n",
      "Iteration 30/2000\n",
      "Policy Loss: 3.6793, Value Loss: 0.8024\n",
      "Iteration 31/2000\n",
      "Policy Loss: 3.5436, Value Loss: 0.6871\n",
      "Iteration 32/2000\n",
      "Policy Loss: 3.4497, Value Loss: 0.6353\n",
      "Iteration 33/2000\n",
      "Policy Loss: 3.7822, Value Loss: 0.6298\n",
      "Iteration 34/2000\n",
      "Policy Loss: 3.5551, Value Loss: 0.5627\n",
      "Iteration 35/2000\n",
      "Policy Loss: 3.3500, Value Loss: 0.6545\n",
      "Iteration 36/2000\n",
      "Policy Loss: 3.4129, Value Loss: 0.5747\n",
      "Iteration 37/2000\n",
      "Policy Loss: 3.2371, Value Loss: 0.6302\n",
      "Iteration 38/2000\n",
      "Policy Loss: 3.2043, Value Loss: 0.3189\n",
      "Iteration 39/2000\n",
      "Policy Loss: 3.3618, Value Loss: 0.5170\n",
      "Iteration 40/2000\n",
      "Policy Loss: 3.1588, Value Loss: 0.5571\n",
      "Iteration 41/2000\n",
      "Policy Loss: 2.7890, Value Loss: 0.3397\n",
      "Iteration 42/2000\n",
      "Policy Loss: 3.7159, Value Loss: 0.6794\n",
      "Iteration 43/2000\n",
      "Policy Loss: 2.5577, Value Loss: 0.6067\n",
      "Iteration 44/2000\n",
      "Policy Loss: 2.7664, Value Loss: 0.5498\n",
      "Iteration 45/2000\n",
      "Policy Loss: 3.3283, Value Loss: 0.5406\n",
      "Iteration 46/2000\n",
      "Policy Loss: 3.0434, Value Loss: 0.5313\n",
      "Iteration 47/2000\n",
      "Policy Loss: 2.6545, Value Loss: 0.4629\n",
      "Iteration 48/2000\n",
      "Policy Loss: 2.5652, Value Loss: 0.3944\n",
      "Iteration 49/2000\n",
      "Policy Loss: 3.0166, Value Loss: 0.3098\n",
      "Iteration 50/2000\n",
      "Policy Loss: 3.0286, Value Loss: 0.5447\n",
      "Iteration 51/2000\n",
      "Policy Loss: 2.8381, Value Loss: 0.5702\n",
      "Iteration 52/2000\n",
      "Policy Loss: 2.6208, Value Loss: 0.3674\n",
      "Iteration 53/2000\n",
      "Policy Loss: 2.9230, Value Loss: 0.5171\n",
      "Iteration 54/2000\n",
      "Policy Loss: 2.7391, Value Loss: 0.6065\n",
      "Iteration 55/2000\n",
      "Policy Loss: 3.2304, Value Loss: 0.5262\n",
      "Iteration 56/2000\n",
      "Policy Loss: 2.4509, Value Loss: 0.5072\n",
      "Iteration 57/2000\n",
      "Policy Loss: 3.3652, Value Loss: 0.6400\n",
      "Iteration 58/2000\n",
      "Policy Loss: 2.6470, Value Loss: 0.3689\n",
      "Iteration 59/2000\n",
      "Policy Loss: 3.7905, Value Loss: 0.6750\n",
      "Iteration 60/2000\n",
      "Policy Loss: 2.8598, Value Loss: 0.4130\n",
      "Iteration 61/2000\n",
      "Policy Loss: 2.6468, Value Loss: 0.5641\n",
      "Iteration 62/2000\n",
      "Policy Loss: 2.9692, Value Loss: 0.4694\n",
      "Iteration 63/2000\n",
      "Policy Loss: 2.2559, Value Loss: 0.3120\n",
      "Iteration 64/2000\n",
      "Policy Loss: 2.2099, Value Loss: 0.4308\n",
      "Iteration 65/2000\n",
      "Policy Loss: 2.8738, Value Loss: 0.5406\n",
      "Iteration 66/2000\n",
      "Policy Loss: 2.8893, Value Loss: 0.3778\n",
      "Iteration 67/2000\n",
      "Policy Loss: 1.9151, Value Loss: 0.3253\n",
      "Iteration 68/2000\n",
      "Policy Loss: 2.6782, Value Loss: 0.4964\n",
      "Iteration 69/2000\n",
      "Policy Loss: 3.2711, Value Loss: 0.4566\n",
      "Iteration 70/2000\n",
      "Policy Loss: 3.5590, Value Loss: 0.4096\n",
      "Iteration 71/2000\n",
      "Policy Loss: 3.1638, Value Loss: 0.5616\n",
      "Iteration 72/2000\n",
      "Policy Loss: 2.7695, Value Loss: 0.3516\n",
      "Iteration 73/2000\n",
      "Policy Loss: 1.7210, Value Loss: 0.2313\n",
      "Iteration 74/2000\n",
      "Policy Loss: 1.9818, Value Loss: 0.2422\n",
      "Iteration 75/2000\n",
      "Policy Loss: 1.9481, Value Loss: 0.1972\n",
      "Iteration 76/2000\n",
      "Policy Loss: 1.6348, Value Loss: 0.0617\n",
      "Iteration 77/2000\n",
      "Policy Loss: 2.2368, Value Loss: 0.3096\n",
      "Iteration 78/2000\n",
      "Policy Loss: 2.5792, Value Loss: 0.4928\n",
      "Iteration 79/2000\n",
      "Policy Loss: 1.7193, Value Loss: 0.2671\n",
      "Iteration 80/2000\n",
      "Policy Loss: 1.9925, Value Loss: 0.3570\n",
      "Iteration 81/2000\n",
      "Policy Loss: 1.9751, Value Loss: 0.2627\n",
      "Iteration 82/2000\n",
      "Policy Loss: 2.1516, Value Loss: 0.3297\n",
      "Iteration 83/2000\n",
      "Policy Loss: 2.2114, Value Loss: 0.3773\n",
      "Iteration 84/2000\n",
      "Policy Loss: 2.7466, Value Loss: 0.3666\n",
      "Iteration 85/2000\n",
      "Policy Loss: 1.9168, Value Loss: 0.2472\n",
      "Iteration 86/2000\n",
      "Policy Loss: 1.8948, Value Loss: 0.2993\n",
      "Iteration 87/2000\n",
      "Policy Loss: 1.0822, Value Loss: 0.2509\n",
      "Iteration 88/2000\n",
      "Policy Loss: 2.3363, Value Loss: 0.3723\n",
      "Iteration 89/2000\n",
      "Policy Loss: 1.6820, Value Loss: 0.3826\n",
      "Iteration 90/2000\n",
      "Policy Loss: 1.1503, Value Loss: 0.2858\n",
      "Iteration 91/2000\n",
      "Policy Loss: 1.8860, Value Loss: 0.2902\n",
      "Iteration 92/2000\n",
      "Policy Loss: 1.6625, Value Loss: 0.2950\n",
      "Iteration 93/2000\n",
      "Policy Loss: 1.7027, Value Loss: 0.2684\n",
      "Iteration 94/2000\n",
      "Policy Loss: 0.8852, Value Loss: 0.2015\n",
      "Iteration 95/2000\n",
      "Policy Loss: 1.2711, Value Loss: 0.2253\n",
      "Iteration 96/2000\n",
      "Policy Loss: 1.7724, Value Loss: 0.2119\n",
      "Iteration 97/2000\n",
      "Policy Loss: 2.3182, Value Loss: 0.2236\n",
      "Iteration 98/2000\n",
      "Policy Loss: 1.3719, Value Loss: 0.1539\n",
      "Iteration 99/2000\n",
      "Policy Loss: 1.8033, Value Loss: 0.2187\n",
      "Iteration 100/2000\n",
      "Policy Loss: 1.4459, Value Loss: 0.1460\n",
      "Iteration 101/2000\n",
      "Policy Loss: 1.2609, Value Loss: 0.0921\n",
      "Iteration 102/2000\n",
      "Policy Loss: 1.2571, Value Loss: 0.1169\n",
      "Iteration 103/2000\n",
      "Policy Loss: 1.0720, Value Loss: 0.1136\n",
      "Iteration 104/2000\n",
      "Policy Loss: 0.7646, Value Loss: 0.0659\n",
      "Iteration 105/2000\n",
      "Policy Loss: 0.6292, Value Loss: 0.0816\n",
      "Iteration 106/2000\n",
      "Policy Loss: 0.9527, Value Loss: 0.1246\n",
      "Iteration 107/2000\n",
      "Policy Loss: 0.3816, Value Loss: 0.0507\n",
      "Iteration 108/2000\n",
      "Policy Loss: 1.2998, Value Loss: 0.0520\n",
      "Iteration 109/2000\n",
      "Policy Loss: 0.6649, Value Loss: 0.0269\n",
      "Iteration 110/2000\n",
      "Policy Loss: 0.6593, Value Loss: 0.0851\n",
      "Iteration 111/2000\n",
      "Policy Loss: 0.8980, Value Loss: 0.0768\n",
      "Iteration 112/2000\n",
      "Policy Loss: 1.0703, Value Loss: 0.0709\n",
      "Iteration 113/2000\n",
      "Policy Loss: 0.7260, Value Loss: 0.0204\n",
      "Iteration 114/2000\n",
      "Policy Loss: 0.9906, Value Loss: 0.0594\n",
      "Iteration 115/2000\n",
      "Policy Loss: 1.0235, Value Loss: 0.1590\n",
      "Iteration 116/2000\n",
      "Policy Loss: 0.7388, Value Loss: 0.0640\n",
      "Iteration 117/2000\n",
      "Policy Loss: 0.4816, Value Loss: 0.0150\n",
      "Iteration 118/2000\n",
      "Policy Loss: 0.9795, Value Loss: 0.0108\n",
      "Iteration 119/2000\n",
      "Policy Loss: 0.5499, Value Loss: 0.0079\n",
      "Iteration 120/2000\n",
      "Policy Loss: 0.5106, Value Loss: 0.2321\n",
      "Iteration 121/2000\n",
      "Policy Loss: 0.4094, Value Loss: 0.1080\n",
      "Iteration 122/2000\n",
      "Policy Loss: 0.7761, Value Loss: 0.0430\n",
      "Iteration 123/2000\n",
      "Policy Loss: 0.4869, Value Loss: 0.0020\n",
      "Iteration 124/2000\n",
      "Policy Loss: 0.4471, Value Loss: 0.0864\n",
      "Iteration 125/2000\n",
      "Policy Loss: 0.3178, Value Loss: 0.1047\n",
      "Iteration 126/2000\n",
      "Policy Loss: 0.6298, Value Loss: 0.0805\n",
      "Iteration 127/2000\n",
      "Policy Loss: 0.6381, Value Loss: 0.0453\n",
      "Iteration 128/2000\n",
      "Policy Loss: 0.8982, Value Loss: 0.0432\n",
      "Iteration 129/2000\n",
      "Policy Loss: 1.4614, Value Loss: 0.0339\n",
      "Iteration 130/2000\n",
      "Policy Loss: 0.8642, Value Loss: 0.0218\n",
      "Iteration 131/2000\n",
      "Policy Loss: 0.5818, Value Loss: 0.0201\n",
      "Iteration 132/2000\n",
      "Policy Loss: 0.3524, Value Loss: 0.0835\n",
      "Iteration 133/2000\n",
      "Policy Loss: 0.7667, Value Loss: 0.0578\n",
      "Iteration 134/2000\n",
      "Policy Loss: 0.6574, Value Loss: 0.0593\n",
      "Iteration 135/2000\n",
      "Policy Loss: 0.3583, Value Loss: 0.0416\n",
      "Iteration 136/2000\n",
      "Policy Loss: 0.5177, Value Loss: 0.0738\n",
      "Iteration 137/2000\n",
      "Policy Loss: 0.3819, Value Loss: 0.0221\n",
      "Iteration 138/2000\n",
      "Policy Loss: 0.9483, Value Loss: 0.0853\n",
      "Iteration 139/2000\n",
      "Policy Loss: 1.3558, Value Loss: 0.0250\n",
      "Iteration 140/2000\n",
      "Policy Loss: 0.7844, Value Loss: 0.0727\n",
      "Iteration 141/2000\n",
      "Policy Loss: 0.4971, Value Loss: 0.0030\n",
      "Iteration 142/2000\n",
      "Policy Loss: 0.4817, Value Loss: 0.0567\n",
      "Iteration 143/2000\n",
      "Policy Loss: 0.9463, Value Loss: 0.0013\n",
      "Iteration 144/2000\n",
      "Policy Loss: 0.5053, Value Loss: 0.0905\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 145/2000\n",
      "Policy Loss: 0.4750, Value Loss: 0.0001\n",
      "Iteration 146/2000\n",
      "Policy Loss: 1.3037, Value Loss: 0.1234\n",
      "Iteration 147/2000\n",
      "Policy Loss: 0.8938, Value Loss: 0.1692\n",
      "Iteration 148/2000\n",
      "Policy Loss: 0.3487, Value Loss: 0.2092\n",
      "Iteration 149/2000\n",
      "Policy Loss: 0.3179, Value Loss: 0.0673\n",
      "Iteration 150/2000\n",
      "Policy Loss: 0.2519, Value Loss: 0.1217\n",
      "Iteration 151/2000\n",
      "Policy Loss: 0.7480, Value Loss: 0.0336\n",
      "Iteration 152/2000\n",
      "Policy Loss: 0.6775, Value Loss: 0.0076\n",
      "Iteration 153/2000\n",
      "Policy Loss: 0.5126, Value Loss: 0.0689\n",
      "Iteration 154/2000\n",
      "Policy Loss: 0.2815, Value Loss: 0.0005\n",
      "Iteration 155/2000\n",
      "Policy Loss: 0.6462, Value Loss: 0.0420\n",
      "Iteration 156/2000\n",
      "Policy Loss: 0.6537, Value Loss: 0.0410\n",
      "Iteration 157/2000\n",
      "Policy Loss: 0.4758, Value Loss: 0.0173\n",
      "Iteration 158/2000\n",
      "Policy Loss: 0.4744, Value Loss: 0.0088\n",
      "Iteration 159/2000\n",
      "Policy Loss: 0.3921, Value Loss: 0.0103\n",
      "Iteration 160/2000\n",
      "Policy Loss: 0.9765, Value Loss: 0.0008\n",
      "Iteration 161/2000\n",
      "Policy Loss: 0.5344, Value Loss: 0.0245\n",
      "Iteration 162/2000\n",
      "Policy Loss: 0.2793, Value Loss: 0.0052\n",
      "Iteration 163/2000\n",
      "Policy Loss: 0.3139, Value Loss: 0.0001\n",
      "Iteration 164/2000\n",
      "Policy Loss: 0.1479, Value Loss: 0.0002\n",
      "Iteration 165/2000\n",
      "Policy Loss: 0.5065, Value Loss: 0.0293\n",
      "Iteration 166/2000\n",
      "Policy Loss: 0.2105, Value Loss: 0.0026\n",
      "Iteration 167/2000\n",
      "Policy Loss: 0.6638, Value Loss: 0.0020\n",
      "Iteration 168/2000\n",
      "Policy Loss: 0.1249, Value Loss: 0.0007\n",
      "Iteration 169/2000\n",
      "Policy Loss: 1.0826, Value Loss: 0.0011\n",
      "Iteration 170/2000\n",
      "Policy Loss: 0.3637, Value Loss: 0.0056\n",
      "Iteration 171/2000\n",
      "Policy Loss: 0.1374, Value Loss: 0.0154\n",
      "Iteration 172/2000\n",
      "Policy Loss: 0.9115, Value Loss: 0.0191\n",
      "Iteration 173/2000\n",
      "Policy Loss: 0.3638, Value Loss: 0.0019\n",
      "Iteration 174/2000\n",
      "Policy Loss: 0.3687, Value Loss: 0.0007\n",
      "Iteration 175/2000\n",
      "Policy Loss: 0.1817, Value Loss: 0.0041\n",
      "Iteration 176/2000\n",
      "Policy Loss: 0.3665, Value Loss: 0.0267\n",
      "Iteration 177/2000\n",
      "Policy Loss: 0.3749, Value Loss: 0.0083\n",
      "Iteration 178/2000\n",
      "Policy Loss: 0.0660, Value Loss: 0.0047\n",
      "Iteration 179/2000\n",
      "Policy Loss: 0.1684, Value Loss: 0.0052\n",
      "Iteration 180/2000\n",
      "Policy Loss: 0.1289, Value Loss: 0.0000\n",
      "Iteration 181/2000\n",
      "Policy Loss: 0.3835, Value Loss: 0.0066\n",
      "Iteration 182/2000\n",
      "Policy Loss: 0.1135, Value Loss: 0.0036\n",
      "Iteration 183/2000\n",
      "Policy Loss: 0.0301, Value Loss: 0.0139\n",
      "Iteration 184/2000\n",
      "Policy Loss: 0.0147, Value Loss: 0.0029\n",
      "Iteration 185/2000\n",
      "Policy Loss: 0.0764, Value Loss: 0.0020\n",
      "Iteration 186/2000\n",
      "Policy Loss: 0.6953, Value Loss: 0.0074\n",
      "Iteration 187/2000\n",
      "Policy Loss: 0.6268, Value Loss: 0.0001\n",
      "Iteration 188/2000\n",
      "Policy Loss: 2.0613, Value Loss: 0.0023\n",
      "Iteration 189/2000\n",
      "Policy Loss: 0.0416, Value Loss: 0.0007\n",
      "Iteration 190/2000\n",
      "Policy Loss: 0.1595, Value Loss: 0.0023\n",
      "Iteration 191/2000\n",
      "Policy Loss: 0.7814, Value Loss: 0.0009\n",
      "Iteration 192/2000\n",
      "Policy Loss: 0.5662, Value Loss: 0.0064\n",
      "Iteration 193/2000\n",
      "Policy Loss: 0.8137, Value Loss: 0.0177\n",
      "Iteration 194/2000\n",
      "Policy Loss: 0.0934, Value Loss: 0.0032\n",
      "Iteration 195/2000\n",
      "Policy Loss: 0.2933, Value Loss: 0.0159\n",
      "Iteration 196/2000\n",
      "Policy Loss: 0.2675, Value Loss: 0.0022\n",
      "Iteration 197/2000\n",
      "Policy Loss: 0.0751, Value Loss: 0.0002\n",
      "Iteration 198/2000\n",
      "Policy Loss: 0.2097, Value Loss: 0.0108\n",
      "Iteration 199/2000\n",
      "Policy Loss: 0.6161, Value Loss: 0.0064\n",
      "Iteration 200/2000\n",
      "Policy Loss: 0.2678, Value Loss: 0.0010\n",
      "Iteration 201/2000\n",
      "Policy Loss: 0.8181, Value Loss: 0.0175\n",
      "Iteration 202/2000\n",
      "Policy Loss: 1.2001, Value Loss: 0.0233\n",
      "Iteration 203/2000\n",
      "Policy Loss: 0.3734, Value Loss: 0.0039\n",
      "Iteration 204/2000\n",
      "Policy Loss: 0.1970, Value Loss: 0.0006\n",
      "Iteration 205/2000\n",
      "Policy Loss: 0.6901, Value Loss: 0.0216\n",
      "Iteration 206/2000\n",
      "Policy Loss: 0.2110, Value Loss: 0.0004\n",
      "Iteration 207/2000\n",
      "Policy Loss: 0.1711, Value Loss: 0.0182\n",
      "Iteration 208/2000\n",
      "Policy Loss: 0.6569, Value Loss: 0.0076\n",
      "Iteration 209/2000\n",
      "Policy Loss: 0.4361, Value Loss: 0.0230\n",
      "Iteration 210/2000\n",
      "Policy Loss: 0.1582, Value Loss: 0.0888\n",
      "Iteration 211/2000\n",
      "Policy Loss: 0.3264, Value Loss: 0.0223\n",
      "Iteration 212/2000\n",
      "Policy Loss: 0.1441, Value Loss: 0.0074\n",
      "Iteration 213/2000\n",
      "Policy Loss: 0.3148, Value Loss: 0.0069\n",
      "Iteration 214/2000\n",
      "Policy Loss: 0.3107, Value Loss: 0.0026\n",
      "Iteration 215/2000\n",
      "Policy Loss: 0.1277, Value Loss: 0.0059\n",
      "Iteration 216/2000\n",
      "Policy Loss: 0.5000, Value Loss: 0.0029\n",
      "Iteration 217/2000\n",
      "Policy Loss: 0.0741, Value Loss: 0.0175\n",
      "Iteration 218/2000\n",
      "Policy Loss: 0.1153, Value Loss: 0.0079\n",
      "Iteration 219/2000\n",
      "Policy Loss: 0.1968, Value Loss: 0.0053\n",
      "Iteration 220/2000\n",
      "Policy Loss: 0.1406, Value Loss: 0.0138\n",
      "Iteration 221/2000\n",
      "Policy Loss: 0.6545, Value Loss: 0.0043\n",
      "Iteration 222/2000\n",
      "Policy Loss: 0.1780, Value Loss: 0.0003\n",
      "Iteration 223/2000\n",
      "Policy Loss: 0.4403, Value Loss: 0.0056\n",
      "Iteration 224/2000\n",
      "Policy Loss: 0.2599, Value Loss: 0.0010\n",
      "Iteration 225/2000\n",
      "Policy Loss: 0.3793, Value Loss: 0.0007\n",
      "Iteration 226/2000\n",
      "Policy Loss: 0.5135, Value Loss: 0.0016\n",
      "Iteration 227/2000\n",
      "Policy Loss: 0.0364, Value Loss: 0.0018\n",
      "Iteration 228/2000\n",
      "Policy Loss: 0.2448, Value Loss: 0.0062\n",
      "Iteration 229/2000\n",
      "Policy Loss: 0.2395, Value Loss: 0.0009\n",
      "Iteration 230/2000\n",
      "Policy Loss: 0.1972, Value Loss: 0.0001\n",
      "Iteration 231/2000\n",
      "Policy Loss: 0.0751, Value Loss: 0.0014\n",
      "Iteration 232/2000\n",
      "Policy Loss: 0.2712, Value Loss: 0.0007\n",
      "Iteration 233/2000\n",
      "Policy Loss: 0.1543, Value Loss: 0.0072\n",
      "Iteration 234/2000\n",
      "Policy Loss: 0.1240, Value Loss: 0.0092\n",
      "Iteration 235/2000\n",
      "Policy Loss: 0.1285, Value Loss: 0.0001\n",
      "Iteration 236/2000\n",
      "Policy Loss: 0.0182, Value Loss: 0.0018\n",
      "Iteration 237/2000\n",
      "Policy Loss: 0.1111, Value Loss: 0.0014\n",
      "Iteration 238/2000\n",
      "Policy Loss: 0.0619, Value Loss: 0.0002\n",
      "Iteration 239/2000\n",
      "Policy Loss: 0.1077, Value Loss: 0.0057\n",
      "Iteration 240/2000\n",
      "Policy Loss: 0.1231, Value Loss: 0.0003\n",
      "Iteration 241/2000\n",
      "Policy Loss: 0.0613, Value Loss: 0.0000\n",
      "Iteration 242/2000\n",
      "Policy Loss: 0.1521, Value Loss: 0.0000\n",
      "Iteration 243/2000\n",
      "Policy Loss: 0.0445, Value Loss: 0.0012\n",
      "Iteration 244/2000\n",
      "Policy Loss: 0.0763, Value Loss: 0.0040\n",
      "Iteration 245/2000\n",
      "Policy Loss: 0.0679, Value Loss: 0.0268\n",
      "Iteration 246/2000\n",
      "Policy Loss: 0.0474, Value Loss: 0.0065\n",
      "Iteration 247/2000\n",
      "Policy Loss: 0.4845, Value Loss: 0.0000\n",
      "Iteration 248/2000\n",
      "Policy Loss: 0.3317, Value Loss: 0.0026\n",
      "Iteration 249/2000\n",
      "Policy Loss: 0.0633, Value Loss: 0.0014\n",
      "Iteration 250/2000\n",
      "Policy Loss: 0.0248, Value Loss: 0.0002\n",
      "Iteration 251/2000\n",
      "Policy Loss: 0.1158, Value Loss: 0.0051\n",
      "Iteration 252/2000\n",
      "Policy Loss: 0.2164, Value Loss: 0.0003\n",
      "Iteration 253/2000\n",
      "Policy Loss: 0.0638, Value Loss: 0.0356\n",
      "Iteration 254/2000\n",
      "Policy Loss: 0.2322, Value Loss: 0.0003\n",
      "Iteration 255/2000\n",
      "Policy Loss: 0.1209, Value Loss: 0.0016\n",
      "Iteration 256/2000\n",
      "Policy Loss: 0.0957, Value Loss: 0.0000\n",
      "Iteration 257/2000\n",
      "Policy Loss: 0.0475, Value Loss: 0.0159\n",
      "Iteration 258/2000\n",
      "Policy Loss: 0.0814, Value Loss: 0.0062\n",
      "Iteration 259/2000\n",
      "Policy Loss: 0.1236, Value Loss: 0.0039\n",
      "Iteration 260/2000\n",
      "Policy Loss: 0.1257, Value Loss: 0.0007\n",
      "Iteration 261/2000\n",
      "Policy Loss: 0.0452, Value Loss: 0.0016\n",
      "Iteration 262/2000\n",
      "Policy Loss: 0.0712, Value Loss: 0.0011\n",
      "Iteration 263/2000\n",
      "Policy Loss: 0.0219, Value Loss: 0.0108\n",
      "Iteration 264/2000\n",
      "Policy Loss: 1.9054, Value Loss: 0.0222\n",
      "Iteration 265/2000\n",
      "Policy Loss: 0.0858, Value Loss: 0.0121\n",
      "Iteration 266/2000\n",
      "Policy Loss: 1.5079, Value Loss: 0.0145\n",
      "Iteration 267/2000\n",
      "Policy Loss: 0.0122, Value Loss: 0.0016\n",
      "Iteration 268/2000\n",
      "Policy Loss: 0.0261, Value Loss: 0.0003\n",
      "Iteration 269/2000\n",
      "Policy Loss: 0.1209, Value Loss: 0.0097\n",
      "Iteration 270/2000\n",
      "Policy Loss: 0.0451, Value Loss: 0.0092\n",
      "Iteration 271/2000\n",
      "Policy Loss: 1.3301, Value Loss: 0.0133\n",
      "Iteration 272/2000\n",
      "Policy Loss: 0.0571, Value Loss: 0.0093\n",
      "Iteration 273/2000\n",
      "Policy Loss: 0.1088, Value Loss: 0.0015\n",
      "Iteration 274/2000\n",
      "Policy Loss: 0.2307, Value Loss: 0.0151\n",
      "Iteration 275/2000\n",
      "Policy Loss: 0.0929, Value Loss: 0.0001\n",
      "Iteration 276/2000\n",
      "Policy Loss: 0.8584, Value Loss: 0.0041\n",
      "Iteration 277/2000\n",
      "Policy Loss: 0.0397, Value Loss: 0.0018\n",
      "Iteration 278/2000\n",
      "Policy Loss: 0.0842, Value Loss: 0.0017\n",
      "Iteration 279/2000\n",
      "Policy Loss: 0.0545, Value Loss: 0.0007\n",
      "Iteration 280/2000\n",
      "Policy Loss: 0.0773, Value Loss: 0.0015\n",
      "Iteration 281/2000\n",
      "Policy Loss: 0.0794, Value Loss: 0.0001\n",
      "Iteration 282/2000\n",
      "Policy Loss: 0.0936, Value Loss: 0.0004\n",
      "Iteration 283/2000\n",
      "Policy Loss: 0.1169, Value Loss: 0.0015\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 284/2000\n",
      "Policy Loss: 0.2489, Value Loss: 0.0005\n",
      "Iteration 285/2000\n",
      "Policy Loss: 0.0696, Value Loss: 0.0016\n",
      "Iteration 286/2000\n",
      "Policy Loss: 0.0706, Value Loss: 0.0025\n",
      "Iteration 287/2000\n",
      "Policy Loss: 0.0824, Value Loss: 0.0008\n",
      "Iteration 288/2000\n",
      "Policy Loss: 0.0938, Value Loss: 0.0006\n",
      "Iteration 289/2000\n",
      "Policy Loss: 0.1386, Value Loss: 0.0001\n",
      "Iteration 290/2000\n",
      "Policy Loss: 0.4102, Value Loss: 0.0000\n",
      "Iteration 291/2000\n",
      "Policy Loss: 0.1207, Value Loss: 0.0002\n",
      "Iteration 292/2000\n",
      "Policy Loss: 0.3827, Value Loss: 0.0001\n",
      "Iteration 293/2000\n",
      "Policy Loss: 0.0199, Value Loss: 0.0194\n",
      "Iteration 294/2000\n",
      "Policy Loss: 0.0559, Value Loss: 0.0109\n",
      "Iteration 295/2000\n",
      "Policy Loss: 0.0296, Value Loss: 0.0029\n",
      "Iteration 296/2000\n",
      "Policy Loss: 0.1701, Value Loss: 0.0184\n",
      "Iteration 297/2000\n",
      "Policy Loss: 0.1626, Value Loss: 0.0003\n",
      "Iteration 298/2000\n",
      "Policy Loss: 0.0782, Value Loss: 0.0002\n",
      "Iteration 299/2000\n",
      "Policy Loss: 0.0587, Value Loss: 0.0016\n",
      "Iteration 300/2000\n",
      "Policy Loss: 0.1971, Value Loss: 0.0159\n",
      "Iteration 301/2000\n",
      "Policy Loss: 0.1088, Value Loss: 0.0327\n",
      "Iteration 302/2000\n",
      "Policy Loss: 0.1472, Value Loss: 0.0153\n",
      "Iteration 303/2000\n",
      "Policy Loss: 0.0164, Value Loss: 0.0000\n",
      "Iteration 304/2000\n",
      "Policy Loss: 0.0165, Value Loss: 0.0003\n",
      "Iteration 305/2000\n",
      "Policy Loss: 0.0205, Value Loss: 0.0080\n",
      "Iteration 306/2000\n",
      "Policy Loss: 0.3476, Value Loss: 0.0040\n",
      "Iteration 307/2000\n",
      "Policy Loss: 0.0207, Value Loss: 0.0056\n",
      "Iteration 308/2000\n",
      "Policy Loss: 0.0256, Value Loss: 0.0068\n",
      "Iteration 309/2000\n",
      "Policy Loss: 0.1422, Value Loss: 0.0055\n",
      "Iteration 310/2000\n",
      "Policy Loss: 0.0199, Value Loss: 0.0001\n",
      "Iteration 311/2000\n",
      "Policy Loss: 0.1558, Value Loss: 0.0283\n",
      "Iteration 312/2000\n",
      "Policy Loss: 0.0042, Value Loss: 0.0020\n",
      "Iteration 313/2000\n",
      "Policy Loss: 0.0116, Value Loss: 0.0141\n",
      "Iteration 314/2000\n",
      "Policy Loss: 0.1500, Value Loss: 0.0007\n",
      "Iteration 315/2000\n",
      "Policy Loss: 0.0227, Value Loss: 0.0030\n",
      "Iteration 316/2000\n",
      "Policy Loss: 0.0068, Value Loss: 0.0018\n",
      "Iteration 317/2000\n",
      "Policy Loss: 0.0234, Value Loss: 0.0207\n",
      "Iteration 318/2000\n",
      "Policy Loss: 0.0650, Value Loss: 0.0023\n",
      "Iteration 319/2000\n",
      "Policy Loss: 0.0071, Value Loss: 0.0023\n",
      "Iteration 320/2000\n",
      "Policy Loss: 0.0047, Value Loss: 0.0005\n",
      "Iteration 321/2000\n",
      "Policy Loss: 0.0093, Value Loss: 0.0002\n",
      "Iteration 322/2000\n",
      "Policy Loss: 0.8591, Value Loss: 0.0024\n",
      "Iteration 323/2000\n",
      "Policy Loss: 0.0133, Value Loss: 0.0018\n",
      "Iteration 324/2000\n",
      "Policy Loss: 0.0228, Value Loss: 0.0003\n",
      "Iteration 325/2000\n",
      "Policy Loss: 0.0588, Value Loss: 0.0001\n",
      "Iteration 326/2000\n",
      "Policy Loss: 0.0065, Value Loss: 0.0001\n",
      "Iteration 327/2000\n",
      "Policy Loss: 0.0171, Value Loss: 0.0007\n",
      "Iteration 328/2000\n",
      "Policy Loss: 0.0059, Value Loss: 0.0000\n",
      "Iteration 329/2000\n",
      "Policy Loss: 0.0580, Value Loss: 0.0004\n",
      "Iteration 330/2000\n",
      "Policy Loss: 0.0468, Value Loss: 0.0052\n",
      "Iteration 331/2000\n",
      "Policy Loss: 0.0354, Value Loss: 0.0000\n",
      "Iteration 332/2000\n",
      "Policy Loss: 0.0094, Value Loss: 0.0007\n",
      "Iteration 333/2000\n",
      "Policy Loss: 0.0078, Value Loss: 0.0011\n",
      "Iteration 334/2000\n",
      "Policy Loss: 0.0093, Value Loss: 0.0034\n",
      "Iteration 335/2000\n",
      "Policy Loss: 0.0017, Value Loss: 0.0002\n",
      "Iteration 336/2000\n",
      "Policy Loss: 0.0019, Value Loss: 0.0021\n",
      "Iteration 337/2000\n",
      "Policy Loss: 0.0140, Value Loss: 0.0000\n",
      "Iteration 338/2000\n",
      "Policy Loss: 1.0249, Value Loss: 0.0008\n",
      "Iteration 339/2000\n",
      "Policy Loss: 0.0342, Value Loss: 0.0037\n",
      "Iteration 340/2000\n",
      "Policy Loss: 0.1174, Value Loss: 0.0020\n",
      "Iteration 341/2000\n",
      "Policy Loss: 0.0253, Value Loss: 0.0104\n",
      "Iteration 342/2000\n",
      "Policy Loss: 0.1388, Value Loss: 0.0056\n",
      "Iteration 343/2000\n",
      "Policy Loss: 0.4624, Value Loss: 0.0055\n",
      "Iteration 344/2000\n",
      "Policy Loss: 0.0871, Value Loss: 0.0001\n",
      "Iteration 345/2000\n",
      "Policy Loss: 0.0863, Value Loss: 0.0012\n",
      "Iteration 346/2000\n",
      "Policy Loss: 0.1439, Value Loss: 0.0025\n",
      "Iteration 347/2000\n",
      "Policy Loss: 0.0141, Value Loss: 0.0010\n",
      "Iteration 348/2000\n",
      "Policy Loss: 0.0251, Value Loss: 0.0017\n",
      "Iteration 349/2000\n",
      "Policy Loss: 0.1378, Value Loss: 0.0031\n",
      "Iteration 350/2000\n",
      "Policy Loss: 0.0242, Value Loss: 0.0001\n",
      "Iteration 351/2000\n",
      "Policy Loss: 0.2364, Value Loss: 0.0012\n",
      "Iteration 352/2000\n",
      "Policy Loss: 0.4180, Value Loss: 0.0001\n",
      "Iteration 353/2000\n",
      "Policy Loss: 0.3228, Value Loss: 0.0007\n",
      "Iteration 354/2000\n",
      "Policy Loss: 0.0561, Value Loss: 0.0001\n",
      "Iteration 355/2000\n",
      "Policy Loss: 0.4435, Value Loss: 0.0001\n",
      "Iteration 356/2000\n",
      "Policy Loss: 0.0507, Value Loss: 0.0001\n",
      "Iteration 357/2000\n",
      "Policy Loss: 0.0222, Value Loss: 0.0002\n",
      "Iteration 358/2000\n",
      "Policy Loss: 0.0188, Value Loss: 0.0035\n",
      "Iteration 359/2000\n",
      "Policy Loss: 0.0631, Value Loss: 0.0009\n",
      "Iteration 360/2000\n",
      "Policy Loss: 0.0552, Value Loss: 0.0018\n",
      "Iteration 361/2000\n",
      "Policy Loss: 0.0652, Value Loss: 0.0014\n",
      "Iteration 362/2000\n",
      "Policy Loss: 0.0591, Value Loss: 0.0002\n",
      "Iteration 363/2000\n",
      "Policy Loss: 0.1000, Value Loss: 0.0043\n",
      "Iteration 364/2000\n",
      "Policy Loss: 0.0531, Value Loss: 0.0020\n",
      "Iteration 365/2000\n",
      "Policy Loss: 0.1761, Value Loss: 0.0006\n",
      "Iteration 366/2000\n",
      "Policy Loss: 0.2792, Value Loss: 0.0025\n",
      "Iteration 367/2000\n",
      "Policy Loss: 0.0307, Value Loss: 0.0002\n",
      "Iteration 368/2000\n",
      "Policy Loss: 0.0305, Value Loss: 0.0006\n",
      "Iteration 369/2000\n",
      "Policy Loss: 0.0654, Value Loss: 0.0008\n",
      "Iteration 370/2000\n",
      "Policy Loss: 0.0614, Value Loss: 0.0001\n",
      "Iteration 371/2000\n",
      "Policy Loss: 0.1596, Value Loss: 0.0001\n",
      "Iteration 372/2000\n",
      "Policy Loss: 0.2551, Value Loss: 0.0003\n",
      "Iteration 373/2000\n",
      "Policy Loss: 0.2161, Value Loss: 0.0002\n",
      "Iteration 374/2000\n",
      "Policy Loss: 0.0253, Value Loss: 0.0004\n",
      "Iteration 375/2000\n",
      "Policy Loss: 0.0609, Value Loss: 0.0048\n",
      "Iteration 376/2000\n",
      "Policy Loss: 0.1042, Value Loss: 0.0001\n",
      "Iteration 377/2000\n",
      "Policy Loss: 0.0186, Value Loss: 0.0020\n",
      "Iteration 378/2000\n",
      "Policy Loss: 0.1229, Value Loss: 0.0019\n",
      "Iteration 379/2000\n",
      "Policy Loss: 0.0173, Value Loss: 0.0000\n",
      "Iteration 380/2000\n",
      "Policy Loss: 0.0169, Value Loss: 0.0001\n",
      "Iteration 381/2000\n",
      "Policy Loss: 0.0084, Value Loss: 0.0018\n",
      "Iteration 382/2000\n",
      "Policy Loss: 0.0042, Value Loss: 0.0034\n",
      "Iteration 383/2000\n",
      "Policy Loss: 0.3734, Value Loss: 0.0004\n",
      "Iteration 384/2000\n",
      "Policy Loss: 0.0671, Value Loss: 0.0002\n",
      "Iteration 385/2000\n",
      "Policy Loss: 0.0256, Value Loss: 0.0000\n",
      "Iteration 386/2000\n",
      "Policy Loss: 0.0523, Value Loss: 0.0001\n",
      "Iteration 387/2000\n",
      "Policy Loss: 0.0063, Value Loss: 0.0027\n",
      "Iteration 388/2000\n",
      "Policy Loss: 0.0230, Value Loss: 0.0002\n",
      "Iteration 389/2000\n",
      "Policy Loss: 0.0405, Value Loss: 0.0003\n",
      "Iteration 390/2000\n",
      "Policy Loss: 0.0126, Value Loss: 0.0005\n",
      "Iteration 391/2000\n",
      "Policy Loss: 0.0259, Value Loss: 0.0001\n",
      "Iteration 392/2000\n",
      "Policy Loss: 0.0222, Value Loss: 0.0042\n",
      "Iteration 393/2000\n",
      "Policy Loss: 0.0248, Value Loss: 0.0001\n",
      "Iteration 394/2000\n",
      "Policy Loss: 0.0354, Value Loss: 0.0010\n",
      "Iteration 395/2000\n",
      "Policy Loss: 0.0215, Value Loss: 0.0009\n",
      "Iteration 396/2000\n",
      "Policy Loss: 0.0154, Value Loss: 0.0002\n",
      "Iteration 397/2000\n",
      "Policy Loss: 0.0202, Value Loss: 0.0001\n",
      "Iteration 398/2000\n",
      "Policy Loss: 0.2215, Value Loss: 0.0052\n",
      "Iteration 399/2000\n",
      "Policy Loss: 0.0052, Value Loss: 0.0000\n",
      "Iteration 400/2000\n",
      "Policy Loss: 0.0157, Value Loss: 0.0033\n",
      "Iteration 401/2000\n",
      "Policy Loss: 0.0023, Value Loss: 0.0009\n",
      "Iteration 402/2000\n",
      "Policy Loss: 0.0134, Value Loss: 0.0011\n",
      "Iteration 403/2000\n",
      "Policy Loss: 0.1084, Value Loss: 0.0000\n",
      "Iteration 404/2000\n",
      "Policy Loss: 0.0061, Value Loss: 0.0016\n",
      "Iteration 405/2000\n",
      "Policy Loss: 0.0131, Value Loss: 0.0011\n",
      "Iteration 406/2000\n",
      "Policy Loss: 0.0086, Value Loss: 0.0005\n",
      "Iteration 407/2000\n",
      "Policy Loss: 0.0126, Value Loss: 0.0000\n",
      "Iteration 408/2000\n",
      "Policy Loss: 0.2277, Value Loss: 0.0016\n",
      "Iteration 409/2000\n",
      "Policy Loss: 0.0263, Value Loss: 0.0002\n",
      "Iteration 410/2000\n",
      "Policy Loss: 0.0043, Value Loss: 0.0000\n",
      "Iteration 411/2000\n",
      "Policy Loss: 0.0043, Value Loss: 0.0008\n",
      "Iteration 412/2000\n",
      "Policy Loss: 0.0174, Value Loss: 0.0002\n",
      "Iteration 413/2000\n",
      "Policy Loss: 0.0065, Value Loss: 0.0000\n",
      "Iteration 414/2000\n",
      "Policy Loss: 0.0764, Value Loss: 0.0058\n",
      "Iteration 415/2000\n",
      "Policy Loss: 0.1431, Value Loss: 0.0006\n",
      "Iteration 416/2000\n",
      "Policy Loss: 0.0234, Value Loss: 0.0000\n",
      "Iteration 417/2000\n",
      "Policy Loss: 0.0062, Value Loss: 0.0033\n",
      "Iteration 418/2000\n",
      "Policy Loss: 0.0078, Value Loss: 0.0001\n",
      "Iteration 419/2000\n",
      "Policy Loss: 0.2231, Value Loss: 0.0000\n",
      "Iteration 420/2000\n",
      "Policy Loss: 0.0043, Value Loss: 0.0006\n",
      "Iteration 421/2000\n",
      "Policy Loss: 0.0108, Value Loss: 0.0009\n",
      "Iteration 422/2000\n",
      "Policy Loss: 0.0170, Value Loss: 0.0018\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 423/2000\n",
      "Policy Loss: 0.2315, Value Loss: 0.0014\n",
      "Iteration 424/2000\n",
      "Policy Loss: 0.0015, Value Loss: 0.0024\n",
      "Iteration 425/2000\n",
      "Policy Loss: 0.0201, Value Loss: 0.0006\n",
      "Iteration 426/2000\n",
      "Policy Loss: 0.0034, Value Loss: 0.0006\n",
      "Iteration 427/2000\n",
      "Policy Loss: 0.0174, Value Loss: 0.0000\n",
      "Iteration 428/2000\n",
      "Policy Loss: 0.0078, Value Loss: 0.0008\n",
      "Iteration 429/2000\n",
      "Policy Loss: 0.0176, Value Loss: 0.0003\n",
      "Iteration 430/2000\n",
      "Policy Loss: 0.1077, Value Loss: 0.0016\n",
      "Iteration 431/2000\n",
      "Policy Loss: 0.1474, Value Loss: 0.0006\n",
      "Iteration 432/2000\n",
      "Policy Loss: 0.0948, Value Loss: 0.0001\n",
      "Iteration 433/2000\n",
      "Policy Loss: 0.0183, Value Loss: 0.0000\n",
      "Iteration 434/2000\n",
      "Policy Loss: 0.0288, Value Loss: 0.0007\n",
      "Iteration 435/2000\n",
      "Policy Loss: 0.0080, Value Loss: 0.0003\n",
      "Iteration 436/2000\n",
      "Policy Loss: 0.0362, Value Loss: 0.0004\n",
      "Iteration 437/2000\n",
      "Policy Loss: 0.0059, Value Loss: 0.0002\n",
      "Iteration 438/2000\n",
      "Policy Loss: 0.6204, Value Loss: 0.0003\n",
      "Iteration 439/2000\n",
      "Policy Loss: 0.0085, Value Loss: 0.0003\n",
      "Iteration 440/2000\n",
      "Policy Loss: 0.1733, Value Loss: 0.0002\n",
      "Iteration 441/2000\n",
      "Policy Loss: 0.0918, Value Loss: 0.0000\n",
      "Iteration 442/2000\n",
      "Policy Loss: 0.0819, Value Loss: 0.0001\n",
      "Iteration 443/2000\n",
      "Policy Loss: 0.0072, Value Loss: 0.0000\n",
      "Iteration 444/2000\n",
      "Policy Loss: 0.0206, Value Loss: 0.0000\n",
      "Iteration 445/2000\n",
      "Policy Loss: 0.5452, Value Loss: 0.0000\n",
      "Iteration 446/2000\n",
      "Policy Loss: 0.1299, Value Loss: 0.0012\n",
      "Iteration 447/2000\n",
      "Policy Loss: 0.1753, Value Loss: 0.0013\n",
      "Iteration 448/2000\n",
      "Policy Loss: 0.0084, Value Loss: 0.0002\n",
      "Iteration 449/2000\n",
      "Policy Loss: 0.3061, Value Loss: 0.0000\n",
      "Iteration 450/2000\n",
      "Policy Loss: 0.0042, Value Loss: 0.0006\n",
      "Iteration 451/2000\n",
      "Policy Loss: 0.0136, Value Loss: 0.0000\n",
      "Iteration 452/2000\n",
      "Policy Loss: 0.1438, Value Loss: 0.0001\n",
      "Iteration 453/2000\n",
      "Policy Loss: 0.2182, Value Loss: 0.0000\n",
      "Iteration 454/2000\n",
      "Policy Loss: 0.0046, Value Loss: 0.0001\n",
      "Iteration 455/2000\n",
      "Policy Loss: 0.1058, Value Loss: 0.0001\n",
      "Iteration 456/2000\n",
      "Policy Loss: 0.1412, Value Loss: 0.0000\n",
      "Iteration 457/2000\n",
      "Policy Loss: 0.0054, Value Loss: 0.0003\n",
      "Iteration 458/2000\n",
      "Policy Loss: 0.0205, Value Loss: 0.0000\n",
      "Iteration 459/2000\n",
      "Policy Loss: 0.1057, Value Loss: 0.0000\n",
      "Iteration 460/2000\n",
      "Policy Loss: 0.1860, Value Loss: 0.0001\n",
      "Iteration 461/2000\n",
      "Policy Loss: 0.0113, Value Loss: 0.0001\n",
      "Iteration 462/2000\n",
      "Policy Loss: 0.0082, Value Loss: 0.0000\n",
      "Iteration 463/2000\n",
      "Policy Loss: 0.6102, Value Loss: 0.0000\n",
      "Iteration 464/2000\n",
      "Policy Loss: 0.1316, Value Loss: 0.0001\n",
      "Iteration 465/2000\n",
      "Policy Loss: 0.0960, Value Loss: 0.0109\n",
      "Iteration 466/2000\n",
      "Policy Loss: 0.0442, Value Loss: 0.0001\n",
      "Iteration 467/2000\n",
      "Policy Loss: 0.0605, Value Loss: 0.0000\n",
      "Iteration 468/2000\n",
      "Policy Loss: 0.0749, Value Loss: 0.0001\n",
      "Iteration 469/2000\n",
      "Policy Loss: 0.0410, Value Loss: 0.0002\n",
      "Iteration 470/2000\n",
      "Policy Loss: 0.0153, Value Loss: 0.0009\n",
      "Iteration 471/2000\n",
      "Policy Loss: 0.1454, Value Loss: 0.0001\n",
      "Iteration 472/2000\n",
      "Policy Loss: 0.1098, Value Loss: 0.0000\n",
      "Iteration 473/2000\n",
      "Policy Loss: 0.2981, Value Loss: 0.0000\n",
      "Iteration 474/2000\n",
      "Policy Loss: 0.1277, Value Loss: 0.0003\n",
      "Iteration 475/2000\n",
      "Policy Loss: 0.1674, Value Loss: 0.0003\n",
      "Iteration 476/2000\n",
      "Policy Loss: 0.0113, Value Loss: 0.0019\n",
      "Iteration 477/2000\n",
      "Policy Loss: 0.2675, Value Loss: 0.0000\n",
      "Iteration 478/2000\n",
      "Policy Loss: 0.1962, Value Loss: 0.0004\n",
      "Iteration 479/2000\n",
      "Policy Loss: 0.2934, Value Loss: 0.0004\n",
      "Iteration 480/2000\n",
      "Policy Loss: 0.0182, Value Loss: 0.0007\n",
      "Iteration 481/2000\n",
      "Policy Loss: 0.0143, Value Loss: 0.0000\n",
      "Iteration 482/2000\n",
      "Policy Loss: 0.0236, Value Loss: 0.0001\n",
      "Iteration 483/2000\n",
      "Policy Loss: 0.0493, Value Loss: 0.0001\n",
      "Iteration 484/2000\n",
      "Policy Loss: 0.1453, Value Loss: 0.0000\n",
      "Iteration 485/2000\n",
      "Policy Loss: 0.1540, Value Loss: 0.0014\n",
      "Iteration 486/2000\n",
      "Policy Loss: 0.1243, Value Loss: 0.0005\n",
      "Iteration 487/2000\n",
      "Policy Loss: 0.0309, Value Loss: 0.0009\n",
      "Iteration 488/2000\n",
      "Policy Loss: 0.0495, Value Loss: 0.0004\n",
      "Iteration 489/2000\n",
      "Policy Loss: 0.0304, Value Loss: 0.0004\n",
      "Iteration 490/2000\n",
      "Policy Loss: 0.0231, Value Loss: 0.0002\n",
      "Iteration 491/2000\n",
      "Policy Loss: 0.1360, Value Loss: 0.0002\n",
      "Iteration 492/2000\n",
      "Policy Loss: 0.0298, Value Loss: 0.0002\n",
      "Iteration 493/2000\n",
      "Policy Loss: 0.1493, Value Loss: 0.0009\n",
      "Iteration 494/2000\n",
      "Policy Loss: 0.0324, Value Loss: 0.0000\n",
      "Iteration 495/2000\n",
      "Policy Loss: 0.0162, Value Loss: 0.0013\n",
      "Iteration 496/2000\n",
      "Policy Loss: 0.0286, Value Loss: 0.0005\n",
      "Iteration 497/2000\n",
      "Policy Loss: 0.0585, Value Loss: 0.0013\n",
      "Iteration 498/2000\n",
      "Policy Loss: 0.1892, Value Loss: 0.0001\n",
      "Iteration 499/2000\n",
      "Policy Loss: 0.0046, Value Loss: 0.0001\n",
      "Iteration 500/2000\n",
      "Policy Loss: 0.0808, Value Loss: 0.0000\n",
      "Iteration 501/2000\n",
      "Policy Loss: 0.1172, Value Loss: 0.0006\n",
      "Iteration 502/2000\n",
      "Policy Loss: 0.0241, Value Loss: 0.0000\n",
      "Iteration 503/2000\n",
      "Policy Loss: 0.0220, Value Loss: 0.0004\n",
      "Iteration 504/2000\n",
      "Policy Loss: 0.0293, Value Loss: 0.0000\n",
      "Iteration 505/2000\n",
      "Policy Loss: 0.0088, Value Loss: 0.0001\n",
      "Iteration 506/2000\n",
      "Policy Loss: 0.0065, Value Loss: 0.0001\n",
      "Iteration 507/2000\n",
      "Policy Loss: 0.6330, Value Loss: 0.0014\n",
      "Iteration 508/2000\n",
      "Policy Loss: 0.0066, Value Loss: 0.0000\n",
      "Iteration 509/2000\n",
      "Policy Loss: 0.3564, Value Loss: 0.0000\n",
      "Iteration 510/2000\n",
      "Policy Loss: 0.1062, Value Loss: 0.0003\n",
      "Iteration 511/2000\n",
      "Policy Loss: 0.0094, Value Loss: 0.0000\n",
      "Iteration 512/2000\n",
      "Policy Loss: 0.0493, Value Loss: 0.0000\n",
      "Iteration 513/2000\n",
      "Policy Loss: 0.2491, Value Loss: 0.0001\n",
      "Iteration 514/2000\n",
      "Policy Loss: 0.0288, Value Loss: 0.0002\n",
      "Iteration 515/2000\n",
      "Policy Loss: 0.0251, Value Loss: 0.0002\n",
      "Iteration 516/2000\n",
      "Policy Loss: 0.0475, Value Loss: 0.0000\n",
      "Iteration 517/2000\n",
      "Policy Loss: 0.4961, Value Loss: 0.0000\n",
      "Iteration 518/2000\n",
      "Policy Loss: 0.0139, Value Loss: 0.0003\n",
      "Iteration 519/2000\n",
      "Policy Loss: 0.0289, Value Loss: 0.0019\n",
      "Iteration 520/2000\n",
      "Policy Loss: 0.8896, Value Loss: 0.0002\n",
      "Iteration 521/2000\n",
      "Policy Loss: 0.1287, Value Loss: 0.0001\n",
      "Iteration 522/2000\n",
      "Policy Loss: 0.0752, Value Loss: 0.0002\n",
      "Iteration 523/2000\n",
      "Policy Loss: 0.0067, Value Loss: 0.0000\n",
      "Iteration 524/2000\n",
      "Policy Loss: 0.0603, Value Loss: 0.0000\n",
      "Iteration 525/2000\n",
      "Policy Loss: 0.1065, Value Loss: 0.0022\n",
      "Iteration 526/2000\n",
      "Policy Loss: 0.1005, Value Loss: 0.0003\n",
      "Iteration 527/2000\n",
      "Policy Loss: 0.0127, Value Loss: 0.0000\n",
      "Iteration 528/2000\n",
      "Policy Loss: 0.0087, Value Loss: 0.0114\n",
      "Iteration 529/2000\n",
      "Policy Loss: 0.0894, Value Loss: 0.0009\n",
      "Iteration 530/2000\n",
      "Policy Loss: 0.0824, Value Loss: 0.0014\n",
      "Iteration 531/2000\n",
      "Policy Loss: 0.1058, Value Loss: 0.0000\n",
      "Iteration 532/2000\n",
      "Policy Loss: 0.1251, Value Loss: 0.0176\n",
      "Iteration 533/2000\n",
      "Policy Loss: 0.1271, Value Loss: 0.0000\n",
      "Iteration 534/2000\n",
      "Policy Loss: 0.0412, Value Loss: 0.0010\n",
      "Iteration 535/2000\n",
      "Policy Loss: 0.0504, Value Loss: 0.0005\n",
      "Iteration 536/2000\n",
      "Policy Loss: 0.0071, Value Loss: 0.0002\n",
      "Iteration 537/2000\n",
      "Policy Loss: 0.1487, Value Loss: 0.0014\n",
      "Iteration 538/2000\n",
      "Policy Loss: 1.6406, Value Loss: 0.0015\n",
      "Iteration 539/2000\n",
      "Policy Loss: 0.0433, Value Loss: 0.0177\n",
      "Iteration 540/2000\n",
      "Policy Loss: 0.0135, Value Loss: 0.0013\n",
      "Iteration 541/2000\n",
      "Policy Loss: 0.1776, Value Loss: 0.0032\n",
      "Iteration 542/2000\n",
      "Policy Loss: 0.0265, Value Loss: 0.0020\n",
      "Iteration 543/2000\n",
      "Policy Loss: 1.7821, Value Loss: 0.0824\n",
      "Iteration 544/2000\n",
      "Policy Loss: 0.2331, Value Loss: 0.0007\n",
      "Iteration 545/2000\n",
      "Policy Loss: 0.0159, Value Loss: 0.0001\n",
      "Iteration 546/2000\n",
      "Policy Loss: 0.2441, Value Loss: 0.0003\n",
      "Iteration 547/2000\n",
      "Policy Loss: 0.1090, Value Loss: 0.0000\n",
      "Iteration 548/2000\n",
      "Policy Loss: 0.0739, Value Loss: 0.0015\n",
      "Iteration 549/2000\n",
      "Policy Loss: 0.0824, Value Loss: 0.0044\n",
      "Iteration 550/2000\n",
      "Policy Loss: 0.5386, Value Loss: 0.0100\n",
      "Iteration 551/2000\n",
      "Policy Loss: 0.1088, Value Loss: 0.0000\n",
      "Iteration 552/2000\n",
      "Policy Loss: 0.0618, Value Loss: 0.0004\n",
      "Iteration 553/2000\n",
      "Policy Loss: 0.1624, Value Loss: 0.0022\n",
      "Iteration 554/2000\n",
      "Policy Loss: 0.0885, Value Loss: 0.0091\n",
      "Iteration 555/2000\n",
      "Policy Loss: 0.0496, Value Loss: 0.0108\n",
      "Iteration 556/2000\n",
      "Policy Loss: 0.0576, Value Loss: 0.0014\n",
      "Iteration 557/2000\n",
      "Policy Loss: 0.2088, Value Loss: 0.0003\n",
      "Iteration 558/2000\n",
      "Policy Loss: 0.0319, Value Loss: 0.0001\n",
      "Iteration 559/2000\n",
      "Policy Loss: 0.3790, Value Loss: 0.0316\n",
      "Iteration 560/2000\n",
      "Policy Loss: 0.0140, Value Loss: 0.0009\n",
      "Iteration 561/2000\n",
      "Policy Loss: 0.0155, Value Loss: 0.0155\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 562/2000\n",
      "Policy Loss: 0.1492, Value Loss: 0.0001\n",
      "Iteration 563/2000\n",
      "Policy Loss: 0.0270, Value Loss: 0.0000\n",
      "Iteration 564/2000\n",
      "Policy Loss: 0.2505, Value Loss: 0.0002\n",
      "Iteration 565/2000\n",
      "Policy Loss: 0.1116, Value Loss: 0.0008\n",
      "Iteration 566/2000\n",
      "Policy Loss: 0.0600, Value Loss: 0.0027\n",
      "Iteration 567/2000\n",
      "Policy Loss: 0.0832, Value Loss: 0.0000\n",
      "Iteration 568/2000\n",
      "Policy Loss: 0.0545, Value Loss: 0.0020\n",
      "Iteration 569/2000\n",
      "Policy Loss: 0.0764, Value Loss: 0.0009\n",
      "Iteration 570/2000\n",
      "Policy Loss: 0.1019, Value Loss: 0.0007\n",
      "Iteration 571/2000\n",
      "Policy Loss: 0.1237, Value Loss: 0.0003\n",
      "Iteration 572/2000\n",
      "Policy Loss: 0.0156, Value Loss: 0.0005\n",
      "Iteration 573/2000\n",
      "Policy Loss: 0.1740, Value Loss: 0.0136\n",
      "Iteration 574/2000\n",
      "Policy Loss: 0.1509, Value Loss: 0.0000\n",
      "Iteration 575/2000\n",
      "Policy Loss: 0.0069, Value Loss: 0.0003\n",
      "Iteration 576/2000\n",
      "Policy Loss: 0.0080, Value Loss: 0.0095\n",
      "Iteration 577/2000\n",
      "Policy Loss: 0.0408, Value Loss: 0.0003\n",
      "Iteration 578/2000\n",
      "Policy Loss: 0.0164, Value Loss: 0.0015\n",
      "Iteration 579/2000\n",
      "Policy Loss: 0.0154, Value Loss: 0.0000\n",
      "Iteration 580/2000\n",
      "Policy Loss: 0.0051, Value Loss: 0.0021\n",
      "Iteration 581/2000\n",
      "Policy Loss: 0.1566, Value Loss: 0.0009\n",
      "Iteration 582/2000\n",
      "Policy Loss: 0.0048, Value Loss: 0.0098\n",
      "Iteration 583/2000\n",
      "Policy Loss: 0.0089, Value Loss: 0.0011\n",
      "Iteration 584/2000\n",
      "Policy Loss: 0.1224, Value Loss: 0.0000\n",
      "Iteration 585/2000\n",
      "Policy Loss: 0.0957, Value Loss: 0.0002\n",
      "Iteration 586/2000\n",
      "Policy Loss: 0.0057, Value Loss: 0.0000\n",
      "Iteration 587/2000\n",
      "Policy Loss: 0.1011, Value Loss: 0.0001\n",
      "Iteration 588/2000\n",
      "Policy Loss: 0.0367, Value Loss: 0.0000\n",
      "Iteration 589/2000\n",
      "Policy Loss: 0.0054, Value Loss: 0.0000\n",
      "Iteration 590/2000\n",
      "Policy Loss: 0.0158, Value Loss: 0.0158\n",
      "Iteration 591/2000\n",
      "Policy Loss: 0.4162, Value Loss: 0.0002\n",
      "Iteration 592/2000\n",
      "Policy Loss: 0.4979, Value Loss: 0.0000\n",
      "Iteration 593/2000\n",
      "Policy Loss: 0.0021, Value Loss: 0.0000\n",
      "Iteration 594/2000\n",
      "Policy Loss: 0.0349, Value Loss: 0.0090\n",
      "Iteration 595/2000\n",
      "Policy Loss: 0.0096, Value Loss: 0.0000\n",
      "Iteration 596/2000\n",
      "Policy Loss: 0.3931, Value Loss: 0.0001\n",
      "Iteration 597/2000\n",
      "Policy Loss: 0.0271, Value Loss: 0.0010\n",
      "Iteration 598/2000\n",
      "Policy Loss: 0.0354, Value Loss: 0.0062\n",
      "Iteration 599/2000\n",
      "Policy Loss: 0.1040, Value Loss: 0.0000\n",
      "Iteration 600/2000\n",
      "Policy Loss: 0.0554, Value Loss: 0.0006\n",
      "Iteration 601/2000\n",
      "Policy Loss: 0.1088, Value Loss: 0.0009\n",
      "Iteration 602/2000\n",
      "Policy Loss: 0.0083, Value Loss: 0.0068\n",
      "Iteration 603/2000\n",
      "Policy Loss: 0.0040, Value Loss: 0.0003\n",
      "Iteration 604/2000\n",
      "Policy Loss: 0.0052, Value Loss: 0.0000\n",
      "Iteration 605/2000\n",
      "Policy Loss: 0.0195, Value Loss: 0.0001\n",
      "Iteration 606/2000\n",
      "Policy Loss: 0.0749, Value Loss: 0.0000\n",
      "Iteration 607/2000\n",
      "Policy Loss: 0.0104, Value Loss: 0.0003\n",
      "Iteration 608/2000\n",
      "Policy Loss: 0.0195, Value Loss: 0.0000\n",
      "Iteration 609/2000\n",
      "Policy Loss: 0.0173, Value Loss: 0.0006\n",
      "Iteration 610/2000\n",
      "Policy Loss: 0.0265, Value Loss: 0.0003\n",
      "Iteration 611/2000\n",
      "Policy Loss: 0.0066, Value Loss: 0.0023\n",
      "Iteration 612/2000\n",
      "Policy Loss: 0.2652, Value Loss: 0.0000\n",
      "Iteration 613/2000\n",
      "Policy Loss: 0.0497, Value Loss: 0.0001\n",
      "Iteration 614/2000\n",
      "Policy Loss: 0.3122, Value Loss: 0.0002\n",
      "Iteration 615/2000\n",
      "Policy Loss: 0.0024, Value Loss: 0.0004\n",
      "Iteration 616/2000\n",
      "Policy Loss: 0.1558, Value Loss: 0.0001\n",
      "Iteration 617/2000\n",
      "Policy Loss: 0.0412, Value Loss: 0.0001\n",
      "Iteration 618/2000\n",
      "Policy Loss: 0.0496, Value Loss: 0.0017\n",
      "Iteration 619/2000\n",
      "Policy Loss: 0.0062, Value Loss: 0.0000\n",
      "Iteration 620/2000\n",
      "Policy Loss: 0.0102, Value Loss: 0.0014\n",
      "Iteration 621/2000\n",
      "Policy Loss: 0.3943, Value Loss: 0.0012\n",
      "Iteration 622/2000\n",
      "Policy Loss: 0.1888, Value Loss: 0.0002\n",
      "Iteration 623/2000\n",
      "Policy Loss: 0.0066, Value Loss: 0.0004\n",
      "Iteration 624/2000\n",
      "Policy Loss: 0.1109, Value Loss: 0.0002\n",
      "Iteration 625/2000\n",
      "Policy Loss: 0.0041, Value Loss: 0.0000\n",
      "Iteration 626/2000\n",
      "Policy Loss: 0.0785, Value Loss: 0.0000\n",
      "Iteration 627/2000\n",
      "Policy Loss: 0.0978, Value Loss: 0.0000\n",
      "Iteration 628/2000\n",
      "Policy Loss: 0.0049, Value Loss: 0.0014\n",
      "Iteration 629/2000\n",
      "Policy Loss: 0.0079, Value Loss: 0.0035\n",
      "Iteration 630/2000\n",
      "Policy Loss: 0.2789, Value Loss: 0.0021\n",
      "Iteration 631/2000\n",
      "Policy Loss: 0.2042, Value Loss: 0.0000\n",
      "Iteration 632/2000\n",
      "Policy Loss: 0.0025, Value Loss: 0.0004\n",
      "Iteration 633/2000\n",
      "Policy Loss: 0.1489, Value Loss: 0.0000\n",
      "Iteration 634/2000\n",
      "Policy Loss: 0.1046, Value Loss: 0.0001\n",
      "Iteration 635/2000\n",
      "Policy Loss: 0.0404, Value Loss: 0.0000\n",
      "Iteration 636/2000\n",
      "Policy Loss: 0.0918, Value Loss: 0.0000\n",
      "Iteration 637/2000\n",
      "Policy Loss: 0.0008, Value Loss: 0.0016\n",
      "Iteration 638/2000\n",
      "Policy Loss: 0.2101, Value Loss: 0.0000\n",
      "Iteration 639/2000\n",
      "Policy Loss: 0.0240, Value Loss: 0.0000\n",
      "Iteration 640/2000\n",
      "Policy Loss: 0.2097, Value Loss: 0.0005\n",
      "Iteration 641/2000\n",
      "Policy Loss: 0.0093, Value Loss: 0.0017\n",
      "Iteration 642/2000\n",
      "Policy Loss: 0.0085, Value Loss: 0.0003\n",
      "Iteration 643/2000\n",
      "Policy Loss: 0.0028, Value Loss: 0.0000\n",
      "Iteration 644/2000\n",
      "Policy Loss: 0.1048, Value Loss: 0.0000\n",
      "Iteration 645/2000\n",
      "Policy Loss: 0.0031, Value Loss: 0.0001\n",
      "Iteration 646/2000\n",
      "Policy Loss: 0.0864, Value Loss: 0.0000\n",
      "Iteration 647/2000\n",
      "Policy Loss: 0.0035, Value Loss: 0.0012\n",
      "Iteration 648/2000\n",
      "Policy Loss: 0.0565, Value Loss: 0.0010\n",
      "Iteration 649/2000\n",
      "Policy Loss: 0.0518, Value Loss: 0.0000\n",
      "Iteration 650/2000\n",
      "Policy Loss: 0.0056, Value Loss: 0.0001\n",
      "Iteration 651/2000\n",
      "Policy Loss: 0.0071, Value Loss: 0.0001\n",
      "Iteration 652/2000\n",
      "Policy Loss: 0.0194, Value Loss: 0.0001\n",
      "Iteration 653/2000\n",
      "Policy Loss: 0.0040, Value Loss: 0.0000\n",
      "Iteration 654/2000\n",
      "Policy Loss: 0.0263, Value Loss: 0.0000\n",
      "Iteration 655/2000\n",
      "Policy Loss: 0.0216, Value Loss: 0.0002\n",
      "Iteration 656/2000\n",
      "Policy Loss: 0.0194, Value Loss: 0.0000\n",
      "Iteration 657/2000\n",
      "Policy Loss: 0.0123, Value Loss: 0.0010\n",
      "Iteration 658/2000\n",
      "Policy Loss: 0.2630, Value Loss: 0.0000\n",
      "Iteration 659/2000\n",
      "Policy Loss: 0.0160, Value Loss: 0.0000\n",
      "Iteration 660/2000\n",
      "Policy Loss: 0.0022, Value Loss: 0.0001\n",
      "Iteration 661/2000\n",
      "Policy Loss: 0.0073, Value Loss: 0.0001\n",
      "Iteration 662/2000\n",
      "Policy Loss: 0.0092, Value Loss: 0.0001\n",
      "Iteration 663/2000\n",
      "Policy Loss: 0.0058, Value Loss: 0.0006\n",
      "Iteration 664/2000\n",
      "Policy Loss: 0.2331, Value Loss: 0.0002\n",
      "Iteration 665/2000\n",
      "Policy Loss: 0.2018, Value Loss: 0.0002\n",
      "Iteration 666/2000\n",
      "Policy Loss: 0.0548, Value Loss: 0.0021\n",
      "Iteration 667/2000\n",
      "Policy Loss: 0.0289, Value Loss: 0.0007\n",
      "Iteration 668/2000\n",
      "Policy Loss: 0.0986, Value Loss: 0.0000\n",
      "Iteration 669/2000\n",
      "Policy Loss: 0.0059, Value Loss: 0.0000\n",
      "Iteration 670/2000\n",
      "Policy Loss: 0.0030, Value Loss: 0.0003\n",
      "Iteration 671/2000\n",
      "Policy Loss: 0.0040, Value Loss: 0.0017\n",
      "Iteration 672/2000\n",
      "Policy Loss: 0.0576, Value Loss: 0.0003\n",
      "Iteration 673/2000\n",
      "Policy Loss: 0.0025, Value Loss: 0.0003\n",
      "Iteration 674/2000\n",
      "Policy Loss: 0.0513, Value Loss: 0.0010\n",
      "Iteration 675/2000\n",
      "Policy Loss: 0.1433, Value Loss: 0.0000\n",
      "Iteration 676/2000\n",
      "Policy Loss: 0.0406, Value Loss: 0.0000\n",
      "Iteration 677/2000\n",
      "Policy Loss: 0.0270, Value Loss: 0.0000\n",
      "Iteration 678/2000\n",
      "Policy Loss: 0.0976, Value Loss: 0.0095\n",
      "Iteration 679/2000\n",
      "Policy Loss: 0.0215, Value Loss: 0.0000\n",
      "Iteration 680/2000\n",
      "Policy Loss: 0.0168, Value Loss: 0.0000\n",
      "Iteration 681/2000\n",
      "Policy Loss: 0.0240, Value Loss: 0.0005\n",
      "Iteration 682/2000\n",
      "Policy Loss: 0.0101, Value Loss: 0.0003\n",
      "Iteration 683/2000\n",
      "Policy Loss: 0.0141, Value Loss: 0.0001\n",
      "Iteration 684/2000\n",
      "Policy Loss: 0.0431, Value Loss: 0.0009\n",
      "Iteration 685/2000\n",
      "Policy Loss: 0.0498, Value Loss: 0.0000\n",
      "Iteration 686/2000\n",
      "Policy Loss: 0.0199, Value Loss: 0.0000\n",
      "Iteration 687/2000\n",
      "Policy Loss: 0.0184, Value Loss: 0.0000\n",
      "Iteration 688/2000\n",
      "Policy Loss: 0.0083, Value Loss: 0.0000\n",
      "Iteration 689/2000\n",
      "Policy Loss: 0.0052, Value Loss: 0.0019\n",
      "Iteration 690/2000\n",
      "Policy Loss: 0.0135, Value Loss: 0.0000\n",
      "Iteration 691/2000\n",
      "Policy Loss: 0.2291, Value Loss: 0.0016\n",
      "Iteration 692/2000\n",
      "Policy Loss: 0.0199, Value Loss: 0.0000\n",
      "Iteration 693/2000\n",
      "Policy Loss: 0.0063, Value Loss: 0.0005\n",
      "Iteration 694/2000\n",
      "Policy Loss: 0.1305, Value Loss: 0.0002\n",
      "Iteration 695/2000\n",
      "Policy Loss: 0.1882, Value Loss: 0.0000\n",
      "Iteration 696/2000\n",
      "Policy Loss: 0.0387, Value Loss: 0.0000\n",
      "Iteration 697/2000\n",
      "Policy Loss: 0.0147, Value Loss: 0.0173\n",
      "Iteration 698/2000\n",
      "Policy Loss: 0.0256, Value Loss: 0.0000\n",
      "Iteration 699/2000\n",
      "Policy Loss: 0.5223, Value Loss: 0.0002\n",
      "Iteration 700/2000\n",
      "Policy Loss: 0.6490, Value Loss: 0.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 701/2000\n",
      "Policy Loss: 0.0009, Value Loss: 0.0008\n",
      "Iteration 702/2000\n",
      "Policy Loss: 0.0023, Value Loss: 0.0001\n",
      "Iteration 703/2000\n",
      "Policy Loss: 0.0075, Value Loss: 0.0000\n",
      "Iteration 704/2000\n",
      "Policy Loss: 0.7079, Value Loss: 0.0000\n",
      "Iteration 705/2000\n",
      "Policy Loss: 0.0618, Value Loss: 0.0020\n",
      "Iteration 706/2000\n",
      "Policy Loss: 0.4196, Value Loss: 0.0022\n",
      "Iteration 707/2000\n",
      "Policy Loss: 0.0307, Value Loss: 0.0010\n",
      "Iteration 708/2000\n",
      "Policy Loss: 0.1791, Value Loss: 0.0000\n",
      "Iteration 709/2000\n",
      "Policy Loss: 0.0268, Value Loss: 0.0001\n",
      "Iteration 710/2000\n",
      "Policy Loss: 0.4023, Value Loss: 0.0000\n",
      "Iteration 711/2000\n",
      "Policy Loss: 0.0324, Value Loss: 0.0000\n",
      "Iteration 712/2000\n",
      "Policy Loss: 0.0332, Value Loss: 0.0010\n",
      "Iteration 713/2000\n",
      "Policy Loss: 0.0913, Value Loss: 0.0000\n",
      "Iteration 714/2000\n",
      "Policy Loss: 0.0330, Value Loss: 0.0001\n",
      "Iteration 715/2000\n",
      "Policy Loss: 0.3064, Value Loss: 0.0001\n",
      "Iteration 716/2000\n",
      "Policy Loss: 0.2972, Value Loss: 0.0000\n",
      "Iteration 717/2000\n",
      "Policy Loss: 0.0984, Value Loss: 0.0000\n",
      "Iteration 718/2000\n",
      "Policy Loss: 0.0267, Value Loss: 0.0007\n",
      "Iteration 719/2000\n",
      "Policy Loss: 0.1623, Value Loss: 0.0004\n",
      "Iteration 720/2000\n",
      "Policy Loss: 0.0387, Value Loss: 0.0016\n",
      "Iteration 721/2000\n",
      "Policy Loss: 0.0083, Value Loss: 0.0000\n",
      "Iteration 722/2000\n",
      "Policy Loss: 0.0495, Value Loss: 0.0000\n",
      "Iteration 723/2000\n",
      "Policy Loss: 0.0933, Value Loss: 0.0000\n",
      "Iteration 724/2000\n",
      "Policy Loss: 0.1057, Value Loss: 0.0000\n",
      "Iteration 725/2000\n",
      "Policy Loss: 0.0773, Value Loss: 0.0003\n",
      "Iteration 726/2000\n",
      "Policy Loss: 0.4182, Value Loss: 0.0000\n",
      "Iteration 727/2000\n",
      "Policy Loss: 0.0564, Value Loss: 0.0000\n",
      "Iteration 728/2000\n",
      "Policy Loss: 0.0583, Value Loss: 0.0018\n",
      "Iteration 729/2000\n",
      "Policy Loss: 0.0188, Value Loss: 0.0005\n",
      "Iteration 730/2000\n",
      "Policy Loss: 0.9598, Value Loss: 0.0000\n",
      "Iteration 731/2000\n",
      "Policy Loss: 0.0481, Value Loss: 0.0035\n",
      "Iteration 732/2000\n",
      "Policy Loss: 0.0956, Value Loss: 0.0008\n",
      "Iteration 733/2000\n",
      "Policy Loss: 0.2268, Value Loss: 0.0020\n",
      "Iteration 734/2000\n",
      "Policy Loss: 0.1059, Value Loss: 0.0025\n",
      "Iteration 735/2000\n",
      "Policy Loss: 0.1111, Value Loss: 0.0001\n",
      "Iteration 736/2000\n",
      "Policy Loss: 0.0547, Value Loss: 0.0001\n",
      "Iteration 737/2000\n",
      "Policy Loss: 0.0240, Value Loss: 0.0015\n",
      "Iteration 738/2000\n",
      "Policy Loss: 0.0507, Value Loss: 0.0002\n",
      "Iteration 739/2000\n",
      "Policy Loss: 0.0324, Value Loss: 0.0003\n",
      "Iteration 740/2000\n",
      "Policy Loss: 0.1363, Value Loss: 0.0013\n",
      "Iteration 741/2000\n",
      "Policy Loss: 0.1470, Value Loss: 0.0003\n",
      "Iteration 742/2000\n",
      "Policy Loss: 0.0145, Value Loss: 0.0000\n",
      "Iteration 743/2000\n",
      "Policy Loss: 0.0331, Value Loss: 0.0005\n",
      "Iteration 744/2000\n",
      "Policy Loss: 0.0124, Value Loss: 0.0009\n",
      "Iteration 745/2000\n",
      "Policy Loss: 0.0524, Value Loss: 0.0000\n",
      "Iteration 746/2000\n",
      "Policy Loss: 0.1222, Value Loss: 0.0004\n",
      "Iteration 747/2000\n",
      "Policy Loss: 0.4958, Value Loss: 0.0000\n",
      "Iteration 748/2000\n",
      "Policy Loss: 0.3920, Value Loss: 0.0001\n",
      "Iteration 749/2000\n",
      "Policy Loss: 0.1507, Value Loss: 0.0000\n",
      "Iteration 750/2000\n",
      "Policy Loss: 0.1980, Value Loss: 0.0001\n",
      "Iteration 751/2000\n",
      "Policy Loss: 0.0041, Value Loss: 0.0001\n",
      "Iteration 752/2000\n",
      "Policy Loss: 0.0108, Value Loss: 0.0000\n",
      "Iteration 753/2000\n",
      "Policy Loss: 0.1077, Value Loss: 0.0006\n",
      "Iteration 754/2000\n",
      "Policy Loss: 0.0667, Value Loss: 0.0003\n",
      "Iteration 755/2000\n",
      "Policy Loss: 0.1437, Value Loss: 0.0002\n",
      "Iteration 756/2000\n",
      "Policy Loss: 0.1864, Value Loss: 0.0000\n",
      "Iteration 757/2000\n",
      "Policy Loss: 0.0647, Value Loss: 0.0000\n",
      "Iteration 758/2000\n",
      "Policy Loss: 0.0124, Value Loss: 0.0017\n",
      "Iteration 759/2000\n",
      "Policy Loss: 0.2784, Value Loss: 0.0000\n",
      "Iteration 760/2000\n",
      "Policy Loss: 0.0143, Value Loss: 0.0006\n",
      "Iteration 761/2000\n",
      "Policy Loss: 0.6491, Value Loss: 0.0000\n",
      "Iteration 762/2000\n",
      "Policy Loss: 0.2700, Value Loss: 0.0015\n",
      "Iteration 763/2000\n",
      "Policy Loss: 0.2602, Value Loss: 0.0000\n",
      "Iteration 764/2000\n",
      "Policy Loss: 0.1765, Value Loss: 0.0001\n",
      "Iteration 765/2000\n",
      "Policy Loss: 0.0457, Value Loss: 0.0006\n",
      "Iteration 766/2000\n",
      "Policy Loss: 0.2219, Value Loss: 0.0000\n",
      "Iteration 767/2000\n",
      "Policy Loss: 0.1376, Value Loss: 0.0018\n",
      "Iteration 768/2000\n",
      "Policy Loss: 0.0518, Value Loss: 0.0000\n",
      "Iteration 769/2000\n",
      "Policy Loss: 0.1295, Value Loss: 0.0011\n",
      "Iteration 770/2000\n",
      "Policy Loss: 0.0187, Value Loss: 0.0000\n",
      "Iteration 771/2000\n",
      "Policy Loss: 0.0198, Value Loss: 0.0030\n",
      "Iteration 772/2000\n",
      "Policy Loss: 0.0158, Value Loss: 0.0003\n",
      "Iteration 773/2000\n",
      "Policy Loss: 0.1917, Value Loss: 0.0042\n",
      "Iteration 774/2000\n",
      "Policy Loss: 0.1891, Value Loss: 0.0000\n",
      "Iteration 775/2000\n",
      "Policy Loss: 0.0538, Value Loss: 0.0005\n",
      "Iteration 776/2000\n",
      "Policy Loss: 0.0127, Value Loss: 0.0011\n",
      "Iteration 777/2000\n",
      "Policy Loss: 0.2414, Value Loss: 0.0000\n",
      "Iteration 778/2000\n",
      "Policy Loss: 0.3478, Value Loss: 0.0006\n",
      "Iteration 779/2000\n",
      "Policy Loss: 0.3646, Value Loss: 0.0000\n",
      "Iteration 780/2000\n",
      "Policy Loss: 0.2446, Value Loss: 0.0000\n",
      "Iteration 781/2000\n",
      "Policy Loss: 0.0957, Value Loss: 0.0004\n",
      "Iteration 782/2000\n",
      "Policy Loss: 0.1780, Value Loss: 0.0001\n",
      "Iteration 783/2000\n",
      "Policy Loss: 0.1704, Value Loss: 0.0000\n",
      "Iteration 784/2000\n",
      "Policy Loss: 0.3263, Value Loss: 0.0000\n",
      "Iteration 785/2000\n",
      "Policy Loss: 0.1466, Value Loss: 0.0000\n",
      "Iteration 786/2000\n",
      "Policy Loss: 0.0985, Value Loss: 0.0000\n",
      "Iteration 787/2000\n",
      "Policy Loss: 0.0828, Value Loss: 0.0001\n",
      "Iteration 788/2000\n",
      "Policy Loss: 0.2140, Value Loss: 0.0000\n",
      "Iteration 789/2000\n",
      "Policy Loss: 0.1614, Value Loss: 0.0002\n",
      "Iteration 790/2000\n",
      "Policy Loss: 0.1215, Value Loss: 0.0166\n",
      "Iteration 791/2000\n",
      "Policy Loss: 0.1341, Value Loss: 0.0003\n",
      "Iteration 792/2000\n",
      "Policy Loss: 0.0849, Value Loss: 0.0000\n",
      "Iteration 793/2000\n",
      "Policy Loss: 0.1356, Value Loss: 0.0008\n",
      "Iteration 794/2000\n",
      "Policy Loss: 0.0672, Value Loss: 0.0006\n",
      "Iteration 795/2000\n",
      "Policy Loss: 0.0719, Value Loss: 0.0004\n",
      "Iteration 796/2000\n",
      "Policy Loss: 0.0623, Value Loss: 0.0006\n",
      "Iteration 797/2000\n",
      "Policy Loss: 0.0182, Value Loss: 0.0000\n",
      "Iteration 798/2000\n",
      "Policy Loss: 0.0865, Value Loss: 0.0001\n",
      "Iteration 799/2000\n",
      "Policy Loss: 0.0684, Value Loss: 0.0000\n",
      "Iteration 800/2000\n",
      "Policy Loss: 0.0427, Value Loss: 0.0033\n",
      "Iteration 801/2000\n",
      "Policy Loss: 0.0245, Value Loss: 0.0000\n",
      "Iteration 802/2000\n",
      "Policy Loss: 0.3463, Value Loss: 0.0001\n",
      "Iteration 803/2000\n",
      "Policy Loss: 0.2364, Value Loss: 0.0001\n",
      "Iteration 804/2000\n",
      "Policy Loss: 0.1919, Value Loss: 0.0017\n",
      "Iteration 805/2000\n",
      "Policy Loss: 0.1606, Value Loss: 0.0002\n",
      "Iteration 806/2000\n",
      "Policy Loss: 0.0224, Value Loss: 0.0027\n",
      "Iteration 807/2000\n",
      "Policy Loss: 0.0612, Value Loss: 0.0001\n",
      "Iteration 808/2000\n",
      "Policy Loss: 0.1894, Value Loss: 0.0001\n",
      "Iteration 809/2000\n",
      "Policy Loss: 0.1958, Value Loss: 0.0004\n",
      "Iteration 810/2000\n",
      "Policy Loss: 0.0768, Value Loss: 0.0031\n",
      "Iteration 811/2000\n",
      "Policy Loss: 0.2203, Value Loss: 0.0006\n",
      "Iteration 812/2000\n",
      "Policy Loss: 0.0800, Value Loss: 0.0000\n",
      "Iteration 813/2000\n",
      "Policy Loss: 0.0039, Value Loss: 0.0002\n",
      "Iteration 814/2000\n",
      "Policy Loss: 0.0040, Value Loss: 0.0001\n",
      "Iteration 815/2000\n",
      "Policy Loss: 0.6756, Value Loss: 0.0027\n",
      "Iteration 816/2000\n",
      "Policy Loss: 0.0458, Value Loss: 0.0001\n",
      "Iteration 817/2000\n",
      "Policy Loss: 0.2136, Value Loss: 0.0000\n",
      "Iteration 818/2000\n",
      "Policy Loss: 0.1011, Value Loss: 0.0000\n",
      "Iteration 819/2000\n",
      "Policy Loss: 0.0416, Value Loss: 0.0004\n",
      "Iteration 820/2000\n",
      "Policy Loss: 0.0046, Value Loss: 0.0007\n",
      "Iteration 821/2000\n",
      "Policy Loss: 0.1117, Value Loss: 0.0001\n",
      "Iteration 822/2000\n",
      "Policy Loss: 0.1543, Value Loss: 0.0000\n",
      "Iteration 823/2000\n",
      "Policy Loss: 0.0088, Value Loss: 0.0006\n",
      "Iteration 824/2000\n",
      "Policy Loss: 0.0896, Value Loss: 0.0001\n",
      "Iteration 825/2000\n",
      "Policy Loss: 0.0580, Value Loss: 0.0005\n",
      "Iteration 826/2000\n",
      "Policy Loss: 0.0812, Value Loss: 0.0006\n",
      "Iteration 827/2000\n",
      "Policy Loss: 0.0478, Value Loss: 0.0000\n",
      "Iteration 828/2000\n",
      "Policy Loss: 0.0154, Value Loss: 0.0001\n",
      "Iteration 829/2000\n",
      "Policy Loss: 0.2060, Value Loss: 0.0022\n",
      "Iteration 830/2000\n",
      "Policy Loss: 0.2171, Value Loss: 0.0000\n",
      "Iteration 831/2000\n",
      "Policy Loss: 0.0957, Value Loss: 0.0001\n",
      "Iteration 832/2000\n",
      "Policy Loss: 0.6709, Value Loss: 0.0001\n",
      "Iteration 833/2000\n",
      "Policy Loss: 0.1620, Value Loss: 0.0000\n",
      "Iteration 834/2000\n",
      "Policy Loss: 0.0367, Value Loss: 0.0002\n",
      "Iteration 835/2000\n",
      "Policy Loss: 0.1212, Value Loss: 0.0000\n",
      "Iteration 836/2000\n",
      "Policy Loss: 0.1745, Value Loss: 0.0004\n",
      "Iteration 837/2000\n",
      "Policy Loss: 0.2116, Value Loss: 0.0001\n",
      "Iteration 838/2000\n",
      "Policy Loss: 0.2361, Value Loss: 0.0000\n",
      "Iteration 839/2000\n",
      "Policy Loss: 0.0213, Value Loss: 0.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 840/2000\n",
      "Policy Loss: 0.1005, Value Loss: 0.0000\n",
      "Iteration 841/2000\n",
      "Policy Loss: 0.3942, Value Loss: 0.0000\n",
      "Iteration 842/2000\n",
      "Policy Loss: 0.0178, Value Loss: 0.0012\n",
      "Iteration 843/2000\n",
      "Policy Loss: 0.0397, Value Loss: 0.0000\n",
      "Iteration 844/2000\n",
      "Policy Loss: 0.0133, Value Loss: 0.0002\n",
      "Iteration 845/2000\n",
      "Policy Loss: 0.0882, Value Loss: 0.0000\n",
      "Iteration 846/2000\n",
      "Policy Loss: 0.2113, Value Loss: 0.0003\n",
      "Iteration 847/2000\n",
      "Policy Loss: 0.2101, Value Loss: 0.0000\n",
      "Iteration 848/2000\n",
      "Policy Loss: 0.0096, Value Loss: 0.0020\n",
      "Iteration 849/2000\n",
      "Policy Loss: 0.0927, Value Loss: 0.0021\n",
      "Iteration 850/2000\n",
      "Policy Loss: 0.0138, Value Loss: 0.0000\n",
      "Iteration 851/2000\n",
      "Policy Loss: 0.1811, Value Loss: 0.0007\n",
      "Iteration 852/2000\n",
      "Policy Loss: 0.1695, Value Loss: 0.0002\n",
      "Iteration 853/2000\n",
      "Policy Loss: 0.0936, Value Loss: 0.0000\n",
      "Iteration 854/2000\n",
      "Policy Loss: 0.3585, Value Loss: 0.0000\n",
      "Iteration 855/2000\n",
      "Policy Loss: 0.1484, Value Loss: 0.0001\n",
      "Iteration 856/2000\n",
      "Policy Loss: 0.0313, Value Loss: 0.0003\n",
      "Iteration 857/2000\n",
      "Policy Loss: 0.1223, Value Loss: 0.0070\n",
      "Iteration 858/2000\n",
      "Policy Loss: 0.0216, Value Loss: 0.0000\n",
      "Iteration 859/2000\n",
      "Policy Loss: 0.0196, Value Loss: 0.0000\n",
      "Iteration 860/2000\n",
      "Policy Loss: 0.2708, Value Loss: 0.0038\n",
      "Iteration 861/2000\n",
      "Policy Loss: 0.0559, Value Loss: 0.0000\n",
      "Iteration 862/2000\n",
      "Policy Loss: 0.0690, Value Loss: 0.0000\n",
      "Iteration 863/2000\n",
      "Policy Loss: 0.0346, Value Loss: 0.0001\n",
      "Iteration 864/2000\n",
      "Policy Loss: 0.1840, Value Loss: 0.0002\n",
      "Iteration 865/2000\n",
      "Policy Loss: 0.0916, Value Loss: 0.0013\n",
      "Iteration 866/2000\n",
      "Policy Loss: 0.0682, Value Loss: 0.0003\n",
      "Iteration 867/2000\n",
      "Policy Loss: 0.0182, Value Loss: 0.0002\n",
      "Iteration 868/2000\n",
      "Policy Loss: 0.1123, Value Loss: 0.0000\n",
      "Iteration 869/2000\n",
      "Policy Loss: 0.0044, Value Loss: 0.0000\n",
      "Iteration 870/2000\n",
      "Policy Loss: 0.1677, Value Loss: 0.0001\n",
      "Iteration 871/2000\n",
      "Policy Loss: 0.0255, Value Loss: 0.0000\n",
      "Iteration 872/2000\n",
      "Policy Loss: 0.0229, Value Loss: 0.0000\n",
      "Iteration 873/2000\n",
      "Policy Loss: 0.0314, Value Loss: 0.0000\n",
      "Iteration 874/2000\n",
      "Policy Loss: 0.0190, Value Loss: 0.0011\n",
      "Iteration 875/2000\n",
      "Policy Loss: 0.1095, Value Loss: 0.0046\n",
      "Iteration 876/2000\n",
      "Policy Loss: 0.0932, Value Loss: 0.0000\n",
      "Iteration 877/2000\n",
      "Policy Loss: 0.0484, Value Loss: 0.0000\n",
      "Iteration 878/2000\n",
      "Policy Loss: 0.0412, Value Loss: 0.0003\n",
      "Iteration 879/2000\n",
      "Policy Loss: 0.0175, Value Loss: 0.0002\n",
      "Iteration 880/2000\n",
      "Policy Loss: 0.0256, Value Loss: 0.0000\n",
      "Iteration 881/2000\n",
      "Policy Loss: 0.3696, Value Loss: 0.0000\n",
      "Iteration 882/2000\n",
      "Policy Loss: 0.1644, Value Loss: 0.0002\n",
      "Iteration 883/2000\n",
      "Policy Loss: 0.0192, Value Loss: 0.0000\n",
      "Iteration 884/2000\n",
      "Policy Loss: 0.1218, Value Loss: 0.0001\n",
      "Iteration 885/2000\n",
      "Policy Loss: 0.0095, Value Loss: 0.0000\n",
      "Iteration 886/2000\n",
      "Policy Loss: 0.0375, Value Loss: 0.0000\n",
      "Iteration 887/2000\n",
      "Policy Loss: 0.1377, Value Loss: 0.0000\n",
      "Iteration 888/2000\n",
      "Policy Loss: 0.1496, Value Loss: 0.0000\n",
      "Iteration 889/2000\n",
      "Policy Loss: 0.0373, Value Loss: 0.0025\n",
      "Iteration 890/2000\n",
      "Policy Loss: 0.0910, Value Loss: 0.0001\n",
      "Iteration 891/2000\n",
      "Policy Loss: 0.0400, Value Loss: 0.0006\n",
      "Iteration 892/2000\n",
      "Policy Loss: 0.0064, Value Loss: 0.0002\n",
      "Iteration 893/2000\n",
      "Policy Loss: 0.0040, Value Loss: 0.0000\n",
      "Iteration 894/2000\n",
      "Policy Loss: 0.1279, Value Loss: 0.0000\n",
      "Iteration 895/2000\n",
      "Policy Loss: 0.5374, Value Loss: 0.0000\n",
      "Iteration 896/2000\n",
      "Policy Loss: 0.1395, Value Loss: 0.0001\n",
      "Iteration 897/2000\n",
      "Policy Loss: 0.1249, Value Loss: 0.0000\n",
      "Iteration 898/2000\n",
      "Policy Loss: 0.2265, Value Loss: 0.0000\n",
      "Iteration 899/2000\n",
      "Policy Loss: 0.2746, Value Loss: 0.0000\n",
      "Iteration 900/2000\n",
      "Policy Loss: 0.0189, Value Loss: 0.0002\n",
      "Iteration 901/2000\n",
      "Policy Loss: 0.0138, Value Loss: 0.0001\n",
      "Iteration 902/2000\n",
      "Policy Loss: 0.2044, Value Loss: 0.0005\n",
      "Iteration 903/2000\n",
      "Policy Loss: 0.0538, Value Loss: 0.0000\n",
      "Iteration 904/2000\n",
      "Policy Loss: 0.0078, Value Loss: 0.0005\n",
      "Iteration 905/2000\n",
      "Policy Loss: 0.1077, Value Loss: 0.0003\n",
      "Iteration 906/2000\n",
      "Policy Loss: 0.0959, Value Loss: 0.0000\n",
      "Iteration 907/2000\n",
      "Policy Loss: 0.0068, Value Loss: 0.0000\n",
      "Iteration 908/2000\n",
      "Policy Loss: 0.0075, Value Loss: 0.0000\n",
      "Iteration 909/2000\n",
      "Policy Loss: 0.0875, Value Loss: 0.0000\n",
      "Iteration 910/2000\n",
      "Policy Loss: 0.1461, Value Loss: 0.0000\n",
      "Iteration 911/2000\n",
      "Policy Loss: 0.1176, Value Loss: 0.0001\n",
      "Iteration 912/2000\n",
      "Policy Loss: 0.1463, Value Loss: 0.0000\n",
      "Iteration 913/2000\n",
      "Policy Loss: 0.0224, Value Loss: 0.0012\n",
      "Iteration 914/2000\n",
      "Policy Loss: 0.1399, Value Loss: 0.0018\n",
      "Iteration 915/2000\n",
      "Policy Loss: 0.1088, Value Loss: 0.0000\n",
      "Iteration 916/2000\n",
      "Policy Loss: 0.0809, Value Loss: 0.0000\n",
      "Iteration 917/2000\n",
      "Policy Loss: 0.0387, Value Loss: 0.0001\n",
      "Iteration 918/2000\n",
      "Policy Loss: 0.0791, Value Loss: 0.0004\n",
      "Iteration 919/2000\n",
      "Policy Loss: 0.0516, Value Loss: 0.0000\n",
      "Iteration 920/2000\n",
      "Policy Loss: 0.0973, Value Loss: 0.0000\n",
      "Iteration 921/2000\n",
      "Policy Loss: 0.0548, Value Loss: 0.0000\n",
      "Iteration 922/2000\n",
      "Policy Loss: 0.1215, Value Loss: 0.0021\n",
      "Iteration 923/2000\n",
      "Policy Loss: 0.4273, Value Loss: 0.0003\n",
      "Iteration 924/2000\n",
      "Policy Loss: 0.0643, Value Loss: 0.0001\n",
      "Iteration 925/2000\n",
      "Policy Loss: 0.0118, Value Loss: 0.0000\n",
      "Iteration 926/2000\n",
      "Policy Loss: 0.0297, Value Loss: 0.0000\n",
      "Iteration 927/2000\n",
      "Policy Loss: 0.0099, Value Loss: 0.0001\n",
      "Iteration 928/2000\n",
      "Policy Loss: 0.0240, Value Loss: 0.0003\n",
      "Iteration 929/2000\n",
      "Policy Loss: 0.0767, Value Loss: 0.0011\n",
      "Iteration 930/2000\n",
      "Policy Loss: 0.0263, Value Loss: 0.0000\n",
      "Iteration 931/2000\n",
      "Policy Loss: 0.0262, Value Loss: 0.0000\n",
      "Iteration 932/2000\n",
      "Policy Loss: 0.0589, Value Loss: 0.0000\n",
      "Iteration 933/2000\n",
      "Policy Loss: 0.0720, Value Loss: 0.0007\n",
      "Iteration 934/2000\n",
      "Policy Loss: 0.1050, Value Loss: 0.0000\n",
      "Iteration 935/2000\n",
      "Policy Loss: 0.0652, Value Loss: 0.0003\n",
      "Iteration 936/2000\n",
      "Policy Loss: 0.0079, Value Loss: 0.0005\n",
      "Iteration 937/2000\n",
      "Policy Loss: 0.2625, Value Loss: 0.0004\n",
      "Iteration 938/2000\n",
      "Policy Loss: 0.2584, Value Loss: 0.0001\n",
      "Iteration 939/2000\n",
      "Policy Loss: 0.1877, Value Loss: 0.0003\n",
      "Iteration 940/2000\n",
      "Policy Loss: 0.0707, Value Loss: 0.0006\n",
      "Iteration 941/2000\n",
      "Policy Loss: 0.0288, Value Loss: 0.0000\n",
      "Iteration 942/2000\n",
      "Policy Loss: 0.0499, Value Loss: 0.0000\n",
      "Iteration 943/2000\n",
      "Policy Loss: 0.0633, Value Loss: 0.0000\n",
      "Iteration 944/2000\n",
      "Policy Loss: 0.1209, Value Loss: 0.0000\n",
      "Iteration 945/2000\n",
      "Policy Loss: 0.0235, Value Loss: 0.0002\n",
      "Iteration 946/2000\n",
      "Policy Loss: 0.2197, Value Loss: 0.0002\n",
      "Iteration 947/2000\n",
      "Policy Loss: 0.0156, Value Loss: 0.0055\n",
      "Iteration 948/2000\n",
      "Policy Loss: 0.1336, Value Loss: 0.0000\n",
      "Iteration 949/2000\n",
      "Policy Loss: 0.0032, Value Loss: 0.0000\n",
      "Iteration 950/2000\n",
      "Policy Loss: 0.0029, Value Loss: 0.0000\n",
      "Iteration 951/2000\n",
      "Policy Loss: 0.0041, Value Loss: 0.0002\n",
      "Iteration 952/2000\n",
      "Policy Loss: 0.1620, Value Loss: 0.0061\n",
      "Iteration 953/2000\n",
      "Policy Loss: 0.2422, Value Loss: 0.0000\n",
      "Iteration 954/2000\n",
      "Policy Loss: 0.2402, Value Loss: 0.0004\n",
      "Iteration 955/2000\n",
      "Policy Loss: 0.0194, Value Loss: 0.0005\n",
      "Iteration 956/2000\n",
      "Policy Loss: 0.0066, Value Loss: 0.0000\n",
      "Iteration 957/2000\n",
      "Policy Loss: 0.1326, Value Loss: 0.0000\n",
      "Iteration 958/2000\n",
      "Policy Loss: 0.0116, Value Loss: 0.0000\n",
      "Iteration 959/2000\n",
      "Policy Loss: 0.0037, Value Loss: 0.0006\n",
      "Iteration 960/2000\n",
      "Policy Loss: 0.2376, Value Loss: 0.0000\n",
      "Iteration 961/2000\n",
      "Policy Loss: 0.0063, Value Loss: 0.0002\n",
      "Iteration 962/2000\n",
      "Policy Loss: 0.0120, Value Loss: 0.0001\n",
      "Iteration 963/2000\n",
      "Policy Loss: 0.0166, Value Loss: 0.0041\n",
      "Iteration 964/2000\n",
      "Policy Loss: 0.0036, Value Loss: 0.0000\n",
      "Iteration 965/2000\n",
      "Policy Loss: 0.1023, Value Loss: 0.0000\n",
      "Iteration 966/2000\n",
      "Policy Loss: 0.0062, Value Loss: 0.0000\n",
      "Iteration 967/2000\n",
      "Policy Loss: 0.0150, Value Loss: 0.0000\n",
      "Iteration 968/2000\n",
      "Policy Loss: 0.1188, Value Loss: 0.0100\n",
      "Iteration 969/2000\n",
      "Policy Loss: 0.2267, Value Loss: 0.0000\n",
      "Iteration 970/2000\n",
      "Policy Loss: 0.0079, Value Loss: 0.0000\n",
      "Iteration 971/2000\n",
      "Policy Loss: 0.0080, Value Loss: 0.0000\n",
      "Iteration 972/2000\n",
      "Policy Loss: 0.0084, Value Loss: 0.0001\n",
      "Iteration 973/2000\n",
      "Policy Loss: 0.0108, Value Loss: 0.0000\n",
      "Iteration 974/2000\n",
      "Policy Loss: 0.0521, Value Loss: 0.0004\n",
      "Iteration 975/2000\n",
      "Policy Loss: 0.0103, Value Loss: 0.0000\n",
      "Iteration 976/2000\n",
      "Policy Loss: 0.0222, Value Loss: 0.0000\n"
     ]
    }
   ],
   "source": [
    "board_size = 7\n",
    "model = AlphaZeroNet(board_size)\n",
    "\n",
    "\n",
    "\n",
    "policy_loss, value_loss = train_alphazero(\n",
    "                        model=model,\n",
    "                        board_size=board_size,\n",
    "                        iterations=2000,\n",
    "                        games_per_iteration=5,\n",
    "                        batch_size=16,\n",
    "                        mcts_simulations=20,\n",
    "                        alpha=0.5\n",
    "                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ZtmW2gphjeIo",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 430
    },
    "executionInfo": {
     "elapsed": 504,
     "status": "ok",
     "timestamp": 1733702084740,
     "user": {
      "displayName": "Siyi Wu",
      "userId": "06196688456534608936"
     },
     "user_tz": 360
    },
    "id": "ZtmW2gphjeIo",
    "outputId": "52935804-3cce-464b-b080-49b6be7aaf1c"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(policy_loss)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "EB1BlQub7NjO",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 430
    },
    "executionInfo": {
     "elapsed": 281,
     "status": "ok",
     "timestamp": 1733702094092,
     "user": {
      "displayName": "Siyi Wu",
      "userId": "06196688456534608936"
     },
     "user_tz": 360
    },
    "id": "EB1BlQub7NjO",
    "outputId": "c471d77f-08f0-4b29-b46b-fd0fbd0fc9c6"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(value_loss)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "qkRUTTmdsouH",
   "metadata": {
    "id": "qkRUTTmdsouH"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
